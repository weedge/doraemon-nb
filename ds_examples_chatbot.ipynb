{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM25LYIKYdQMZfmW3hMjwcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/ds_examples_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://www.deepspeed.ai/training/\n",
        "- https://www.deepspeed.ai/inference/"
      ],
      "metadata": {
        "id": "xSwHgQn66yHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvwew6-7XV4W",
        "outputId": "0e397cb2-46c3-485e-c068-db2aeb0777f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Dec 13 02:48:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    50W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi --query-gpu=timestamp,memory.total,memory.free,memory.used,name,utilization.gpu,utilization.memory --format=csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvYIi6UDYuPq",
        "outputId": "6f0af455-ad56-4fed-9237-232c558fbfc0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "timestamp, memory.total [MiB], memory.free [MiB], memory.used [MiB], name, utilization.gpu [%], utilization.memory [%]\n",
            "2023/12/13 02:48:25.999, 40960 MiB, 40513 MiB, 0 MiB, NVIDIA A100-SXM4-40GB, 0 %, 0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ•DeepSpeed-Chatï¼šè½»æ¾ã€å¿«é€Ÿä¸”ç»æµå®æƒ åœ°å¯¹æ‰€æœ‰è§„æ¨¡çš„ç±»ä¼¼ ChatGPT æ¨¡å‹è¿›è¡Œ RLHF è®­ç»ƒğŸ•\n",
        "\n",
        "- https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/README.md\n",
        "- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-chat/chinese/README.md\n",
        "\n",
        "æœ¬ç€ä½¿ ChatGPT å¼æ¨¡å‹åŠå…¶åŠŸèƒ½æ°‘ä¸»åŒ–çš„ç²¾ç¥ï¼ŒDeepSpeed å¾ˆè‡ªè±ªåœ°æ¨å‡ºä¸€ä¸ªé€šç”¨ç³»ç»Ÿæ¡†æ¶ï¼Œç”¨äºä¸ºç±»ä¼¼ ChatGPT çš„æ¨¡å‹æä¾›ç«¯åˆ°ç«¯çš„è®­ç»ƒä½“éªŒï¼Œåä¸ºDeepSpeed Chatã€‚å®ƒå¯ä»¥è‡ªåŠ¨å°†æ‚¨æœ€å–œæ¬¢çš„é¢„è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹é€šè¿‡ OpenAI InstructGPT é£æ ¼çš„ä¸‰ä¸ªé˜¶æ®µæ¥ç”Ÿæˆæ‚¨è‡ªå·±çš„é«˜è´¨é‡ ChatGPT é£æ ¼æ¨¡å‹ã€‚\n",
        "\n",
        "DeepSpeed Chat ä½¿é«˜è´¨é‡ ChatGPT å¼æ¨¡å‹çš„è®­ç»ƒå˜å¾—ç®€å•ã€å¿«é€Ÿã€ç»æµä¸”å¯æ‰©å±•ã€‚\n",
        "\n",
        "\n",
        "åªéœ€å•å‡»ä¸€ä¸‹ï¼Œæ‚¨å°±å¯ä»¥åœ¨ 1.36 å°æ—¶å†…åœ¨å…·æœ‰ 48GB å†…å­˜çš„å•ä¸ªæ¶ˆè´¹çº§ NVIDIA A6000 GPU ä¸Šè®­ç»ƒã€ç”Ÿæˆå’ŒæœåŠ¡ 13 äº¿ä¸ªå‚æ•°çš„ ChatGPT æ¨¡å‹ã€‚åœ¨å…·æœ‰ 8 ä¸ª NVIDIA A100-40G GPU çš„å•ä¸ª DGX èŠ‚ç‚¹ä¸Šï¼ŒDeepSpeed-Chat å¯ä»¥åœ¨ 13.6 å°æ—¶å†…è®­ç»ƒ 130 äº¿ä¸ªå‚æ•°çš„ ChatGPT æ¨¡å‹ã€‚åœ¨å¤šGPUå¤šèŠ‚ç‚¹ç³»ç»Ÿï¼ˆäº‘åœºæ™¯ï¼‰ä¸Šï¼Œå³8ä¸ªDGXèŠ‚ç‚¹å’Œ8ä¸ªNVIDIA A100 GPU/èŠ‚ç‚¹ï¼ŒDeepSpeed-Chatå¯ä»¥åœ¨9å°æ—¶å†…è®­ç»ƒå‡º660äº¿å‚æ•°çš„ChatGPTæ¨¡å‹ã€‚æœ€åï¼Œå®ƒçš„è®­ç»ƒé€Ÿåº¦æ¯”ç°æœ‰ RLHF ç³»ç»Ÿå¿« 15 å€ï¼Œå¹¶ä¸”å¯ä»¥å¤„ç†å…·æœ‰è¶…è¿‡ 2000 äº¿ä¸ªå‚æ•°çš„ç±»ä¼¼ ChatGPT æ¨¡å‹çš„è®­ç»ƒï¼šè¿™æ˜¯ç°æœ‰ç³»ç»Ÿçš„å¦ä¸€ä¸ªä¸å¯èƒ½å®Œæˆçš„ä»»åŠ¡ã€‚æœ‰å…³ DeepSpeed-Chat å®ç°çš„å„ç§æ¨¡å‹å¤§å°å’Œä½è®­ç»ƒæˆæœ¬çš„å…¨é¢è®¨è®ºï¼Œè¯·å‚é˜…å‘å¸ƒåšå®¢å’Œè®­ç»ƒæ€§èƒ½è¯„ä¼°ã€‚\n",
        "\n",
        "é™¤æ­¤ç‰ˆæœ¬ä¹‹å¤–ï¼ŒDeepSpeed ç³»ç»Ÿä¸€ç›´è‡ªè±ªåœ°å……å½“ç³»ç»Ÿåç«¯ï¼Œç”¨äºåŠ é€Ÿä¸€ç³»åˆ—æ­£åœ¨è¿›è¡Œçš„å¿«é€Ÿè®­ç»ƒ/å¾®è°ƒèŠå¤©å¼æ¨¡å‹ï¼ˆä¾‹å¦‚ LLaMAï¼‰çš„å·¥ä½œã€‚ä»¥ä¸‹æ˜¯ç”± DeepSpeed æä¾›æ”¯æŒçš„ä¸€äº›å¼€æºç¤ºä¾‹ï¼š\n",
        "\n",
        "- [Databricks Dolly](https://github.com/databrickslabs/dolly)\n",
        "- [LMFlow](https://github.com/OptimalScale/LMFlow)\n",
        "- [CarperAI-TRLX](https://github.com/CarperAI/trlx)\n",
        "- [Huggingface-PEFT](https://github.com/huggingface/peft)\n",
        "\n",
        "\n",
        "DeepSpeed Chat çš„æ‘˜è¦åŒ…æ‹¬ï¼š\n",
        "\n",
        "- DeepSpeed Chatï¼šå®Œæ•´çš„ç«¯åˆ°ç«¯ä¸‰é˜¶æ®µ OpenAI InstructGPT è®­ç»ƒç­–ç•¥ï¼Œå…·æœ‰å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆï¼ˆRLHFï¼‰ï¼Œä»ç”¨æˆ·æœ€å–œæ¬¢çš„é¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹æ£€æŸ¥ç‚¹ç”Ÿæˆé«˜è´¨é‡çš„ ChatGPT å¼æ¨¡å‹ï¼›\n",
        "- DeepSpeed æ··åˆå¼•æ“ï¼šä¸€ä¸ªæ–°çš„ç³»ç»Ÿæ”¯æŒå¿«é€Ÿã€ç»æµä¸”å¯æ‰©å±•çš„æ‰€æœ‰è§„æ¨¡çš„ RLHF è®­ç»ƒã€‚å®ƒåŸºäºæ‚¨æœ€å–œçˆ±çš„ DeepSpeed ç³»ç»ŸåŠŸèƒ½ï¼ˆä¾‹å¦‚ ZeRO æŠ€æœ¯å’Œ DeepSpeed-Inferenceï¼‰æ„å»ºï¼›\n",
        "è½»æ¾è½»æ¾çš„è®­ç»ƒä½“éªŒï¼šå•ä¸ªè„šæœ¬èƒ½å¤Ÿé‡‡ç”¨é¢„å…ˆè®­ç»ƒçš„ Huggingface æ¨¡å‹å¹¶è¿è¡Œ RLHF è®­ç»ƒçš„æ‰€æœ‰ä¸‰ä¸ªæ­¥éª¤ï¼Œ a) ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ï¼Œb) å¥–åŠ±æ¨¡å‹å¾®è°ƒ ï¼Œc) åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLHFï¼‰ã€‚\n",
        "- å¯¹å½“ä»Šç±»ä¼¼ ChatGPT çš„æ¨¡å‹è®­ç»ƒçš„é€šç”¨ç³»ç»Ÿæ”¯æŒï¼šDeepSpeed Chat ä¸ä»…å¯ä»¥ä½œä¸ºåŸºäº 3 æ­¥æŒ‡ä»¤çš„ RLHF ç®¡é“çš„ç³»ç»Ÿåç«¯ï¼Œè¿˜å¯ä»¥ä½œä¸ºå½“å‰çš„å•ä¸€æ¨¡å‹å¾®è°ƒæ¢ç´¢ï¼ˆä¾‹å¦‚ï¼Œä»¥ LLaMA ä¸ºä¸­å¿ƒçš„å¾®è°ƒï¼‰å’Œé€‚ç”¨äºå„ç§æ¨¡å‹å’Œåœºæ™¯çš„é€šç”¨ RLHF è®­ç»ƒã€‚\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "- SFT: https://cameronrwolfe.substack.com/p/understanding-and-using-supervised\n",
        "- RHLF: https://huggingface.co/blog/zh/rlhf , https://huyenchip.com/2023/05/02/rlhf.html\n",
        "- [**Training language models to follow instructions with human feedback**](https://arxiv.org/abs/2203.02155)\n",
        "- [**ZeRO: Memory Optimizations Toward Training Trillion Parameter Models**](https://arxiv.org/abs/1910.02054)\n",
        "- [**LoRA: Low-Rank Adaptation of Large Language Models**](https://arxiv.org/abs/2106.09685)\n",
        "- [**Proximal Policy Optimization**](https://arxiv.org/abs/1707.06347)\n",
        "\n",
        "Tips:\n",
        "- ç›¸å…³å¾®è°ƒæ“ä½œå¯ä»¥é€šè¿‡ PERF: https://huggingface.co/docs/peft/index + TRLï¼šhttps://huggingface.co/docs/trl/index è¿›è¡Œå­¦ä¹ \n",
        "- gradient_accumulation: https://huggingface.co/docs/accelerate/usage_guides/gradient_accumulation"
      ],
      "metadata": {
        "id": "RtZwG9GiCrtf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# å®‰è£…ä¾èµ–"
      ],
      "metadata": {
        "id": "547SnlTHLLyD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2XAEW8P7CGiB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a2acf9f-488f-492f-9daf-50d52dbac921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.12.4.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.13)\n",
            "Collecting pynvml (from deepspeed)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.12.4-py3-none-any.whl size=1290638 sha256=41bf5a9eabee25ccb50331e300c4fd26d919ee0373a29cb86ce6c3beb7f847d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/52/f464610477b069120f740202a9d84a27f9d7235cbf035c4b75\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: ninja, hjson, pynvml, deepspeed\n",
            "Successfully installed deepspeed-0.12.4 hjson-3.1.0 ninja-1.11.1.1 pynvml-11.5.0\n"
          ]
        }
      ],
      "source": [
        "# gpu SM arch 8.0+ (Ampere+), A100\n",
        "# use V100 is ok\n",
        "!pip install deepspeed\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ds_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3SSoMfzXBws",
        "outputId": "11dd83cb-1f50-4f0b-ad0c-4e57612a4c69"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-13 02:49:13,067] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "--------------------------------------------------\n",
            "DeepSpeed C++/CUDA extension op report\n",
            "--------------------------------------------------\n",
            "NOTE: Ops not installed will be just-in-time (JIT) compiled at\n",
            "      runtime if needed. Op compatibility means that your system\n",
            "      meet the required dependencies to JIT install the op.\n",
            "--------------------------------------------------\n",
            "JIT compiled ops requires ninja\n",
            "ninja .................. \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "op name ................ installed .. compatible\n",
            "--------------------------------------------------\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "async_io ............... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "fused_adam ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_adam ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_adagrad ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cpu_lion ............... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "evoformer_attn ......... \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "fused_lamb ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "fused_lion ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "inference_core_ops ..... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "cutlass_ops ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "quantizer .............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "ragged_device_ops ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "ragged_ops ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "random_ltd ............. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.1\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.1.0), only 1.0.0 is known to be compatible\n",
            "sparse_attn ............ \u001b[93m[NO]\u001b[0m ....... \u001b[93m[NO]\u001b[0m\n",
            "spatial_inference ...... \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer ............ \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "stochastic_transformer . \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "transformer_inference .. \u001b[93m[NO]\u001b[0m ....... \u001b[92m[OKAY]\u001b[0m\n",
            "--------------------------------------------------\n",
            "DeepSpeed general environment info:\n",
            "torch install path ............... ['/usr/local/lib/python3.10/dist-packages/torch']\n",
            "torch version .................... 2.1.0+cu118\n",
            "deepspeed install path ........... ['/usr/local/lib/python3.10/dist-packages/deepspeed']\n",
            "deepspeed info ................... 0.12.4, unknown, unknown\n",
            "torch cuda version ............... 11.8\n",
            "torch hip version ................ None\n",
            "nvcc version ..................... 11.8\n",
            "deepspeed wheel compiled w. ...... torch 2.1, cuda 11.8\n",
            "shared memory (/dev/shm) size .... 40.75 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!deepspeed -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjI56g2LgjYQ",
        "outputId": "e84999e1-1698-424d-f2f0-43f488ddf403"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-12 14:50:53,792] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "usage: deepspeed [-h] [-H HOSTFILE] [-i INCLUDE] [-e EXCLUDE] [--num_nodes NUM_NODES]\n",
            "                 [--min_elastic_nodes MIN_ELASTIC_NODES] [--max_elastic_nodes MAX_ELASTIC_NODES]\n",
            "                 [--num_gpus NUM_GPUS] [--master_port MASTER_PORT] [--master_addr MASTER_ADDR]\n",
            "                 [--launcher LAUNCHER] [--launcher_args LAUNCHER_ARGS] [--module] [--no_python]\n",
            "                 [--no_local_rank] [--no_ssh_check] [--force_multi] [--save_pid]\n",
            "                 [--enable_each_rank_log ENABLE_EACH_RANK_LOG] [--autotuning {tune,run}]\n",
            "                 [--elastic_training] [--bind_cores_to_rank] [--bind_core_list BIND_CORE_LIST]\n",
            "                 [--ssh_port SSH_PORT]\n",
            "                 user_script ...\n",
            "\n",
            "DeepSpeed runner to help launch distributed multi-node/multi-gpu training jobs.\n",
            "\n",
            "positional arguments:\n",
            "  user_script           User script to launch, followed by any required arguments.\n",
            "  user_args\n",
            "\n",
            "options:\n",
            "  -h, --help            show this help message and exit\n",
            "  -H HOSTFILE, --hostfile HOSTFILE\n",
            "                        Hostfile path (in MPI style) that defines the resource pool available to\n",
            "                        the job (e.g., worker-0 slots=4) (default: /job/hostfile)\n",
            "  -i INCLUDE, --include INCLUDE\n",
            "                        Specify hardware resources to use during execution. String format is\n",
            "                        NODE_SPEC[@NODE_SPEC ...], where NODE_SPEC=NAME[:SLOT[,SLOT ...]]. If\n",
            "                        :SLOT is omitted, include all slots on that host. Example: -i\n",
            "                        \"worker-0@worker-1:0,2\" will use all slots on worker-0 and slots [0, 2] on\n",
            "                        worker-1. (default: )\n",
            "  -e EXCLUDE, --exclude EXCLUDE\n",
            "                        Specify hardware resources to NOT use during execution. Mutually exclusive\n",
            "                        with --include. Resource formatting is the same as --include. Example: -e\n",
            "                        \"worker-1:0\" will use all available resources except slot 0 on worker-1.\n",
            "                        (default: )\n",
            "  --num_nodes NUM_NODES\n",
            "                        Total number of worker nodes to run on, this will use the top N hosts from\n",
            "                        the given hostfile. (default: -1)\n",
            "  --min_elastic_nodes MIN_ELASTIC_NODES\n",
            "                        Minimum number of nodes to run elastic training on. Default is 1 when\n",
            "                        elastic training is enabled (default: -1)\n",
            "  --max_elastic_nodes MAX_ELASTIC_NODES\n",
            "                        Maximum number of nodes to run elastic training on. Default is num_nodes\n",
            "                        when elastic training is enabled (default: -1)\n",
            "  --num_gpus NUM_GPUS, --num_accelerators NUM_GPUS\n",
            "                        Max number of GPUs to use on each node, will use [0:N) GPU ids on each\n",
            "                        node. (default: -1)\n",
            "  --master_port MASTER_PORT\n",
            "                        (optional) Port used by PyTorch distributed for communication during\n",
            "                        training. (default: 29500)\n",
            "  --master_addr MASTER_ADDR\n",
            "                        (optional) IP address of node 0, will be inferred via 'hostname -I' if not\n",
            "                        specified. (default: )\n",
            "  --launcher LAUNCHER   (optional) choose launcher backend for multi-node training. Options\n",
            "                        currently include PDSH, OpenMPI, MVAPICH, SLURM, MPICH, IMPI. (default:\n",
            "                        pdsh)\n",
            "  --launcher_args LAUNCHER_ARGS\n",
            "                        (optional) pass launcher specific arguments as a single quoted argument.\n",
            "                        (default: )\n",
            "  --module              Change each process to interpret the launch script as a Python module,\n",
            "                        executing with the same behavior as 'python -m'. (default: False)\n",
            "  --no_python           Skip prepending the training script with 'python' - just execute it\n",
            "                        directly. (default: False)\n",
            "  --no_local_rank       Do not pass local_rank as an argument when calling the user's training\n",
            "                        script. (default: False)\n",
            "  --no_ssh_check        Do not perform ssh check in multi-node launcher model (default: False)\n",
            "  --force_multi         Force multi-node launcher mode, helps in cases where user wants to launch\n",
            "                        on single remote node. (default: False)\n",
            "  --save_pid            Save file containing launcher process id (pid) at /tmp/<main-pid>.ds,\n",
            "                        where <main-pid> is the pid of the first process that invoked `deepspeed`.\n",
            "                        Useful when launching deepspeed processes programmatically. (default:\n",
            "                        False)\n",
            "  --enable_each_rank_log ENABLE_EACH_RANK_LOG\n",
            "                        redirect the stdout and stderr from each rank into different log files\n",
            "                        (default: None)\n",
            "  --autotuning {tune,run}\n",
            "                        Run DeepSpeed autotuner to discover optimal configuration parameters\n",
            "                        before running job. (default: )\n",
            "  --elastic_training    Enable elastic training support in DeepSpeed. (default: False)\n",
            "  --bind_cores_to_rank  Bind each rank to different cores of the host (default: False)\n",
            "  --bind_core_list BIND_CORE_LIST\n",
            "                        List of cores to bind to with comma separated list of numbers and range.\n",
            "                        i.e. 1,3-5,7 => [1,3,4,5,7]. When not specified, all cores on system would\n",
            "                        be used rank binding (default: None)\n",
            "  --ssh_port SSH_PORT   SSH port to use for remote connections (default: None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/microsoft/DeepSpeedExamples.git\n"
      ],
      "metadata": {
        "id": "hGn0aGAmDgHR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6257ff-7ba0-4442-f3ea-d3869a7e75f0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSpeedExamples'...\n",
            "remote: Enumerating objects: 9729, done.\u001b[K\n",
            "remote: Counting objects: 100% (3128/3128), done.\u001b[K\n",
            "remote: Compressing objects: 100% (888/888), done.\u001b[K\n",
            "remote: Total 9729 (delta 2361), reused 2767 (delta 2165), pack-reused 6601\u001b[K\n",
            "Receiving objects: 100% (9729/9729), 119.28 MiB | 14.76 MiB/s, done.\n",
            "Resolving deltas: 100% (5453/5453), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/ && pip install -r requirements.txt && pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLtBP_iPVHYi",
        "outputId": "3323c0ce-b120-458c-db1d-d9b738b1f551"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets>=2.8.0 (from -r requirements.txt (line 1))\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.97 (from -r requirements.txt (line 2))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (3.20.3)\n",
            "Collecting accelerate>=0.15.0 (from -r requirements.txt (line 4))\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (2.1.0+cu118)\n",
            "Requirement already satisfied: deepspeed>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.12.4)\n",
            "Requirement already satisfied: transformers!=4.33.2,>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (4.35.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (3.4.1)\n",
            "Collecting multiprocess (from datasets>=2.8.0->-r requirements.txt (line 1))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->-r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->-r requirements.txt (line 4)) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->-r requirements.txt (line 4)) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->-r requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (1.11.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (1.10.13)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.0->-r requirements.txt (line 6)) (11.5.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.33.2,>=4.31.0->-r requirements.txt (line 7)) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.33.2,>=4.31.0->-r requirements.txt (line 7)) (0.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 8)) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->-r requirements.txt (line 1)) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->-r requirements.txt (line 1)) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 8)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.8.0->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.8.0->-r requirements.txt (line 1)) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 8)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->-r requirements.txt (line 8)) (3.2.2)\n",
            "Installing collected packages: sentencepiece, pyarrow-hotfix, dill, multiprocess, accelerate, datasets\n",
            "Successfully installed accelerate-0.25.0 datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.6 sentencepiece-0.1.99\n",
            "Obtaining file:///content/DeepSpeedExamples/applications/DeepSpeed-Chat\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: datasets>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (2.15.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.97 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (0.1.99)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (3.20.3)\n",
            "Requirement already satisfied: accelerate>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (0.25.0)\n",
            "Requirement already satisfied: torch>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (2.1.0+cu118)\n",
            "Requirement already satisfied: deepspeed>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (0.12.4)\n",
            "Requirement already satisfied: transformers!=4.33.2,>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (4.35.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from deepspeed-chat==0.1) (2.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->deepspeed-chat==0.1) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->deepspeed-chat==0.1) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->deepspeed-chat==0.1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->deepspeed-chat==0.1) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->deepspeed-chat==0.1) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.15.0->deepspeed-chat==0.1) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.8.0->deepspeed-chat==0.1) (3.9.1)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.2->deepspeed-chat==0.1) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.2->deepspeed-chat==0.1) (1.11.1.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.2->deepspeed-chat==0.1) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.2->deepspeed-chat==0.1) (1.10.13)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed>=0.9.2->deepspeed-chat==0.1) (11.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->deepspeed-chat==0.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->deepspeed-chat==0.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->deepspeed-chat==0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->deepspeed-chat==0.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->deepspeed-chat==0.1) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.12.0->deepspeed-chat==0.1) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.33.2,>=4.31.0->deepspeed-chat==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers!=4.33.2,>=4.31.0->deepspeed-chat==0.1) (0.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (1.59.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (3.5.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->deepspeed-chat==0.1) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->deepspeed-chat==0.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->deepspeed-chat==0.1) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->deepspeed-chat==0.1) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->deepspeed-chat==0.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->deepspeed-chat==0.1) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.8.0->deepspeed-chat==0.1) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deepspeed-chat==0.1) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deepspeed-chat==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->deepspeed-chat==0.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->deepspeed-chat==0.1) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->deepspeed-chat==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->deepspeed-chat==0.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->deepspeed-chat==0.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets>=2.8.0->deepspeed-chat==0.1) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->deepspeed-chat==0.1) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.8.0->deepspeed-chat==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.8.0->deepspeed-chat==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.12.0->deepspeed-chat==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->deepspeed-chat==0.1) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->deepspeed-chat==0.1) (3.2.2)\n",
            "Installing collected packages: deepspeed-chat\n",
            "  Running setup.py develop for deepspeed-chat\n",
            "Successfully installed deepspeed-chat-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# æ•°æ®é›†\n",
        "\n",
        "[Dahoas/rm-static](https://huggingface.co/datasets/Dahoas/rm-static)\n",
        "\n",
        "[Dahoas/full-hh-rlhf](https://huggingface.co/datasets/Dahoas/full-hh-rlhf)\n",
        "\n",
        "[Dahoas/synthetic-instruct-gptj-pairwise](https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise)\n",
        "\n",
        "[rlhf-reward-datasets](https://huggingface.co/datasets/rlhf-reward-datasets)\n",
        "\n",
        "[openai/webgpt_comparisons](https://huggingface.co/datasets/openai/webgpt_comparisons)\n",
        "\n",
        "[stanfordnlp/SHP](https://huggingface.co/datasets/stanfordnlp/SHP)\n",
        "\n",
        "å…¶ä»–è‡ªå®šä¹‰çš„æ•°æ®ï¼Œå¦‚æœç”¨äºå…¬å¼€ç ”ç©¶ç›®çš„ï¼Œå¯ä»¥ä¸Šä¼ è‡³huggingfaceï¼Œé€šè¿‡DataLoaderå»åŠ è½½æ•°æ®ï¼›\n",
        "å¦‚æœæ˜¯å…¬å¸å†…éƒ¨ä¸“æœ‰æ•°æ®ï¼Œæœ‰æ„å»ºæ•°æ®æ¹–çš„èƒ½åŠ›ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡s3åè®®åŠ è½½ï¼Œ\n"
      ],
      "metadata": {
        "id": "LCGWdxisgRbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# trainning è®­ç»ƒ"
      ],
      "metadata": {
        "id": "6BFQ4vhXP9wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œè®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ (LLM) å’ŒåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹  (RLHF) ä»ç„¶æ˜¯å­˜åœ¨è®¸å¤šæœªçŸ¥æ•°çš„æ‚¬è€Œæœªå†³çš„é—®é¢˜ã€‚DeepSpeed-Chatæ—¨åœ¨æä¾›ç«¯åˆ°ç«¯çš„RLHFè®­ç»ƒç®¡é“ä»¥åŠé«˜æ•ˆã€å¿«é€Ÿçš„ç³»ç»Ÿæ”¯æŒï¼Œè€Œä¸æ˜¯RLHFè®­ç»ƒçš„å…¨é¢è§£å†³æ–¹æ¡ˆã€‚ç”±äºè¿™ä¸ªé¢†åŸŸç›¸å¯¹è¾ƒæ–°ï¼Œå¯¹äºç”¨æˆ·å’Œå¼€å‘äººå‘˜æ¥è¯´éƒ½å­˜åœ¨å„ç§æœªçŸ¥å› ç´ ã€‚\n",
        "\n",
        "\n",
        "\n",
        "ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¸€ä¸ªè„šæœ¬ï¼Œä»¥é¢„è®­ç»ƒçš„ OPT-1.3B ä½œä¸º actor æ¨¡å‹ï¼ŒOPT-350M ä½œä¸º reward æ¨¡å‹ï¼Œç”Ÿæˆä¸€ä¸ªæœ€ç»ˆçš„ 13 äº¿å‚æ•°çš„ ChatGPT ç±»å‹çš„æ¨¡å‹ï¼š\n"
      ],
      "metadata": {
        "id": "wSNcAJvERRQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# å•å¡gpu\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/ \\\n",
        "  && python e2e_rlhf.py --actor-model facebook/opt-1.3b --reward-model facebook/opt-350m --deployment-type single_gpu\n",
        "\n",
        "# v100-16G or A100-40G OOM\n",
        "# https://github.com/microsoft/DeepSpeedExamples/issues/271"
      ],
      "metadata": {
        "id": "E0O0dJy0P_q_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b38b16a-e38b-4412-e718-7874dba2222d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---=== Running Step 1 ===---\n",
            "Running:\n",
            "bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 211, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 196, in main\n",
            "    launch_cmd(args, step_num, cmd)\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 176, in launch_cmd\n",
            "    raise RuntimeError('\\n\\n'.join((\n",
            "RuntimeError: Step 1 exited with non-zero status 1\n",
            "\n",
            "Launch command: bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b \n",
            "\n",
            "Log output: /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b/training.log\n",
            "\n",
            "Please see our tutorial at https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat/training/step1_supervised_finetuning\n",
            "\n",
            "Please check that you have installed our requirements: `pip install -r requirements.txt`\n",
            "\n",
            "If you are seeing an OOM error, try modifying /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh:\n",
            "\n",
            "  - Reduce `--per_device_*_batch_size`\n",
            "\n",
            "  - Increase `--zero_stage {0,1,2,3}` on multi-gpu setups\n",
            "\n",
            "  - Enable `--gradient_checkpointing` or `--only_optimize_lora`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å•å¡gpu\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/ \\\n",
        "  && python e2e_rlhf.py --actor-model facebook/opt-1.3b --reward-model facebook/opt-350m --deployment-type single_gpu"
      ],
      "metadata": {
        "id": "f7xE2u9leu-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143da43c-08c0-4d31-d460-731e39c2228a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---=== Running Step 1 ===---\n",
            "Running:\n",
            "bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b \n",
            "---=== Finished Step 1 in 0:51:24 ===---\n",
            "---=== Running Step 2 ===---\n",
            "Running:\n",
            "bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/training_scripts/opt/single_gpu/run_350m.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 211, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 196, in main\n",
            "    launch_cmd(args, step_num, cmd)\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 176, in launch_cmd\n",
            "    raise RuntimeError('\\n\\n'.join((\n",
            "RuntimeError: Step 2 exited with non-zero status 1\n",
            "\n",
            "Launch command: bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/training_scripts/opt/single_gpu/run_350m.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m \n",
            "\n",
            "Log output: /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m/training.log\n",
            "\n",
            "Please see our tutorial at https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning\n",
            "\n",
            "Please check that you have installed our requirements: `pip install -r requirements.txt`\n",
            "\n",
            "If you are seeing an OOM error, try modifying /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/training_scripts/opt/single_gpu/run_350m.sh:\n",
            "\n",
            "  - Reduce `--per_device_*_batch_size`\n",
            "\n",
            "  - Increase `--zero_stage {0,1,2,3}` on multi-gpu setups\n",
            "\n",
            "  - Enable `--gradient_checkpointing` or `--only_optimize_lora`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -alh DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b\n",
        "!head DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b/merges.txt\n",
        "!cat DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b/config.json\n",
        "!head DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b/vocab.json\n"
      ],
      "metadata": {
        "id": "GP64gKtrkk_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SFT actor-model is ok; skip step 1\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/ \\\n",
        "  && python e2e_rlhf.py --step 2 3 --actor-model facebook/opt-1.3b --reward-model facebook/opt-350m --deployment-type single_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtgVB-eNW7BB",
        "outputId": "4b0aeb24-461b-4092-cf5a-9357a82303bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---=== Running Step 2 ===---\n",
            "Running:\n",
            "bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/training_scripts/opt/single_gpu/run_350m.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m \n",
            "---=== Finished Step 2 in 0:23:58 ===---\n",
            "---=== Running Step 3 ===---\n",
            "Running:\n",
            "bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m '' '' /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 211, in <module>\n",
            "    main(args)\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 196, in main\n",
            "    launch_cmd(args, step_num, cmd)\n",
            "  File \"/content/DeepSpeedExamples/applications/DeepSpeed-Chat/e2e_rlhf.py\", line 176, in launch_cmd\n",
            "    raise RuntimeError('\\n\\n'.join((\n",
            "RuntimeError: Step 3 exited with non-zero status 2\n",
            "\n",
            "Launch command: bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m '' '' /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b\n",
            "\n",
            "Log output: /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b/training.log\n",
            "\n",
            "Please see our tutorial at https://github.com/microsoft/DeepSpeedExamples/tree/master/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning\n",
            "\n",
            "Please check that you have installed our requirements: `pip install -r requirements.txt`\n",
            "\n",
            "If you are seeing an OOM error, try modifying /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh:\n",
            "\n",
            "  - Reduce `--per_device_*_batch_size`\n",
            "\n",
            "  - Increase `--zero_stage {0,1,2,3}` on multi-gpu setups\n",
            "\n",
            "  - Enable `--gradient_checkpointing` or `--only_optimize_lora`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -alh DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m\n",
        "!head DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m/merges.txt\n",
        "!cat DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m/config.json\n",
        "!head DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m/vocab.json\n"
      ],
      "metadata": {
        "id": "Wx67Kr4GlHwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SFT actor-model and RM reward-model are ok; skip step 1,2\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/ \\\n",
        "  && python e2e_rlhf.py --step 3 --actor-model facebook/opt-1.3b --reward-model facebook/opt-350m --deployment-type single_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpJZvIRLd5zl",
        "outputId": "d71d7305-234f-4749-8576-82b76ea5101b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---=== Running Step 3 ===---\n",
            "Running:\n",
            "bash /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m '' '' /content/DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -alh DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b\n",
        "!head DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b/merges.txt\n",
        "!cat DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b/config.json\n",
        "!head DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b/vocab.json\n"
      ],
      "metadata": {
        "id": "TEY45BHglUaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tipsï¼š\n",
        "- ä»¥ä¸Šè®­ç»ƒéœ€è¦è°ƒæ•´ batch_size to device ä»¥é˜²OOM, å¯ä»¥ç›‘æ§å†…å­˜ä½¿ç”¨ç‡è¿›è¡Œè°ƒæ•´åˆ°gpuåˆ©ç”¨ç‡æœ€é«˜çš„çŠ¶æ€"
      ],
      "metadata": {
        "id": "ULXgZWPxgJUY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## è®­ç»ƒè®°å½•\n"
      ],
      "metadata": {
        "id": "Wn4ZEaktSzI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### step1_supervised_finetuning\n",
        "\n",
        "```\n",
        "/content# cat /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh\n",
        "#!/bin/bash\n",
        "# Copyright (c) Microsoft Corporation.\n",
        "# SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "# DeepSpeed Team\n",
        "\n",
        "# Note that usually LoRA needs to use larger learning rate\n",
        "OUTPUT=$1\n",
        "ZERO_STAGE=$2\n",
        "if [ \"$OUTPUT\" == \"\" ]; then\n",
        "    OUTPUT=./output\n",
        "fi\n",
        "if [ \"$ZERO_STAGE\" == \"\" ]; then\n",
        "    ZERO_STAGE=0\n",
        "fi\n",
        "mkdir -p $OUTPUT\n",
        "\n",
        "# u can change num_train_epochs default 1\n",
        "deepspeed --num_gpus 1 main.py --model_name_or_path facebook/opt-1.3b \\\n",
        "   --per_device_train_batch_size 2 \\\n",
        "   --per_device_eval_batch_size 2 \\\n",
        "   --max_seq_len 512 \\\n",
        "   --learning_rate 9.65e-6 \\\n",
        "   --weight_decay 0.1 \\\n",
        "   --num_train_epochs 2 \\\n",
        "   --gradient_accumulation_steps 1 \\\n",
        "   --lr_scheduler_type cosine \\\n",
        "   --num_warmup_steps 0 \\\n",
        "   --seed 1234 \\\n",
        "   --zero_stage $ZERO_STAGE \\\n",
        "   --deepspeed \\\n",
        "   --only_optimize_lora \\\n",
        "   --output_dir $OUTPUT &> $OUTPUT/training.log\n",
        "\n",
        "#   --gradient_accumulation_steps 8 --lora_dim 128 --zero_stage $ZERO_STAGE \\\n",
        "#   --enable_tensorboard \\\n",
        "#   --tensorboard_path $OUTPUT \\\n",
        "```\n",
        "\n",
        "```\n",
        "/content# nvidia-smi --query-gpu=timestamp,memory.total,memory.free,memory.used,name,utilization.gpu,utilization.memory --format=csv -l 3\n",
        "timestamp, memory.total [MiB], memory.free [MiB], memory.used [MiB], name, utilization.gpu [%], utilization.memory [%]\n",
        "2023/12/13 03:26:17.335, 40960 MiB, 3244 MiB, 37269 MiB, NVIDIA A100-SXM4-40GB, 90 %, 65 %\n",
        "2023/12/13 03:26:20.336, 40960 MiB, 3244 MiB, 37269 MiB, NVIDIA A100-SXM4-40GB, 90 %, 66 %\n",
        "2023/12/13 03:26:23.337, 40960 MiB, 3244 MiB, 37269 MiB, NVIDIA A100-SXM4-40GB, 88 %, 63 %\n",
        "2023/12/13 03:26:26.338, 40960 MiB, 3244 MiB, 37269 MiB, NVIDIA A100-SXM4-40GB, 90 %, 66 %\n",
        "2023/12/13 03:26:29.340, 40960 MiB, 3244 MiB, 37269 MiB, NVIDIA A100-SXM4-40GB, 90 %, 64 %\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "61FzfS0xQIaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step2_reward_model_finetuning\n",
        "\n",
        "```\n",
        "/content# cat /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/training_scripts/opt/single_gpu/run_350m.sh\n",
        "#!/bin/bash\n",
        "# Copyright (c) Microsoft Corporation.\n",
        "# SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "# DeepSpeed Team\n",
        "OUTPUT=$1\n",
        "ZERO_STAGE=$2\n",
        "if [ \"$OUTPUT\" == \"\" ]; then\n",
        "    OUTPUT=./output\n",
        "fi\n",
        "if [ \"$ZERO_STAGE\" == \"\" ]; then\n",
        "    ZERO_STAGE=0\n",
        "fi\n",
        "mkdir -p $OUTPUT\n",
        "\n",
        "deepspeed --num_gpus 1 main.py --model_name_or_path facebook/opt-350m \\\n",
        "   --per_device_train_batch_size 2 \\\n",
        "   --per_device_eval_batch_size 2 \\\n",
        "   --only_optimize_lora \\\n",
        "   --num_padding_at_beginning 1 \\\n",
        "   --weight_decay 0.1 \\\n",
        "   --dropout 0.0 \\\n",
        "   --gradient_accumulation_steps 4 --zero_stage $ZERO_STAGE \\\n",
        "   --enable_tensorboard \\\n",
        "   --tensorboard_path $OUTPUT \\\n",
        "   --deepspeed --output_dir $OUTPUT &> $OUTPUT/training.log\n",
        "```\n",
        "\n",
        "```\n",
        "/content# nvidia-smi --query-gpu=timestamp,memory.total,memory.free,memory.used,name,utilization.gpu,utilization.memory --format=csv -l 3\n",
        "timestamp, memory.total [MiB], memory.free [MiB], memory.used [MiB], name, utilization.gpu [%], utilization.memory [%]\n",
        "2023/12/13 04:11:43.910, 40960 MiB, 29262 MiB, 11251 MiB, NVIDIA A100-SXM4-40GB, 82 %, 46 %\n",
        "2023/12/13 04:11:46.910, 40960 MiB, 29262 MiB, 11251 MiB, NVIDIA A100-SXM4-40GB, 83 %, 46 %\n",
        "2023/12/13 04:11:49.911, 40960 MiB, 29262 MiB, 11251 MiB, NVIDIA A100-SXM4-40GB, 86 %, 48 %\n",
        "2023/12/13 04:11:52.913, 40960 MiB, 29262 MiB, 11251 MiB, NVIDIA A100-SXM4-40GB, 81 %, 46 %\n",
        "```\n",
        "\n",
        "```\n",
        "/content# tail -f DeepSpeedExamples/applications/DeepSpeed-Chat/output/reward-models/350m/training.log\n",
        "[2023-12-13 04:31:49,413] [INFO] [logging.py:96:log_dist] [Rank 0] step=3420, skipped=29, lr=[1.4959651352601607e-06, 1.4959651352601607e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:31:49,421] [INFO] [timer.py:260:stop] epoch=0/micro_step=13680/global_step=3420, RunningAvgSamplesPerSec=22.258547892879996, CurrSamplesPerSec=22.2247897865576, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:31:53,037] [INFO] [logging.py:96:log_dist] [Rank 0] step=3430, skipped=29, lr=[1.4265805656755864e-06, 1.4265805656755864e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:31:53,045] [INFO] [timer.py:260:stop] epoch=0/micro_step=13720/global_step=3430, RunningAvgSamplesPerSec=22.258493057977653, CurrSamplesPerSec=22.348077786347293, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:31:56,645] [INFO] [logging.py:96:log_dist] [Rank 0] step=3440, skipped=29, lr=[1.3587962402902082e-06, 1.3587962402902082e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:31:56,653] [INFO] [timer.py:260:stop] epoch=0/micro_step=13760/global_step=3440, RunningAvgSamplesPerSec=22.2586868350505, CurrSamplesPerSec=22.411875188689073, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:32:00,260] [INFO] [logging.py:96:log_dist] [Rank 0] step=3450, skipped=29, lr=[1.29261676053547e-06, 1.29261676053547e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:32:00,268] [INFO] [timer.py:260:stop] epoch=0/micro_step=13800/global_step=3450, RunningAvgSamplesPerSec=22.258773386410347, CurrSamplesPerSec=22.11042815422408, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:32:03,931] [INFO] [logging.py:96:log_dist] [Rank 0] step=3460, skipped=29, lr=[1.228046618900422e-06, 1.228046618900422e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:32:03,939] [INFO] [timer.py:260:stop] epoch=0/micro_step=13840/global_step=3460, RunningAvgSamplesPerSec=22.25792098458994, CurrSamplesPerSec=22.08814474216896, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:32:07,556] [INFO] [logging.py:96:log_dist] [Rank 0] step=3470, skipped=29, lr=[1.1650901986267365e-06, 1.1650901986267365e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:32:07,564] [INFO] [timer.py:260:stop] epoch=0/micro_step=13880/global_step=3470, RunningAvgSamplesPerSec=22.257832439582216, CurrSamplesPerSec=22.273370674193252, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:32:11,178] [INFO] [logging.py:96:log_dist] [Rank 0] step=3480, skipped=29, lr=[1.1037517734111851e-06, 1.1037517734111851e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:32:11,186] [INFO] [timer.py:260:stop] epoch=0/micro_step=13920/global_step=3480, RunningAvgSamplesPerSec=22.25781006707543, CurrSamplesPerSec=22.34028109749196, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:32:14,091] [INFO] [fused_optimizer.py:352:_update_scale] No Grad overflow for 100 iterations\n",
        "[2023-12-13 04:32:14,091] [INFO] [fused_optimizer.py:353:_update_scale] Increasing dynamic loss scale from 131072.0 to 262144.0\n",
        "[2023-12-13 04:32:14,436] [INFO] [fused_optimizer.py:344:_update_scale]\n",
        "Grad overflow on iteration 3488\n",
        "[2023-12-13 04:32:14,436] [INFO] [fused_optimizer.py:345:_update_scale] Reducing dynamic loss scale from 262144.0 to 131072.0\n",
        "[2023-12-13 04:32:14,436] [INFO] [logging.py:96:log_dist] [Rank 0] Overflow detected. Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
        "[2023-12-13 04:32:14,794] [INFO] [logging.py:96:log_dist] [Rank 0] step=3490, skipped=30, lr=[1.0499340201976543e-06, 1.0499340201976543e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:32:14,802] [INFO] [timer.py:260:stop] epoch=0/micro_step=13960/global_step=3490, RunningAvgSamplesPerSec=22.25792125305279, CurrSamplesPerSec=22.130596141276783, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "[2023-12-13 04:32:18,420] [INFO] [logging.py:96:log_dist] [Rank 0] step=3500, skipped=30, lr=[9.916811660250824e-07, 9.916811660250824e-07], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 04:32:18,427] [INFO] [timer.py:260:stop] epoch=0/micro_step=14000/global_step=3500, RunningAvgSamplesPerSec=22.257833648158577, CurrSamplesPerSec=22.329458081397593, MemAllocated=4.34GB, MaxMemAllocated=9.18GB\n",
        "```\n",
        "\n",
        "```\n",
        "tail -f DeepSpeedExamples/applications/DeepSpeed-Chat/output/actor-models/1.3b/training.log\n",
        "\n",
        "[2023-12-13 03:30:35,531] [INFO] [logging.py:96:log_dist] [Rank 0] step=8140, skipped=80, lr=[4.394243808375539e-06, 4.394243808375539e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 03:30:35,572] [INFO] [timer.py:260:stop] epoch=1/micro_step=514/global_step=8140, RunningAvgSamplesPerSec=10.306346983794935, CurrSamplesPerSec=10.236351300561811, MemAllocated=17.27GB, MaxMemAllocated=29.52GB\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.85, Samples/sec: 10.20, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.99, Samples/sec: 10.23, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 42.01, Samples/sec: 10.24, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.98, Samples/sec: 10.23, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 42.06, Samples/sec: 10.25, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.96, Samples/sec: 10.23, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 42.02, Samples/sec: 10.24, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.19s, TFLOPs: 42.08, Samples/sec: 10.26, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.97, Samples/sec: 10.23, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 42.01, Samples/sec: 10.24, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "[2023-12-13 03:30:37,504] [INFO] [logging.py:96:log_dist] [Rank 0] step=8150, skipped=80, lr=[4.384345924461392e-06, 4.384345924461392e-06], mom=[(0.9, 0.95), (0.9, 0.95)]\n",
        "[2023-12-13 03:30:37,544] [INFO] [timer.py:260:stop] epoch=1/micro_step=524/global_step=8150, RunningAvgSamplesPerSec=10.306265178726324, CurrSamplesPerSec=10.151742299006925, MemAllocated=17.27GB, MaxMemAllocated=29.52GB\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.49, Samples/sec: 10.11, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.99, Samples/sec: 10.23, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 42.03, Samples/sec: 10.24, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 42.05, Samples/sec: 10.25, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.95, Samples/sec: 10.22, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.92, Samples/sec: 10.22, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.20s, TFLOPs: 41.93, Samples/sec: 10.22, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "Model Parameters: 1.316 B, Latency: 0.19s, TFLOPs: 42.19, Samples/sec: 10.28, Time/seq 0.10s, Batch Size: 2, Sequence Length: 512\n",
        "```"
      ],
      "metadata": {
        "id": "XDKBqNZxXt3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### step3_rlhf_finetuning\n",
        "\n",
        "```\n",
        "/contentcat /content/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/training_scripts/opt/single_gpu/run_1.3b.sh\n",
        "#!/bin/bash\n",
        "# Copyright (c) Microsoft Corporation.\n",
        "# SPDX-License-Identifier: Apache-2.0\n",
        "\n",
        "# DeepSpeed Team\n",
        "ACTOR_MODEL_PATH=$1\n",
        "CRITIC_MODEL_PATH=$2\n",
        "ACTOR_ZERO_STAGE=$3\n",
        "CRITIC_ZERO_STAGE=$4\n",
        "OUTPUT=$5\n",
        "if [ \"$OUTPUT\" == \"\" ]; then\n",
        "    OUTPUT=./output\n",
        "fi\n",
        "if [ \"$ACTOR_ZERO_STAGE\" == \"\" ]; then\n",
        "    ACTOR_ZERO_STAGE=0\n",
        "fi\n",
        "if [ \"$CRITIC_ZERO_STAGE\" == \"\" ]; then\n",
        "    CRITIC_ZERO_STAGE=0\n",
        "fi\n",
        "mkdir -p $OUTPUT\n",
        "\n",
        "deepspeed --num_gpus 1 main.py \\\n",
        "   --actor_model_name_or_path $ACTOR_MODEL_PATH --critic_model_name_or_path $CRITIC_MODEL_PATH \\\n",
        "   --actor_zero_stage $ACTOR_ZERO_STAGE --critic_zero_stage $CRITIC_ZERO_STAGE \\\n",
        "   --per_device_generation_batch_size 4 \\\n",
        "   --per_device_training_batch_size 4 \\\n",
        "   --only_optimize_lora \\\n",
        "   --num_padding_at_beginning 1 --gradient_accumulation_steps 2 \\\n",
        "   --deepspeed --actor_lora_dim 128 --enable_hybrid_engine --actor_gradient_checkpointing --actor_dropout 0.0 \\\n",
        "   --output_dir $OUTPUT &> $OUTPUT/training.log\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "/content# nvidia-smi --query-gpu=timestamp,memory.total,memory.free,memory.used,name,utilization.gpu,utilization.memory --format=csv -l 3\n",
        "timestamp, memory.total [MiB], memory.free [MiB], memory.used [MiB], name, utilization.gpu [%], utilization.memory [%]\n",
        "2023/12/13 04:49:57.829, 40960 MiB, 19124 MiB, 21389 MiB, NVIDIA A100-SXM4-40GB, 88 %, 52 %\n",
        "2023/12/13 04:50:00.843, 40960 MiB, 19124 MiB, 21389 MiB, NVIDIA A100-SXM4-40GB, 67 %, 38 %\n",
        "2023/12/13 04:50:03.845, 40960 MiB, 19124 MiB, 21389 MiB, NVIDIA A100-SXM4-40GB, 55 %, 31 %\n",
        "2023/12/13 04:50:06.846, 40960 MiB, 19124 MiB, 21389 MiB, NVIDIA A100-SXM4-40GB, 57 %, 32 %\n",
        "2023/12/13 04:50:09.846, 40960 MiB, 19124 MiB, 21389 MiB, NVIDIA A100-SXM4-40GB, 57 %, 32 %\n",
        "2023/12/13 04:50:12.847, 40960 MiB, 19124 MiB, 21389 MiB, NVIDIA A100-SXM4-40GB, 84 %, 47 %\n",
        "```\n",
        "\n",
        "```\n",
        "/content# tail -f DeepSpeedExamples/applications/DeepSpeed-Chat/output/step3-models/1.3b/training.log\n",
        "-------------------------------------------------------------------------------------\n",
        "|E2E latency=0.78s |Gather latency=0.00s (0.00%) |Generate time=0.39s (50.18%) |Training time=0.30s (38.80%) |Others=0.09 (11.02%)|CurSamplesPerSec=5.15 |AvgSamplesPerSec=2.48\n",
        "Epoch: 0 | Step: 287 | PPO Epoch: 1 | Actor Loss: 0.06512451171875 | Critic Loss: 0.030548095703125 | Unsupervised Loss: 0.0\n",
        "End-to-End => Latency: 0.78s, TFLOPs: 34.54, Samples/sec: 5.11, Time/seq 0.20s, Batch Size: 4, Total Seq. Length: 512\n",
        "Generation => Latency: 0.47s, Per-token Latency 1.84 ms, TFLOPs: 11.64, BW: 1556.94 GB/sec, Answer Seq. Length: 256\n",
        "Training   => Latency: 0.31s, TFLOPs: 68.88\n",
        "Actor Model Parameters => 1.429 B, Critic Model Parameters => 0.331 B\n",
        "Average reward score: -42.5 | EMA reward score: -41.4414139346459\n",
        "-------------------------------------------------------------------------------------\n",
        "|E2E latency=0.93s |Gather latency=0.00s (0.00%) |Generate time=0.46s (49.93%) |Training time=0.33s (35.98%) |Others=0.13 (14.09%)|CurSamplesPerSec=4.31 |AvgSamplesPerSec=2.48\n",
        "Epoch: 0 | Step: 288 | PPO Epoch: 1 | Actor Loss: 0.0499267578125 | Critic Loss: 0.0175628662109375 | Unsupervised Loss: 0.0\n",
        "End-to-End => Latency: 0.49s, TFLOPs: 55.67, Samples/sec: 8.23, Time/seq 0.12s, Batch Size: 4, Total Seq. Length: 512\n",
        "Generation => Latency: 0.25s, Per-token Latency 0.97 ms, TFLOPs: 22.09, BW: 2954.18 GB/sec, Answer Seq. Length: 256\n",
        "Training   => Latency: 0.24s, TFLOPs: 90.57\n",
        "Actor Model Parameters => 1.429 B, Critic Model Parameters => 0.331 B\n",
        "Average reward score: -41.1875 | EMA reward score: -41.4414139346459\n",
        "-------------------------------------------------------------------------------------\n",
        "|E2E latency=0.63s |Gather latency=0.00s (0.00%) |Generate time=0.24s (38.04%) |Training time=0.31s (48.50%) |Others=0.09 (13.45%)|CurSamplesPerSec=6.32 |AvgSamplesPerSec=2.49\n",
        "Epoch: 0 | Step: 289 | PPO Epoch: 1 | Actor Loss: -0.0202178955078125 | Critic Loss: 0.06353759765625 | Unsupervised Loss: 0.0\n",
        "End-to-End => Latency: 0.60s, TFLOPs: 44.97, Samples/sec: 6.65, Time/seq 0.15s, Batch Size: 4, Total Seq. Length: 512\n",
        "Generation => Latency: 0.28s, Per-token Latency 1.10 ms, TFLOPs: 19.36, BW: 2588.93 GB/sec, Answer Seq. Length: 256\n",
        "Training   => Latency: 0.32s, TFLOPs: 67.66\n",
        "Actor Model Parameters => 1.429 B, Critic Model Parameters => 0.331 B\n",
        "Average reward score: -42.21875 | EMA reward score: -41.467585041181316\n",
        "-------------------------------------------------------------------------------------\n",
        "```"
      ],
      "metadata": {
        "id": "jsTWwgjxgy1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è€—æ—¶"
      ],
      "metadata": {
        "id": "P7rIr6tPS3rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "| Model Sizes                      | Step 1 | Step 2 | Step 3 | Total  |\n",
        "|--------------------------------- |:------:|:------:|:------:|:------:|\n",
        "| Actor: OPT-1.3B, Reward: OPT-350M | hr\t| hr | hr | hr |\n",
        "\n",
        "*è¡¨ 1. åœ¨å•å¡ï¼ˆV100-16Gï¼‰ï¼Œé’ˆå¯¹ä¸åŒçš„RLHFæ­¥éª¤ï¼Œ ä½¿ç”¨DeepSpeed-Chatè®­ç»ƒOPT-1.3bæ‰€éœ€çš„æ—¶é—´ã€‚*\n",
        "\n",
        "\n",
        "| Model Sizes                      | Step 1 | Step 2 | Step 3 | Total  |\n",
        "|--------------------------------- |:------:|:------:|:------:|:------:|\n",
        "| Actor: OPT-1.3B, Reward: OPT-350M | 00:51:24 hr\t| 0:23:58 hr | hr | hr |\n",
        "\n",
        "*è¡¨ 2. åœ¨å•å¡ï¼ˆA100-40Gï¼‰ï¼Œé’ˆå¯¹ä¸åŒçš„RLHFæ­¥éª¤ï¼Œ ä½¿ç”¨DeepSpeed-Chatè®­ç»ƒOPT-1.3bæ‰€éœ€çš„æ—¶é—´ã€‚*\n",
        "\n",
        "\n",
        "</div>\n",
        "\n",
        "- V100: https://images.nvidia.com/content/volta-architecture/pdf/volta-architecture-whitepaper.pdf\n",
        "- **A100**: https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf"
      ],
      "metadata": {
        "id": "QXxxzG3BSJc9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## æ€è€ƒ\n",
        "1. è¿™ä¸ªæ˜¯å•æœºè®­ç»ƒå®éªŒï¼Œæµ‹è¯•å¼€å‘è®­ç»ƒæ¨¡å‹ä½¿ç”¨ï¼Œå±äºç¦»çº¿æ•°æ®è®­ç»ƒæ¨¡å‹ï¼›å¦‚æœå·¥ç¨‹è§„èŒƒåŒ–ï¼Œéœ€è¦å¼•å…¥ç›‘æ§ï¼Œè°ƒåº¦å¼•æ“ç­‰ç­‰ï¼Œä½¿ç”¨æ²‰æ·€å¥½çš„å¼€æºåˆ†å¸ƒå¼æœºå™¨å­¦ä¹ å¹³å° [ray](https://github.com/ray-project/ray) æ¡†æ¶, [Ray: A Distributed Framework for Emerging AI Applications](https://arxiv.org/abs/1712.05889)\n",
        "2. ä»¥å¾€å¤§æ•°æ®æ—¶ä»£ï¼Œå·²ç»ç§¯ç´¯å·¥ç¨‹åŒ–å®è·µçš„å¹³å°åº•åº§ï¼›ç°åœ¨å·²ç»è¿›å…¥ç®—åŠ›æ—¶ä»£ï¼Œå¦‚ä½•åœ¨å‚ç›´é¢†åŸŸä½¿ç”¨å¥½æ•°æ®å’Œç®—åŠ›ï¼Œè®­ç»ƒ/æ¨ç†åŠ é€Ÿå’Œæ¨¡å‹æ€§èƒ½å¢å¼ºï¼Œä»¥åŠç«¯åˆ°ç«¯çš„å¿«é€Ÿæ„å»ºï¼Œé™ä½æˆæœ¬ï¼Œä½ç¢³\n",
        "3. ç›¸å…³LLMè®ºæ–‡å¾ˆå¤šï¼Œå­¦ä¹ èƒ½åŠ›éå¸¸é‡è¦å•¦ï¼Œéœ€è¦é‰´åˆ«åŸºç¡€è®ºæ–‡ï¼Œå­¦ä¼šåœ¨å·¨äººè‚©è†€ä¸Šæ€è€ƒé—®é¢˜ï¼Œä¿æŒå¥½å¥‡å¿ƒ\n",
        "4. ç®—åŠ›ç¦»ä¸å¼€åº•å±‚ç¡¬ä»¶å’Œå¯¹åº”åº“æ”¯æŒï¼Œéœ€è¦æŒæ¡å¥½è¿™äº›å·¥å…·ï¼Œç®—å­åŠ é€Ÿ\n",
        "5. å‚æ•°è°ƒè¯•æ¯”è¾ƒè€—æ—¶ï¼Œéœ€è¦ä¸€å¥—æ–¹æ³•è®º :)"
      ],
      "metadata": {
        "id": "kmCBxl4yYaSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ä¸‰ä¸ªè®­ç»ƒæ­¥éª¤\n",
        "ä¸ºäº†å®ç°æ— ç¼çš„è®­ç»ƒä½“éªŒï¼Œæˆ‘ä»¬éµå¾ª InstructGPT è®ºæ–‡çš„æ–¹æ³•ï¼Œå¹¶åœ¨ DeepSpeed-Chat ä¸­æ•´åˆäº†ä¸€ä¸ªç«¯åˆ°ç«¯çš„è®­ç»ƒæµç¨‹ï¼Œå¦‚å›¾æ‰€ç¤º:\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "![](https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/assets/image/ppo_trainer.png?raw=true)\n",
        "\n",
        "</div>\n",
        "æˆ‘ä»¬çš„æµç¨‹åŒ…æ‹¬ä¸‰ä¸ªä¸»è¦æ­¥éª¤ï¼š\n",
        "\n",
        "- æ­¥éª¤1ï¼šç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ â€”â€” ä½¿ç”¨ç²¾é€‰çš„äººç±»å›ç­”æ¥å¾®è°ƒé¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ä»¥åº”å¯¹å„ç§æŸ¥è¯¢ï¼›\n",
        "- æ­¥éª¤2ï¼šå¥–åŠ±æ¨¡å‹å¾®è°ƒ â€”â€” ä½¿ç”¨ä¸€ä¸ªåŒ…å«äººç±»å¯¹åŒä¸€æŸ¥è¯¢çš„å¤šä¸ªç­”æ¡ˆæ‰“åˆ†çš„æ•°æ®é›†æ¥è®­ç»ƒä¸€ä¸ªç‹¬ç«‹çš„ï¼ˆé€šå¸¸æ¯” SFT å°çš„ï¼‰å¥–åŠ±æ¨¡å‹ï¼ˆRWï¼‰ï¼›\n",
        "- æ­¥éª¤3ï¼šRLHF è®­ç»ƒ â€”â€” åˆ©ç”¨ Proximal Policy Optimizationï¼ˆPPOï¼‰ç®—æ³•ï¼Œæ ¹æ® RW æ¨¡å‹çš„å¥–åŠ±åé¦ˆè¿›ä¸€æ­¥å¾®è°ƒ SFT æ¨¡å‹ã€‚\n",
        "\n",
        "åœ¨æ­¥éª¤3ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªé¢å¤–çš„åŠŸèƒ½ï¼Œä»¥å¸®åŠ©æé«˜æ¨¡å‹è´¨é‡ï¼š\n",
        "\n",
        "- æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰ â€”â€” å¯ä»¥é€‰æ‹©åŸºäº EMA çš„æ£€æŸ¥ç‚¹è¿›è¡Œæœ€ç»ˆè¯„ä¼°\n",
        "- æ··åˆè®­ç»ƒ â€”â€” å°†é¢„è®­ç»ƒç›®æ ‡ï¼ˆå³ä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹ï¼‰ä¸ PPO ç›®æ ‡æ··åˆï¼Œä»¥é˜²æ­¢åœ¨åƒ SQuAD2.0 è¿™æ ·çš„å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½æŸå¤±\n",
        "\n",
        "è¿™ä¸¤ä¸ªè®­ç»ƒåŠŸèƒ½ï¼ŒEMA å’Œæ··åˆè®­ç»ƒï¼Œå¸¸å¸¸è¢«å…¶ä»–çš„å¼€æºæ¡†æ¶æ‰€å¿½ç•¥ï¼Œå› ä¸ºå®ƒä»¬å¹¶ä¸ä¼šå¦¨ç¢è®­ç»ƒçš„è¿›è¡Œã€‚ç„¶è€Œï¼Œæ ¹æ® InstructGPTï¼ŒEMA é€šå¸¸æ¯”ä¼ ç»Ÿçš„æœ€ç»ˆè®­ç»ƒæ¨¡å‹æä¾›æ›´å¥½çš„å“åº”è´¨é‡ï¼Œè€Œæ··åˆè®­ç»ƒå¯ä»¥å¸®åŠ©æ¨¡å‹ä¿æŒé¢„è®­ç»ƒåŸºå‡†è§£å†³èƒ½åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸ºç”¨æˆ·æä¾›è¿™äº›åŠŸèƒ½ï¼Œä»¥ä¾¿å……åˆ†è·å¾— InstructGPT ä¸­æè¿°çš„è®­ç»ƒä½“éªŒï¼Œå¹¶äº‰å–æ›´é«˜çš„æ¨¡å‹è´¨é‡ã€‚\n",
        "\n",
        "é™¤äº†ä¸ InstructGPT è®ºæ–‡é«˜åº¦ä¸€è‡´å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€é¡¹æ–¹ä¾¿çš„åŠŸèƒ½ï¼Œä»¥æ”¯æŒç ”ç©¶äººå‘˜å’Œä»ä¸šè€…ä½¿ç”¨å¤šä¸ªæ•°æ®èµ„æºè®­ç»ƒä»–ä»¬è‡ªå·±çš„ RLHF æ¨¡å‹ï¼š\n",
        "\n",
        "- æ•°æ®æŠ½è±¡å’Œæ··åˆèƒ½åŠ›ï¼š DeepSpeed-Chat èƒ½å¤Ÿä½¿ç”¨å¤šä¸ªä¸åŒæ¥æºçš„æ•°æ®é›†è®­ç»ƒæ¨¡å‹ä»¥è·å¾—æ›´å¥½çš„æ¨¡å‹è´¨é‡ã€‚å®ƒé…å¤‡äº†ï¼ˆ1ï¼‰ä¸€ä¸ªæŠ½è±¡æ•°æ®é›†å±‚ï¼Œä»¥ç»Ÿä¸€ä¸åŒæ•°æ®é›†çš„æ ¼å¼ï¼›ä»¥åŠï¼ˆ2ï¼‰æ•°æ®æ‹†åˆ†/æ··åˆåŠŸèƒ½ï¼Œä»¥ä¾¿å¤šä¸ªæ•°æ®é›†åœ¨ 3 ä¸ªè®­ç»ƒé˜¶æ®µä¸­è¢«é€‚å½“åœ°æ··åˆç„¶åæ‹†åˆ†ã€‚\n",
        "\n"
      ],
      "metadata": {
        "id": "iHyUd-vFSv8s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. supervised_finetuning(SFT) ç›‘ç£å¾®è°ƒ\n",
        "\n",
        "æœ‰ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰ç¡®å®åœ¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é¢†åŸŸå–å¾—äº†é‡å¤§è¿›å±•ã€‚ç„¶è€Œï¼Œè¯¸å¦‚é‡å¤å†…å®¹ç”Ÿæˆä»¥åŠå›°æƒ‘åº¦ (PPL) åˆ†æ•°ä¸ç”Ÿæˆèƒ½åŠ›ä¹‹é—´ä¸ä¸€è‡´ç­‰æ„å¤–è¡Œä¸ºä»ç„¶å¯èƒ½å‘ç”Ÿã€‚\n",
        "\n",
        "æ ¹æ®æˆ‘ä»¬çš„æµ‹è¯•ï¼Œæœ‰å‡ ä¸ªæœ¯è¯­ä¼šå½±å“ç”Ÿæˆè¡Œä¸ºï¼š\n",
        "\n",
        "- weight decayï¼šOPT æ¨¡å‹ç»è¿‡æƒé‡è¡°å‡é¢„è®­ç»ƒã€‚æ­¤åï¼Œå¾®è°ƒé€šå¸¸ä¼šç»§æ‰¿æ­¤è®¾ç½®ã€‚ä½†æ˜¯ï¼Œå®ƒå¯èƒ½æ— æ³•ç”Ÿæˆæ‰€éœ€çš„æ¨¡å‹ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬çš„ OPT-1.3B ç¤ºä¾‹ï¼Œæˆ‘ä»¬ç¦ç”¨äº†æƒé‡è¡°å‡ã€‚\n",
        "dropoutï¼šä¸ä¸Šé¢ç±»ä¼¼ï¼ŒOPTé¢„è®­ç»ƒä¸­ä½¿ç”¨äº†dropoutã€‚ç„¶è€Œï¼ŒSFTä¸ä¸€å®šéœ€è¦å®ƒã€‚ç‰¹åˆ«æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬çš„ OPT-1.3B ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯ç”¨äº† dropoutã€‚\n",
        "- datasetï¼šä½¿ç”¨æ›´å¤šæ•°æ®é€šå¸¸å¯ä»¥æä¾›æ›´å¥½çš„æ¨¡å‹è´¨é‡ã€‚ä½†å¦‚æœæ•°æ®é›†çš„æ¥æºå·®å¼‚å¤ªå¤§ï¼Œå¯èƒ½ä¼šæŸå®³æ€§èƒ½ã€‚å¯¹äºæˆ‘ä»¬çš„ OPT-1.3B ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å››ä¸ªæ•°æ®é›†\n",
        "```\n",
        "Dahoas/rm-static\n",
        "Dahoas/full-hh-rlhf\n",
        "Dahoas/synthetic-instruct-gptj-pairwise\n",
        "yitingxie/rlhf-reward-datasets\n",
        "```\n",
        "- training epochsé€šå¸¸ï¼Œä¸ºäº†é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œå¦‚æœè¾ƒå°çš„è®­ç»ƒå‘¨æœŸå¯ä»¥è¾¾åˆ°ç›¸ä¼¼çš„æ¨¡å‹è´¨é‡ï¼Œæˆ‘ä»¬ä¼šé€‰æ‹©è¾ƒå°çš„è®­ç»ƒå‘¨æœŸè€Œä¸æ˜¯è¾ƒé•¿çš„è®­ç»ƒå‘¨æœŸï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ PPL ä½œä¸ºæŒ‡æ ‡ï¼‰ã€‚ç„¶è€Œï¼Œä¸ InstructGPT æŒ‡å‡ºçš„ç±»ä¼¼ï¼Œæˆ‘ä»¬å‘ç°å³ä½¿ç”±äºè¾ƒé•¿çš„è®­ç»ƒè€Œå¯¼è‡´è¿‡åº¦æ‹Ÿåˆï¼Œä»ç„¶å»ºè®®ä½¿ç”¨è¾ƒé•¿çš„è®­ç»ƒå‘¨æœŸä»¥è·å¾—æ›´å¥½çš„ç”Ÿæˆè´¨é‡ã€‚ç‰¹åˆ«æ˜¯ï¼Œå¯¹äºæˆ‘ä»¬çš„ OPT-1.3B ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ 16 ä¸ª epochï¼Œå°½ç®¡æˆ‘ä»¬å‘ç° 1 æˆ– 2 ä¸ª epoch è®­ç»ƒå¯ä»¥è¾¾åˆ°ç›¸åŒçš„ PPL åˆ†æ•°ã€‚\n",
        "\n",
        "\n",
        "https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/README.md\n"
      ],
      "metadata": {
        "id": "Cgng2DKnTAOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move into the first step of the pipeline\n",
        "# Run the training script\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/ \\\n",
        "  && bash -x training_scripts/opt/single_gpu/run_1.3b.sh"
      ],
      "metadata": {
        "id": "R6eS0-8LTGN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/ \\\n",
        "  && bash -x evaluation_scripts/run_prompt.sh"
      ],
      "metadata": {
        "id": "rmbOTE0JTQO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. reward_model_finetuning(RM) å¥–åŠ±æ¨¡å‹å¾®è°ƒ\n",
        "\n",
        "å¥–åŠ±æ¨¡å‹ï¼ˆRMï¼‰å¾®è°ƒç¡®å®ä¸SFTç±»ä¼¼ï¼Œä¸»è¦åŒºåˆ«åœ¨äºï¼š\n",
        "1. è®­ç»ƒæ•°æ®é›†ä¸åŒâ€”â€”RMå¯¹åŒä¸€æŸ¥è¯¢æ—¢éœ€è¦å¥½çš„å“åº”ï¼Œä¹Ÿéœ€è¦åçš„å“åº”ï¼›\n",
        "2. è®­ç»ƒlossä¸åŒâ€”â€”RMéœ€è¦pairrankinglossä½œä¸ºä¼˜åŒ–ç›®æ ‡ã€‚\n",
        "\n",
        "æˆ‘ä»¬ä¸ºå¥–åŠ±æ¨¡å‹æä¾›äº†ä¸¤ä¸ªæŒ‡æ ‡ï¼š\n",
        "1. æ¥å—çš„å“åº”ï¼ˆå’Œä¸è‰¯å“åº”ï¼‰çš„å¥–åŠ±åˆ†æ•°;\n",
        "2. å‡†ç¡®æ€§ï¼Œå³å½“æ¥å—çš„å“åº”å¯ä»¥è·å¾—æ¯”æ‹’ç»çš„å“åº”æ›´é«˜çš„åˆ†æ•°æ—¶ã€‚\n",
        "\n",
        "æœ‰æ—¶ï¼Œæˆ‘ä»¬è§‚å¯Ÿåˆ°å‡†ç¡®æ€§éå¸¸é«˜ï¼Œä½†æ¥å—ç­”æ¡ˆçš„å¹³å‡å¥–åŠ±åˆ†æ•°ä¸ºè´Ÿï¼Œæˆ–è€…æ‹’ç»ç­”æ¡ˆçš„åˆ†æ•°ä¸æ¥å—ç­”æ¡ˆç›¸ä¼¼ã€‚è¿™ä¼šå½±å“ç¬¬ 3 æ­¥æ¨¡å‹çš„è´¨é‡å—ï¼Ÿå¦‚æœæˆ‘ä»¬åœ¨ç¬¬ 3 æ­¥ä¸­ä½¿ç”¨åº¦é‡å¥–åŠ±åˆ†æ•°å¢ç›Šï¼Œè¿™å¯èƒ½ä¸ä¼šæœ‰ä»»ä½•é—®é¢˜ã€‚ç„¶è€Œï¼Œè¿™ä¸ªæœºå™¨å­¦ä¹ æŒ‡æ ‡ï¼ˆå¥–åŠ±åˆ†æ•°å¢ç›Š/å¢åŠ ï¼‰å¹¶ä¸èƒ½çœŸæ­£åæ˜ step-3æ¨¡å‹ç”Ÿæˆçš„è´¨é‡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬è¿˜æ²¡æœ‰æ˜ç¡®çš„ç­”æ¡ˆã€‚\n",
        "\n",
        "åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬åˆ†äº«æ›´å¤šå…³äºæˆ‘ä»¬åœ¨æ¢ç´¢è¿‡ç¨‹ä¸­è§‚å¯Ÿåˆ°çš„æƒ…å†µï¼š\n",
        "\n",
        "- weight decayï¼šå¯¹äºæˆ‘ä»¬çš„ OPT-350m ç¤ºä¾‹ï¼Œæˆ‘ä»¬å¯ç”¨äº† 0.1 çš„æƒé‡è¡°å‡ã€‚\n",
        "- dropoutï¼šå¯¹äºæˆ‘ä»¬çš„ OPT-350m ç¤ºä¾‹ï¼Œæˆ‘ä»¬ç¦ç”¨äº† dropoutã€‚\n",
        "- datasetï¼šå¯¹äºæˆ‘ä»¬çš„ OPT-350m ç¤ºä¾‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å››ä¸ªæ•°æ®é›†ï¼š\n",
        "  - Dahoas/rm-static\n",
        "  - Dahoas/full-hh-rlhf\n",
        "  - Dahoas/synthetic-instruct-gptj-pairwise\n",
        "  - yitingxie/rlhf-reward-datasets\n",
        "- training epochsInstructGPT å»ºè®®å¯¹æ¨¡å‹è¿›è¡Œ 1 epoch çš„å¾®è°ƒï¼Œå› ä¸ºè¿‡åº¦æ‹Ÿåˆä¼šæŸå®³ç¬¬ 3 æ­¥çš„æ€§èƒ½ã€‚åœ¨æˆ‘ä»¬çš„æ¢ç´¢è¿‡ç¨‹ä¸­ï¼Œå½“æˆ‘ä»¬å¢åŠ è®­ç»ƒå‘¨æœŸæ—¶ï¼Œæˆ‘ä»¬æ²¡æœ‰çœ‹åˆ°è¿‡åº¦æ‹Ÿåˆè¡Œä¸ºã€‚ä½†æ˜¯ï¼Œè¯·éµå¾ªä½œè€…çš„æŒ‡ç¤ºã€‚æˆ‘ä»¬å°†è®­ç»ƒçºªå…ƒè®¾ç½®ä¸º 1ã€‚\n",
        "\n",
        "æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œæä¾›äº†æ›´å¤šçš„æ¢ç´¢ï¼Œå³ä½¿æˆ‘ä»¬æ²¡æœ‰å°†å®ƒä»¬è®¾ç½®ä¸ºé€‰é¡¹æˆ–å°†å®ƒä»¬åŒ…å«åœ¨æˆ‘ä»¬å½“å‰çš„ç®¡é“ä¸­\n",
        "- multiple answers for one promptåœ¨ InstructGPT ä¸­ï¼Œä½œè€…ç‰¹åˆ«æåˆ°ï¼Œå¯¹ä¸€ä¸ªæç¤ºä½¿ç”¨é…å¯¹çš„æ‹’ç»å’Œæ¥å—ç­”æ¡ˆä¸é€‚åˆå¥–åŠ±æ¨¡å‹è®­ç»ƒã€‚å› æ­¤ï¼ŒInstructGPT ä¼šæ ¹æ®æ¯ä¸ªæç¤ºæ„å»ºåŒ…å« 4--9 ä¸ªç­”æ¡ˆçš„æ•°æ®é›†ã€‚ç„¶è€Œï¼Œæˆ‘ä»¬æ²¡æœ‰æ‰¾åˆ°å…·æœ‰æ­¤åŠŸèƒ½çš„è‰¯å¥½æ•°æ®é›†ã€‚\n",
        "- initialize RM with SFT or Pretrained checkpointæˆ‘ä»¬å¯¹æ­¤è¿›è¡Œäº†å†…éƒ¨æµ‹è¯•ï¼Œä½†æ²¡æœ‰å‘ç°å‡†ç¡®æ€§æˆ–å¥–åŠ±åˆ†æ•°æœ‰å¾ˆå¤§å·®å¼‚ã€‚æ­¤å¤–ï¼Œåœ¨ InstructGPT ä¸­ï¼Œä½œè€…ä¹Ÿæœ‰ç›¸åŒçš„å‘ç°ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬é¼“åŠ±ç”¨æˆ·å°è¯•è‡ªå·±ä½¿ç”¨ã€‚\n",
        "- Reward score calculationæˆ‘ä»¬ä½¿ç”¨æœ€ç»ˆä»¤ç‰Œï¼ˆæˆ–ç¬¬ä¸€ä¸ªå¡«å……ä»¤ç‰Œï¼‰æ¥è·å¾—å¥–åŠ±åˆ†æ•°ã€‚ç„¶è€Œï¼Œè¿™å¯èƒ½ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚ä¾‹å¦‚ï¼Œç”¨æˆ·å¯ä»¥å°è¯•æ•´ä¸ªç­”æ¡ˆçš„å¹³å‡åˆ†ç­‰ã€‚\n",
        "- Reward loss objectiveæˆ‘ä»¬åªæ˜¯ä½¿ç”¨æ’åæŸå¤±ä½œä¸ºç›®æ ‡ã€‚ç„¶è€Œï¼Œå…¶ä»–çš„ï¼Œæ¯”å¦‚ MSEï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸€ä¸ªé€‰æ‹©ã€‚\n",
        "\n",
        "\n",
        "https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/README.md"
      ],
      "metadata": {
        "id": "R7Cjv9LrTjFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move into the second step of the pipeline\n",
        "# Run the training script\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/ \\\n",
        "  && bash -x training_scripts/opt/single_gpu/run_350m.sh"
      ],
      "metadata": {
        "id": "up8ecyNiUZOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/training/step2_reward_model_finetuning/ \\\n",
        "  && bash -x evaluation_scripts/run_eval.sh"
      ],
      "metadata": {
        "id": "OOTaVrH5UgVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. rlhf_finetuning åˆ©ç”¨äººç±»åé¦ˆè¿›è¡Œå¼ºåŒ–å­¦ä¹ \n",
        "\n",
        "RLHF å¾®è°ƒæ˜¯ä¸‰æ­¥è®­ç»ƒä¸­æœ€å¤æ‚çš„ä¸€æ­¥ã€‚ä¸SFTç±»ä¼¼ï¼Œå¥–åŠ±åˆ†æ•°å¹¶ä¸èƒ½çœŸæ­£åæ˜ æ¨¡å‹ç”Ÿæˆçš„è´¨é‡ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬æœ‰æ—¶ä¼šè§‚å¯Ÿåˆ°å¥–åŠ±åˆ†æ•°åœ¨æŸä¸ªç‚¹ä¸‹é™åˆ°åˆå§‹é˜¶æ®µï¼Œç„¶åè¿…é€Ÿæ¢å¤ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œæˆ‘ä»¬è¿˜çœ‹åˆ°è®­ç»ƒå¾ˆå®¹æ˜“å‡ºç°å‘æ•£ã€‚æˆ‘ä»¬åœ¨è¿™é‡Œåˆ†äº«æˆ‘ä»¬çš„è®¾ç½®å’Œè§‚å¯Ÿã€‚\n",
        "\n",
        "- weight decayï¼šå¯¹äºæˆ‘ä»¬çš„ OPT-1.3B/350mï¼ˆæ¼”å‘˜/è¯„è®ºå®¶ï¼‰ç¤ºä¾‹ï¼Œæˆ‘ä»¬ç¦ç”¨äº†ä¸¤ä¸ªæ¨¡å‹çš„æƒé‡è¡°å‡ã€‚\n",
        "- dropoutï¼šæˆ‘ä»¬ç¦ç”¨äº† OPT-1.3B çš„ droppoutï¼Œå¹¶å¯ç”¨äº† OPT-350mã€‚\n",
        "- datasetï¼šæˆ‘ä»¬ä½¿ç”¨ä»¥ä¸‹å•ä¸ªæ•°æ®é›†ï¼šDahoas/rm-staticã€‚\n",
        "- training epochså¥–åŠ±åˆ†æ•°å¾ˆå¿«å°±ä¼šå˜å¾—å¹³åº¸ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å°† OPT-1.3B/350mï¼ˆæ¼”å‘˜/è¯„è®ºå®¶ï¼‰ç¤ºä¾‹çš„è®­ç»ƒçºªå…ƒè®¾ç½®ä¸º 1ã€‚ç„¶è€Œï¼Œæ›´é•¿çš„è®­ç»ƒå¯èƒ½ä¼šåƒ SFT ä¸€æ ·å¸¦æ¥æ›´å¥½çš„æ¨¡å‹è´¨é‡ã€‚\n",
        "- ema checkpointæˆ‘ä»¬è§‚å¯Ÿåˆ° ema æ£€æŸ¥ç‚¹é€šå¸¸å¯ä»¥å¸¦æ¥æ›´å¥½çš„æ¨¡å‹ç”Ÿæˆè´¨é‡ï¼Œå¦‚ InstructGPT ä¸­æ‰€è¿°ã€‚\n",
        "- PPO related hyperparametersPPOè®­ç»ƒæœ‰å¾ˆå¤šè¶…å‚æ•°ã€‚ç›®å‰ï¼Œæˆ‘ä»¬ä¸ºç”¨æˆ·å¯¹å®ƒä»¬è¿›è¡Œäº†ç¡¬ç¼–ç ï¼Œä½†æ‚¨å¯èƒ½éœ€è¦æ ¹æ®è‡ªå·±çš„ä½¿ç”¨æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚\n",
        "- mix unsupervised trainingInstructGPT å»ºè®®æ··åˆ PPO å’Œæ— ç›‘ç£è®­ç»ƒï¼Œä»¥é˜²æ­¢æ¨¡å‹åŸºå‡†è´¨é‡çš„æŸå¤±ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬ç›´æ¥åº”ç”¨ Instruct ä¸­çš„è¶…å‚æ•°æ—¶ï¼Œæ¨¡å‹æ— æ³•æ”¶æ•›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åœæ­¢å¯¹æ­¤è¿›è¡Œæ¢ç´¢ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬é¼“åŠ±ç”¨æˆ·å¯¹å…¶è¿›è¡Œæµ‹è¯•å¹¶æ ¹æ®è‡ªå·±çš„ä½¿ç”¨æƒ…å†µè°ƒæ•´è¶…å‚æ•°ã€‚\n",
        "- diverging issueæˆ‘ä»¬å‘ç°ä½¿ç”¨ä¸åŒçš„ç”Ÿæˆè®­ç»ƒæ‰¹é‡å¤§å° ( --per_device_generation_batch_size) å’Œ PPO è®­ç»ƒæ‰¹é‡å¤§å° ( --per_device_training_batch_size)ã€è¶…è¿‡ä¸€ä¸ª PPO è®­ç»ƒå‘¨æœŸ ( --ppo_epochs) æˆ–è¶…è¿‡ä¸€ä¸ªç”Ÿæˆæ‰¹é‡ ( --generation_batches 1) æ˜¯éå¸¸ä¸ç¨³å®šçš„ã€‚è¿™äº›éƒ½æŒ‡å‘åŒä¸€ä¸ªé—®é¢˜ï¼šæˆ‘ä»¬æ— æ³•åœ¨ç”Ÿæˆå®éªŒæ•°æ®åå¤šæ¬¡æ›´æ–°å‚ä¸è€…æ¨¡å‹ã€‚å› æ­¤ï¼Œåœ¨æˆ‘ä»¬æ‰€æœ‰æˆåŠŸçš„è¿è¡Œä¸­ï¼Œæˆ‘ä»¬éƒ½è®¾ç½®äº†per_device_generation_batch_size=per_device_training_batch_sizeå’Œppo_epochs=generation_batches=1ã€‚è¿™å¯¹äºæ ‡å‡†å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹æ¥è¯´æ˜¯æ„æƒ³ä¸åˆ°çš„ï¼Œæˆ‘ä»¬å°è¯•äº†ä¸åŒçš„æ–¹æ³•æ¥å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œä½†éƒ½å¤±è´¥äº†ã€‚é€ æˆè¿™ç§ä¸ç¨³å®šçš„æœ€å¯èƒ½åŸå› ä¹‹ä¸€æ˜¯æˆ‘ä»¬å‘ç°å‡½æ•°ä¸­ä½¿ç”¨çš„log_probså’Œå³ä½¿åœ¨è¿ç»­ä¸¤æ¬¡è¿­ä»£å†…ä¹Ÿä¼šå¾ˆå¿«å‘æ•£ï¼Œè¿™å¯¼è‡´å¯¹åº”çš„å€¼å¾ˆå¤§ã€‚è®¾ç½®ä¸¥æ ¼çš„ä¸Šç•Œå¯ä»¥ç¼“è§£è¿™ä¸ªé—®é¢˜ï¼Œä½†å¹¶ä¸èƒ½å®Œå…¨è§£å†³æ”¶æ•›é—®é¢˜ã€‚old_log_probsactor_loss_fnratio\n",
        "\n",
        "\n",
        "https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/README.md\n",
        "\n",
        "\n",
        "RLHF: Reinforcement Learning with Human Feedback\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "![](https://github.com/microsoft/DeepSpeedExamples/blob/master/applications/DeepSpeed-Chat/assets/image/ppo_trainer.png?raw=true)\n",
        "\n",
        "</div>\n",
        "\n",
        "åœ¨æ­¥éª¤3ä¸­ï¼Œæˆ‘ä»¬æä¾›äº†ä¸¤ä¸ªé¢å¤–çš„åŠŸèƒ½ï¼Œä»¥å¸®åŠ©æé«˜æ¨¡å‹è´¨é‡ï¼š\n",
        "\n",
        "- æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰ â€”â€” å¯ä»¥é€‰æ‹©åŸºäº EMA çš„æ£€æŸ¥ç‚¹è¿›è¡Œæœ€ç»ˆè¯„ä¼°\n",
        "- æ··åˆè®­ç»ƒ â€”â€” å°†é¢„è®­ç»ƒç›®æ ‡ï¼ˆå³ä¸‹ä¸€ä¸ªå•è¯é¢„æµ‹ï¼‰ä¸ PPO ç›®æ ‡æ··åˆï¼Œä»¥é˜²æ­¢åœ¨åƒ SQuAD2.0 è¿™æ ·çš„å…¬å¼€åŸºå‡†æµ‹è¯•ä¸­çš„æ€§èƒ½æŸå¤±\n",
        "\n",
        "è¿™ä¸¤ä¸ªè®­ç»ƒåŠŸèƒ½ï¼ŒEMA å’Œæ··åˆè®­ç»ƒï¼Œå¸¸å¸¸è¢«å…¶ä»–çš„å¼€æºæ¡†æ¶æ‰€å¿½ç•¥ï¼Œå› ä¸ºå®ƒä»¬å¹¶ä¸ä¼šå¦¨ç¢è®­ç»ƒçš„è¿›è¡Œã€‚ç„¶è€Œï¼Œæ ¹æ® InstructGPTï¼ŒEMA é€šå¸¸æ¯”ä¼ ç»Ÿçš„æœ€ç»ˆè®­ç»ƒæ¨¡å‹æä¾›æ›´å¥½çš„å“åº”è´¨é‡ï¼Œè€Œæ··åˆè®­ç»ƒå¯ä»¥å¸®åŠ©æ¨¡å‹ä¿æŒé¢„è®­ç»ƒåŸºå‡†è§£å†³èƒ½åŠ›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¸ºç”¨æˆ·æä¾›è¿™äº›åŠŸèƒ½ï¼Œä»¥ä¾¿å……åˆ†è·å¾— InstructGPT ä¸­æè¿°çš„è®­ç»ƒä½“éªŒï¼Œå¹¶äº‰å–æ›´é«˜çš„æ¨¡å‹è´¨é‡ã€‚\n",
        "\n",
        "ä½œä¸ºæ•´ä¸ª 3 æ­¥ InstructGPT ç®¡é“ä¸­æœ€å¤æ‚çš„ä¸€æ­¥ï¼ŒDeepSpeed Chat çš„æ··åˆå¼•æ“å®ç°äº†è¶³å¤Ÿçš„åŠ é€Ÿï¼Œä»¥é¿å…å¤§é‡çš„è®­ç»ƒæ—¶é—´ï¼ˆæˆæœ¬ï¼‰å½±å“ã€‚å¦‚æœå·²ç»æœ‰äº†ç»è¿‡å¾®è°ƒçš„å‚ä¸è€…å’Œå¥–åŠ±æ¨¡å‹æ£€æŸ¥ç‚¹ckptï¼Œåˆ™åªéœ€è¿è¡Œä»¥ä¸‹è„šæœ¬å³å¯å¯ç”¨ PPO è®­ç»ƒã€‚\n",
        "\n"
      ],
      "metadata": {
        "id": "1i9mW3KmTvjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move into the final step of the pipeline\n",
        "# Run the training script\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/training/step3_rlhf_finetuning/ \\\n",
        "  && bash -x training_scripts/opt/single_gpu/run_1.3b.sh"
      ],
      "metadata": {
        "id": "5Oe_BzmPUW5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeepSpeed Hybrid Engine â€”â€” ç»Ÿä¸€çš„é«˜æ•ˆæ··åˆå¼•æ“ï¼Œä¸º RLHF è®­ç»ƒæä¾›åŠ¨åŠ›å¹¶è¿›è¡Œä¼˜åŒ–\n",
        "\n",
        "DeepSpeed-Chatæµç¨‹çš„å‰ä¸¤æ­¥ä¸å¤§å‹æ¨¡å‹çš„å¸¸è§„å¾®è°ƒç›¸ä¼¼ï¼Œå¾—ç›ŠäºåŸºäº[ZeROçš„å†…å­˜ç®¡ç†ä¼˜åŒ– ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/abs/1910.02054)å’ŒDeepSpeedè®­ç»ƒä¸­çš„å¹¶è¡Œç­–ç•¥çµæ´»ç»„åˆï¼Œå®ç°äº†è§„æ¨¡å’Œé€Ÿåº¦çš„æå‡ã€‚ç„¶è€Œï¼Œæµç¨‹çš„ç¬¬ä¸‰æ­¥åœ¨æ€§èƒ½æ–¹é¢æ˜¯æœ€å…·æŒ‘æˆ˜æ€§çš„éƒ¨åˆ†ã€‚æ¯æ¬¡è¿­ä»£éƒ½éœ€è¦é«˜æ•ˆå¤„ç†ä¸¤ä¸ªé˜¶æ®µï¼š\n",
        "1. ç”Ÿæˆå›ç­”çš„æ¨ç†é˜¶æ®µï¼Œä¸ºè®­ç»ƒæä¾›è¾“å…¥ï¼›\n",
        "2. æ›´æ–° actor å’Œ reward æ¨¡å‹æƒé‡çš„è®­ç»ƒé˜¶æ®µï¼Œä»¥åŠå®ƒä»¬ä¹‹é—´çš„äº¤äº’å’Œè°ƒåº¦ã€‚\n",
        "\n",
        "è¿™å¼•å…¥äº†ä¸¤ä¸ªä¸»è¦å›°éš¾ï¼š\n",
        "1. å†…å­˜æˆæœ¬ï¼Œå› ä¸ºåœ¨ç¬¬ä¸‰é˜¶æ®µçš„æ•´ä¸ªè¿‡ç¨‹ä¸­éœ€è¦è¿è¡Œå¤šä¸ªSFTå’ŒRWæ¨¡å‹ï¼›\n",
        "2. ç”Ÿæˆå›ç­”é˜¶æ®µçš„é€Ÿåº¦è¾ƒæ…¢ï¼Œå¦‚æœæ²¡æœ‰æ­£ç¡®åŠ é€Ÿï¼Œå°†æ˜¾è‘—æ‹–æ…¢æ•´ä¸ªç¬¬ä¸‰é˜¶æ®µã€‚\n",
        "\n",
        "æ­¤å¤–ï¼Œæˆ‘ä»¬åœ¨ç¬¬ä¸‰é˜¶æ®µä¸­æ·»åŠ çš„ä¸¤ä¸ªé‡è¦å¯é€‰åŠŸèƒ½ï¼ŒåŒ…æ‹¬æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼ˆEMAï¼‰æ”¶é›†å’Œæ··åˆè®­ç»ƒï¼Œå°†äº§ç”Ÿé¢å¤–çš„å†…å­˜å’Œè®­ç»ƒæˆæœ¬ã€‚\n",
        "\n",
        "ä¸ºäº†åº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œæˆ‘ä»¬**å°†DeepSpeedè®­ç»ƒå’Œæ¨ç†çš„ç³»ç»ŸåŠŸèƒ½æ•´åˆä¸ºä¸€ä¸ªç»Ÿä¸€çš„åŸºç¡€è®¾æ–½ï¼Œç§°ä¸ºæ··åˆå¼•æ“ï¼ˆHybrid Engineï¼‰**ã€‚å®ƒåˆ©ç”¨åŸå§‹DeepSpeedå¼•æ“è¿›è¡Œé«˜é€Ÿè®­ç»ƒæ¨¡å¼ï¼ŒåŒæ—¶è½»æ¾åº”ç”¨DeepSpeedæ¨ç†å¼•æ“è¿›è¡Œç”Ÿæˆ/è¯„ä¼°æ¨¡å¼ï¼Œä¸ºç¬¬ä¸‰é˜¶æ®µçš„RLHFè®­ç»ƒæä¾›äº†ä¸€ä¸ªæ˜æ˜¾æ›´å¿«çš„è®­ç»ƒç³»ç»Ÿã€‚\n",
        "\n",
        "å¦‚å›¾2æ‰€ç¤ºï¼ŒDeepSpeedè®­ç»ƒå’Œæ¨ç†å¼•æ“ä¹‹é—´çš„è¿‡æ¸¡æ˜¯æ— ç¼çš„ï¼šé€šè¿‡ä¸ºactoræ¨¡å‹å¯ç”¨å…¸å‹çš„evalå’Œtrainæ¨¡å¼ï¼Œå½“è¿è¡Œæ¨ç†å’Œè®­ç»ƒæµç¨‹æ—¶ï¼ŒDeepSpeedé€‰æ‹©å…¶ä¸åŒçš„ä¼˜åŒ–æ¥è¿è¡Œæ¨¡å‹æ›´å¿«å¹¶æé«˜æ•´ä¸ªç³»ç»Ÿååé‡ã€‚\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "<img src=\"https://github.com/microsoft/DeepSpeed/blob/master/blogs/assets/images/hybrid-engine.png?raw=true\" width=\"600px\" alt=\"DeepSpeed-Chat!\"/>\n",
        "\n",
        "*Figure 2. è®¾è®¡å›¾è§£ï¼šDeepSpeed Hybrid Engineï¼Œç”¨äºåŠ é€Ÿ RLHF æµç¨‹ä¸­æœ€è€—æ—¶çš„éƒ¨åˆ†ã€‚*\n",
        "\n",
        "</div>\n",
        "\n",
        "åœ¨RLHFè®­ç»ƒçš„ç»éªŒç”Ÿæˆé˜¶æ®µçš„æ¨ç†æ‰§è¡Œè¿‡ç¨‹ä¸­ï¼ŒDeepSpeedæ··åˆå¼•æ“ä½¿ç”¨è½»é‡çº§å†…å­˜ç®¡ç†ç³»ç»Ÿæ¥å¤„ç†KVç¼“å­˜å’Œä¸­é—´ç»“æœï¼ŒåŒæ—¶ä½¿ç”¨é«˜åº¦ä¼˜åŒ–çš„æ¨ç†CUDAæ ¸å’Œå¼ é‡å¹¶è¡Œè®¡ç®—ã€‚ä¸ç°æœ‰è§£å†³æ–¹æ¡ˆç›¸æ¯”ï¼ŒDeepSpeed-HEæ˜¾è‘—æé«˜äº†ååé‡ï¼ˆæ¯ç§’tokenæ•°ï¼‰ã€‚\n",
        "\n",
        "åœ¨è®­ç»ƒæ‰§è¡Œè¿‡ç¨‹ä¸­ï¼Œæ··åˆå¼•æ“ä½¿ç”¨äº†å¤šç§å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œå¦‚DeepSpeedçš„ZeROç³»åˆ—æŠ€æœ¯å’Œç°åœ¨æµè¡Œçš„LoRAæ–¹æ³•ã€‚è¿™äº›æŠ€æœ¯åœ¨æ··åˆå¼•æ“ä¸­å¯ä»¥å½¼æ­¤å…¼å®¹ï¼Œå¹¶å¯ä»¥ç»„åˆåœ¨ä¸€èµ·ä»¥æä¾›æœ€é«˜è®­ç»ƒæ•ˆç‡ã€‚\n",
        "\n",
        "DeepSpeed-HEå¯ä»¥åœ¨è®­ç»ƒå’Œæ¨ç†ä¹‹é—´æ— ç¼æ›´æ”¹æ¨¡å‹åˆ†åŒºï¼Œä»¥æ”¯æŒåŸºäºå¼ é‡å¹¶è¡Œè®¡ç®—çš„æ¨ç†å’ŒåŸºäºZeROçš„åˆ†ç‰‡æœºåˆ¶è¿›è¡Œè®­ç»ƒã€‚å®ƒè¿˜ä¼šé‡æ–°é…ç½®å†…å­˜ç³»ç»Ÿä»¥åœ¨æ­¤æœŸé—´æœ€å¤§åŒ–å†…å­˜å¯ç”¨æ€§ã€‚DeepSpeed-HEè¿˜é€šè¿‡è§„é¿å†…å­˜åˆ†é…ç“¶é¢ˆå’Œæ”¯æŒå¤§æ‰¹é‡å¤§å°æ¥è¿›ä¸€æ­¥æé«˜æ€§èƒ½ã€‚æ··åˆå¼•æ“é›†æˆäº†DeepSpeedè®­ç»ƒå’Œæ¨ç†çš„ä¸€ç³»åˆ—ç³»ç»ŸæŠ€æœ¯ï¼Œçªç ´äº†ç°æœ‰RLHFè®­ç»ƒçš„æé™ï¼Œå¹¶ä¸ºRLHFå·¥ä½œè´Ÿè½½æä¾›äº†æ— ä¸ä¼¦æ¯”çš„è§„æ¨¡å’Œç³»ç»Ÿæ•ˆç‡ã€‚\n",
        "\n",
        "å‚è€ƒï¼š\n",
        "- [**ZeRO: Memory Optimizations Toward Training Trillion Parameter Models**](https://arxiv.org/abs/1910.02054)\n",
        "- [**LoRA: Low-Rank Adaptation of Large Language Models**](https://arxiv.org/abs/2106.09685)"
      ],
      "metadata": {
        "id": "glG-zXWyI8Lp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inference æ¨¡å‹æ¨ç†"
      ],
      "metadata": {
        "id": "mT9YkXAx3mbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# serve the final model\n",
        "!cd DeepSpeedExamples/applications/DeepSpeed-Chat/ && python chat.py --path  ${PATH-to-your-actor-model}\n"
      ],
      "metadata": {
        "id": "Ca3y9yjM3rgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# more\n",
        "\n",
        "RLHFï¼ˆäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼‰è®­ç»ƒä»ç„¶æ˜¯ä¸€ä¸ªæ‚¬è€Œæœªå†³çš„é—®é¢˜ï¼Œè€Œ DeepSpeed-Chat æ—¨åœ¨æˆä¸ºç ”ç©¶äººå‘˜å’Œä»ä¸šè€…ä»¥é«˜æ•ˆã€å¿«é€Ÿçš„è®­ç»ƒä½“éªŒè¿›è¡Œç ”ç©¶çš„èµ·ç‚¹ã€‚æ··åˆå¼•æ“å’Œå…¶ä»–é«˜æ•ˆç»„ä»¶ï¼ˆä¾‹å¦‚ LoRAï¼‰å¯ä»¥ä» DeepSpeed-Chat ç»§æ‰¿ï¼Œä½¿æ‚¨èƒ½å¤Ÿå¼€å‘è‡ªå·±çš„ RLHF è®­ç»ƒç®¡é“ï¼Œç”¨äºæ¢ç´¢ã€ç ”ç©¶å’Œå…¶ä»–ç›®çš„ã€‚\n",
        "\n"
      ],
      "metadata": {
        "id": "Wbf7YKcclXRJ"
      }
    }
  ]
}