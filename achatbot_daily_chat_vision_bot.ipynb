{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/PZiBOvadrHcb+C3JlR+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/achatbot_daily_chat_vision_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTOZMjbnUZyM"
      },
      "outputs": [],
      "source": [
        "!cd /content && rm -rf achatbot && git clone --recursive https://github.com/ai-bot-pro/achatbot.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot"
      ],
      "metadata": {
        "id": "jj-NSzY1U_p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/pypi_achatbot.sh dev"
      ],
      "metadata": {
        "id": "nesIRk-jVKsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.7.2-py3-none-any.whl[daily_room_audio_stream,livekit,livekit-api,sense_voice_asr,deepgram_asr_processor,llm_transformers_manual_vision,tts_edge,openai,queue]\""
      ],
      "metadata": {
        "id": "1U0Zy_vGVUPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download FunAudioLLM/SenseVoiceSmall  --local-dir ./models/FunAudioLLM/SenseVoiceSmall --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "4--WNqx8VpUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download Qwen/Qwen2-VL-2B-Instruct --local-dir ./models/Qwen/Qwen2-VL-2B-Instruct --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "QNh_N0AeVsmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download Qwen/Qwen2-VL-7B-Instruct --local-dir ./models/Qwen/Qwen2-VL-7B-Instruct --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "1i_8aDZQx-dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download unsloth/Llama-3.2-11B-Vision-Instruct --local-dir ./models/unsloth/Llama-3.2-11B-Vision-Instruct --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "0BtNGMtGyE0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhPOa8RBb0dS"
      },
      "source": [
        "run bot task woker with bot.json, e.g.: dummy_bot.json\n",
        "\n",
        "- use daily/livekit room stream, u can click bot joined the room url, to start chat with bot with audio and camera stream,\n",
        "  - [daily](https://www.daily.co/) need DAILY_API_KEY\n",
        "  - [livekit](https://livekit.io/) need project url LIVEKIT_URL, LIVEKIT_API_KEY, LIVEKIT_API_SECRET\n",
        "- use openai/groq/together.ai api llm model need api key\n",
        "  - [openai](https://openai.com/) OPENAI_API_KEY\n",
        "  - [groq](https://groq.com/) GROQ_API_KEY\n",
        "  - [together.ai](https://www.together.ai/) TOGETHER_API_KEY\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DAILY_API_KEY=userdata.get('DAILY_API_KEY')\n",
        "\n",
        "LIVEKIT_URL=userdata.get('LIVEKIT_URL')\n",
        "LIVEKIT_API_KEY=userdata.get('LIVEKIT_API_KEY')\n",
        "LIVEKIT_API_SECRET=userdata.get('LIVEKIT_API_SECRET')\n",
        "\n",
        "TOGETHER_API_KEY=userdata.get('TOGETHER_API_KEY')\n",
        "\n",
        "DEEPGRAM_API_KEY=userdata.get('DEEPGRAM_API_KEY')\n"
      ],
      "metadata": {
        "id": "uXIAi2IYUkcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/daily_chat_transformers_vision_bot.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpESnKKg2VNb",
        "outputId": "bd0113f1-2d96-4152-8836-53bed528a1a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chat_bot_name\": \"DailyChatVisionBot\",\n",
            "  \"room_name\": \"chat-bot\",\n",
            "  \"room_url\": \"\",\n",
            "  \"token\": \"\",\n",
            "  \"services\": {\n",
            "    \"pipeline\": \"achatbot\",\n",
            "    \"vad\": \"silero\",\n",
            "    \"asr\": \"sense_voice\",\n",
            "    \"llm\": \"groq\",\n",
            "    \"vision_llm\": \"transformers_manual_vision_qwen\",\n",
            "    \"tts\": \"edge\"\n",
            "  },\n",
            "  \"config\": {\n",
            "    \"vad\": {\n",
            "      \"tag\": \"silero_vad_analyzer\",\n",
            "      \"args\": { \"stop_secs\": 0.7 }\n",
            "    },\n",
            "    \"asr\": {\n",
            "      \"tag\": \"deepgram_asr_processor\",\n",
            "      \"args\": {\n",
            "        \"language\": \"zh\",\n",
            "        \"model\": \"nova-2\"\n",
            "      }\n",
            "    },\n",
            "    \"llm\": {\n",
            "      \"tag\": \"openai_llm_processor\",\n",
            "      \"base_url\": \"https://api.together.xyz/v1\",\n",
            "      \"model\": \"Qwen/Qwen2-72B-Instruct\",\n",
            "      \"language\": \"zh\",\n",
            "      \"messages\": [\n",
            "        {\n",
            "          \"role\": \"system\",\n",
            "          \"content\": \"你是一个叫奥利给的助理，老板的得力助手。你可以问我任何问题。保持回答简短和清晰。请用中文回答。如果用户问你请'描述下你看到的'，请直接回答'奥利给。'。\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"vision_llm\": {\n",
            "      \"tag\": \"llm_transformers_manual_vision_qwen\",\n",
            "      \"args\": {\n",
            "        \"lm_device\": \"cuda\",\n",
            "        \"lm_model_name_or_path\": \"./models/Qwen/Qwen2-VL-2B-Instruct\",\n",
            "        \"chat_history_size\": 0,\n",
            "        \"init_chat_prompt\": \"请用中文交流\",\n",
            "        \"model_type\": \"chat_completion\"\n",
            "      },\n",
            "      \"language\": \"zh\"\n",
            "    },\n",
            "    \"tts\": {\n",
            "      \"tag\": \"tts_edge\",\n",
            "      \"args\": {\n",
            "        \"voice_name\": \"zh-CN-YunjianNeural\",\n",
            "        \"language\": \"zh\",\n",
            "        \"gender\": \"Male\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"config_list\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKB146E-b9s_"
      },
      "outputs": [],
      "source": [
        "!DAILY_API_KEY=$DAILY_API_KEY TOGETHER_API_KEY=$TOGETHER_API_KEY DEEPGRAM_API_KEY=$DEEPGRAM_API_KEY \\\n",
        "  python -m src.cmd.bots.main -f /content/daily_chat_transformers_vision_bot.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/livekit_chat_transformers_vision_bot.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj6cgUWd2aYu",
        "outputId": "5b49608b-42f8-4822-a573-c2e1d56ee9de"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"chat_bot_name\": \"LivekitChatVisionBot\",\n",
            "  \"room_name\": \"chat-bot\",\n",
            "  \"room_url\": \"\",\n",
            "  \"token\": \"\",\n",
            "  \"room_manager\": {\n",
            "    \"tag\": \"livekit_room\",\n",
            "    \"args\": {\n",
            "      \"bot_name\": \"LivekitChatVisionBot\",\n",
            "      \"is_common_session\": false\n",
            "    }\n",
            "  },\n",
            "  \"services\": {},\n",
            "  \"config\": {\n",
            "    \"vad\": {\n",
            "      \"tag\": \"silero_vad_analyzer\",\n",
            "      \"args\": { \"stop_secs\": 0.7 }\n",
            "    },\n",
            "    \"asr\": {\n",
            "      \"tag\": \"sense_voice_asr\",\n",
            "      \"args\": {\n",
            "        \"language\": \"zn\",\n",
            "        \"model_name_or_path\": \"./models/FunAudioLLM/SenseVoiceSmall\"\n",
            "      }\n",
            "    },\n",
            "    \"llm\": {\n",
            "      \"tag\": \"openai_llm_processor\",\n",
            "      \"base_url\": \"https://api.together.xyz/v1\",\n",
            "      \"model\": \"Qwen/Qwen2-72B-Instruct\",\n",
            "      \"language\": \"zh\",\n",
            "      \"messages\": [\n",
            "        {\n",
            "          \"role\": \"system\",\n",
            "          \"content\": \"你是一个叫奥利给的助理，老板的得力助手。你可以问我任何问题。保持回答简短和清晰。请用中文回答。如果用户问你请'描述下你看到的'，请直接回答'奥利给。'。\"\n",
            "        }\n",
            "      ]\n",
            "    },\n",
            "    \"vision_llm\": {\n",
            "      \"tag\": \"llm_transformers_manual_vision_qwen\",\n",
            "      \"args\": {\n",
            "        \"lm_device\": \"cuda\",\n",
            "        \"lm_model_name_or_path\": \"./models/Qwen/Qwen2-VL-2B-Instruct\",\n",
            "        \"chat_history_size\": 0,\n",
            "        \"init_chat_prompt\": \"请用中文交流\",\n",
            "        \"model_type\": \"chat_completion\"\n",
            "      },\n",
            "      \"language\": \"zh\"\n",
            "    },\n",
            "    \"tts\": {\n",
            "      \"tag\": \"tts_edge\",\n",
            "      \"args\": {\n",
            "        \"voice_name\": \"zh-CN-YunjianNeural\",\n",
            "        \"language\": \"zh\",\n",
            "        \"gender\": \"Male\"\n",
            "      }\n",
            "    }\n",
            "  },\n",
            "  \"config_list\": []\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!TOGETHER_API_KEY=$TOGETHER_API_KEY LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_chat_transformers_vision_bot.json"
      ],
      "metadata": {
        "id": "MAMh470T1wAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6EiEKxtbqVT"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "REDIS_PASSWORD=userdata.get('REDIS_PASSWORD')\n",
        "#print(REDIS_PASSWORD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FzqIIMQ9boPX"
      },
      "outputs": [],
      "source": [
        "!LOG_LEVEL=debug REDIS_PASSWORD=$REDIS_PASSWORD python -m src.cmd.bots.main -f /content/task_bot.json"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Note**\n",
        "- Llama-3.2-11B-Vision-Instruct 可以支持中文视频对话，但是效果一般，中文训练样本比较少，多样性不够造成的，如果不想ft, 可以在预测下一个token的时候调整下多样性的参数，比如温度和重复惩罚, 或者对模型输出的内容进行去重处理； 本质上解决还是需要加入微调语料集，继续训练下模型，对中文文本语言模型支持友好。\n",
        "\n",
        "LLMs复读机问题指的是大型语言模型（LLMs）在生成文本时出现的一种现象，即模型倾向于无限地复制输入的文本或者以过度频繁的方式重复相同的句子或短语。这种现象使得模型的输出缺乏多样性和创造性，给用户带来了不好的体验。\n",
        "\n",
        "复读机问题可能出现的原因包括：\n",
        "\n",
        "(1)数据偏差：大型语言模型通常是通过预训练阶段使用大规模无标签数据进行训练的。如果训练数据中存在大量的重复文本或者某些特定的句子或短语出现频率较高，模型在生成文本时可能会倾向于复制这些常见的模式。\n",
        "\n",
        "(2)训练目标的限制：大型语言模型的训练通常是基于自监督学习的方法，通过预测下一个词或掩盖词来学习语言模型。这样的训练目标可能使得模型更倾向于生成与输入相似的文本，导致复读机问题的出现。\n",
        "\n",
        "(3)缺乏多样性的训练数据：虽然大型语言模型可以处理大规模的数据，但如果训练数据中缺乏多样性的语言表达和语境，模型可能无法学习到足够的多样性和创造性，导致复读机问题的出现。\n",
        "\n",
        "为了解决复读机问题，可以采取以下策略：\n",
        "\n",
        "(1)多样性训练数据：在训练阶段，尽量使用多样性的语料库来训练模型，避免数据偏差和重复文本的问题。\n",
        "\n",
        "(2)引入噪声：在生成文本时，可以引入一些随机性或噪声，例如通过采样不同的词或短语，或者引入随机的变换操作，以增加生成文本的多样性。\n",
        "\n",
        "(3)温度参数调整：温度参数是用来控制生成文本的多样性的一个参数。通过调整温度参数的值，可以控制生成文本的独创性和多样性，从而减少复读机问题的出现。\n",
        "\n",
        "(4)后处理和过滤：对生成的文本进行后处理和过滤，去除重复的句子或短语，以提高生成文本的质量和多样性。\n",
        "\n",
        "需要注意的是，复读机问题是大型语言模型面临的一个挑战，解决这个问题是一个复杂的任务，需要综合考虑数据、训练目标、模型架构和生成策略等多个因素。目前，研究人员和工程师们正在不断努力改进和优化大型语言模型，以提高其生成文本的多样性和创造性。\n",
        "\n",
        "\n",
        "# Reference\n",
        "- https://www.zhihu.com/question/616130636\n",
        "- https://ai.stackexchange.com/questions/39540/how-do-temperature-and-repetition-penalty-interfere"
      ],
      "metadata": {
        "id": "ybbx4J25-5vi"
      }
    }
  ]
}