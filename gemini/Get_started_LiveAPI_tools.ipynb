{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/gemini/Get_started_LiveAPI_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWESX0tpdrE-"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YQvTrJpxzRlJ"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://ai.google.dev/gemini-api/docs/live-tools?hl=zh-cn"
      ],
      "metadata": {
        "id": "lZfEgg8r54Th"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hp_P0cDzTWp"
      },
      "source": [
        "# Gemini - Multimodal live API: Tool use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7f4kFby0E6j"
      },
      "source": [
        "本笔记本提供了如何使用 Gemini 2.5 的多模态实时 API 来操作工具的示例。\n",
        "\n",
        "该 API 提供 Google 搜索、代码执行和函数调用工具。早期的 Gemini 模型支持这些工具的不同版本。Gemini 2.5（实时 API）最大的变化在于，基本上所有工具都由代码执行来处理。有了这项变化，您可以在单个 API 调用中使用**多个工具**，模型也可以在单个代码执行块中使用多个工具。\n",
        "\n",
        "本教程假设您已熟悉实时 API，如[本教程](../quickstarts/Get_started_LiveAPI.ipynb)中所述。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mfk6YY3G5kqp"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5027929de8f"
      },
      "source": [
        "### 安装 SDK\n",
        "\n",
        "全新的 **[Google Gen AI SDK](https://ai.google.dev/gemini-api/docs/sdks)** 提供对 Gemini 2.5（及更早版本）的编程访问，支持使用 [Google AI for Developers](https://ai.google.dev/gemini-api/docs) 和 [Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/overview) API。除少数例外情况外，在一个平台上运行的代码可以在两个平台上运行。这意味着您可以使用开发者 API 创建应用程序原型，然后将应用程序迁移到 Vertex AI，而无需重写代码。\n",
        "\n",
        "有关此新 SDK 的更多详细信息，请参阅 [文档](https://ai.google.dev/gemini-api/docs/sdks) 或 [入门指南](../quickstarts/Get_started.ipynb)。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "46zEFO2a9FFd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93047348-659c-4f0a-cd44-7ab7f565666d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.2/261.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install -U -q google-genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTIfnvCn9HvH"
      },
      "source": [
        "### 设置 API 密钥\n",
        "\n",
        "要运行以下单元格，您的 API 密钥必须存储在名为 `GOOGLE_API_KEY` 的 Colab Secret 中。如果您还没有 API 密钥，或者不确定如何创建 Colab Secret，请参阅 [Authentication ![image](https://storage.googleapis.com/generativeai-downloads/images/colab_icon16.png)](../quickstarts/Authentication.ipynb) 获取示例。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A1pkoyZb9Jm3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ['GOOGLE_API_KEY']=userdata.get('GOOGLE_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y13XaCvLY136"
      },
      "source": [
        "### 初始化 SDK 客户端\n",
        "\n",
        "客户端将从环境变量中获取您的 API 密钥。\n",
        "\n",
        "要使用正式 API，您需要将客户端版本设置为 `v1alpha`。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HghvVpbU0Uap"
      },
      "outputs": [],
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(http_options={\"api_version\": \"v1alpha\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOov6dpG99rY"
      },
      "source": [
        "### 选择模型\n",
        "\n",
        "您可以选择最新的稳定版模型或预览版模型。请注意，像 `gemini-2.5-flash-native-audio-preview-09-2025` 这样的原生音频模型无法在此笔记本中使用，因为它们无法输出纯文本，而 Colab 对此有严格的限制。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "27Fikag0xSaB"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = 'gemini-2.5-flash-native-audio-preview-09-2025'  # @param ['gemini-2.0-flash-live-001', 'gemini-live-2.5-flash-preview', 'gemini-2.5-flash-native-audio-preview-09-2025'] {allow-input: true, isTemplate: true}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLU9brx6p5YS"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yMG4iLu5ZLgc"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import contextlib\n",
        "import json\n",
        "import wave\n",
        "\n",
        "from IPython.display import display, Markdown, Audio, HTML\n",
        "\n",
        "from google import genai\n",
        "from google.genai import types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrb4aX5KqKKX"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmfQ-NvFI7Ct"
      },
      "source": [
        "您将使用 Live API 的音频输出，在 Colab 中收听音频的最简单方法是将 `PCM` 数据写入 `WAV` 文件："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "p2aGpzlR-60Q"
      },
      "outputs": [],
      "source": [
        "@contextlib.contextmanager\n",
        "def wave_file(filename, channels=1, rate=24000, sample_width=2):\n",
        "    with wave.open(filename, \"wb\") as wf:\n",
        "        wf.setnchannels(channels)\n",
        "        wf.setsampwidth(sample_width)\n",
        "        wf.setframerate(rate)\n",
        "        yield wf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfdD9mVxqatm"
      },
      "source": [
        "使用日志记录器可以更轻松地开启/关闭调试消息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wgHJgpV9Zw4E"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = logging.getLogger('Live')\n",
        "logger.setLevel('INFO')\n",
        "#logger.setLevel('DEBUG')  # Switch between \"INFO\" and \"DEBUG\" to toggle debug messages."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hiaxgUCZSYJ"
      },
      "source": [
        "## Get started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQoca-W7ri0y"
      },
      "source": [
        "大部分 Live API 的设置与[入门教程](../quickstarts/Get_started_LiveAPI.ipynb)类似。由于本教程并未着重讲解 API 的实时交互功能，因此代码已简化：此代码使用 Live API，但仅发送一条文本提示，并监听一轮回复。\n",
        "\n",
        "您可以在任何示例中设置 `modality=\"AUDIO\"` 以获取语音输出。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lwLZrmW5zR_P"
      },
      "outputs": [],
      "source": [
        "n = 0\n",
        "async def run(prompt, modality=\"TEXT\", tools=None):\n",
        "  global n\n",
        "  if tools is None:\n",
        "    tools=[]\n",
        "\n",
        "  config = {\n",
        "          \"tools\": tools,\n",
        "          \"response_modalities\": [modality]\n",
        "  }\n",
        "\n",
        "  async with client.aio.live.connect(model=MODEL_ID, config=config) as session:\n",
        "    display(Markdown(prompt))\n",
        "    display(Markdown('-------------------------------'))\n",
        "    await session.send_client_content(\n",
        "      turns={\"role\": \"user\", \"parts\": [{\"text\": prompt}]}, turn_complete=True\n",
        "    )\n",
        "\n",
        "    audio = False\n",
        "    filename = f'audio_{n}.wav'\n",
        "    with wave_file(filename) as wf:\n",
        "      async for response in session.receive():\n",
        "        logger.debug(str(response))\n",
        "        if response.server_content and response.server_content.model_turn and response.server_content.model_turn.parts and hasattr(response.server_content.model_turn.parts[0], 'text'):\n",
        "          if text := response.server_content.model_turn.parts[0].text:\n",
        "            display(Markdown(text))\n",
        "            continue\n",
        "\n",
        "        if response.server_content and response.server_content.model_turn and response.server_content.model_turn.parts and hasattr(response.server_content.model_turn.parts[0], 'data'):\n",
        "          if data := response.server_content.model_turn.parts[0].data:\n",
        "            print('.', end='')\n",
        "            wf.writeframes(data)\n",
        "            audio = True\n",
        "            continue\n",
        "\n",
        "        server_content = response.server_content\n",
        "        if server_content is not None:\n",
        "          handle_server_content(wf, server_content)\n",
        "          continue\n",
        "\n",
        "        tool_call = response.tool_call\n",
        "        if tool_call is not None:\n",
        "          await handle_tool_call(session, tool_call)\n",
        "\n",
        "\n",
        "  if audio:\n",
        "    display(Audio(filename, autoplay=True))\n",
        "    n = n+1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngrvxzrf0ERR"
      },
      "source": [
        "由于本教程演示了多个工具，您需要编写更多代码来处理它们返回的不同类型的对象。\n",
        "\n",
        "- `code_execution` 工具可以返回 `executable_code` 和 `code_execution_result` 两部分。\n",
        "\n",
        "- `google_search` 工具可能会附加一个 `grounding_metadata` 对象。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "CypjqSb-0C-Q"
      },
      "outputs": [],
      "source": [
        "def handle_server_content(wf, server_content):\n",
        "  model_turn = server_content.model_turn\n",
        "  if model_turn:\n",
        "    for part in model_turn.parts:\n",
        "      executable_code = part.executable_code\n",
        "      if executable_code is not None:\n",
        "        display(Markdown('-------------------------------'))\n",
        "        display(Markdown(f'``` python\\n{executable_code.code}\\n```'))\n",
        "        display(Markdown('-------------------------------'))\n",
        "\n",
        "      code_execution_result = part.code_execution_result\n",
        "      if code_execution_result is not None:\n",
        "        display(Markdown('-------------------------------'))\n",
        "        display(Markdown(f'``` \\n{code_execution_result.output}\\n```'))\n",
        "        display(Markdown('-------------------------------'))\n",
        "\n",
        "  grounding_metadata = getattr(server_content, 'grounding_metadata', None)\n",
        "  if grounding_metadata is not None:\n",
        "    display(\n",
        "        HTML(grounding_metadata.search_entry_point.rendered_content))\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPnXSNZ5rydM"
      },
      "source": [
        "最后，使用 `function_declarations` 工具时，API 可能会返回 `tool_call` 对象。为了保持代码简洁，`tool_call` 处理程序只需对每个函数调用回复 `\"ok\"` 即可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "EmTKF_DtrY4U"
      },
      "outputs": [],
      "source": [
        "async def handle_tool_call(session, tool_call):\n",
        "  print(\"Tool call:\")\n",
        "  function_responses = []\n",
        "  for fc in tool_call.function_calls:\n",
        "    function_response = types.FunctionResponse(\n",
        "        id=fc.id,\n",
        "        name=fc.name,\n",
        "        response={\"result\": \"ok\"},\n",
        "    )\n",
        "    function_responses.append(function_response)\n",
        "  print('>>> ', function_responses)\n",
        "  await session.send_tool_response(function_responses=function_responses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcNu3zUNsI_p"
      },
      "source": [
        "Try running it for a first time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ss9I0MRdHbP2",
        "outputId": "d7369143-4eda-4922-b928-798570433926",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Hello!"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": " How can I help you today?\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "await run(prompt=\"Hello?\", tools=None, modality = \"TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_BFBLLGp-Ye"
      },
      "source": [
        "## Simple function call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMq795G6t2hA"
      },
      "source": [
        "API 的函数调用功能可以处理多种类型的函数。SDK 的支持仍在开发中。因此，请尽量简化操作，只需发送一个最基本的函数定义：仅包含函数名称即可。\n",
        "\n",
        "请注意，在实际的 API 中，函数调用与聊天轮次无关。即使函数调用正在处理中，对话也可以继续进行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8Y00qqZZt5L-"
      },
      "outputs": [],
      "source": [
        "turn_on_the_lights = {'name': 'turn_on_the_lights'}\n",
        "turn_off_the_lights = {'name': 'turn_off_the_lights'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "8dCjPmz8nEbv",
        "outputId": "2f4400bd-fe49-4872-da38-a1f2a6eb06a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Turn on the lights"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\nprint(default_api.turn_on_the_lights())\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-7466577173747406610',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \n{'result': 'ok'}\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "OK. I'"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ve turned on the lights.\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"Turn on the lights\"\n",
        "\n",
        "tools = [\n",
        "    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}\n",
        "]\n",
        "\n",
        "await run(prompt, tools=tools, modality = \"TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmPB49ZodNKr"
      },
      "source": [
        "## 异步函数调用\n",
        "\n",
        "**异步函数调用** 允许模型异步管理其函数调用，而不会阻塞用户输入。\n",
        "\n",
        "您可以决定函数调用结束时模型的行为：不输出任何内容、中断当前操作或等待完成当前任务。\n",
        "\n",
        "接下来的单元格将使用略微更新的代码来调用 Live API，以便会话保持打开状态 20 秒，并接受每 10 秒发送给模型的多个请求。如果您对此实现感兴趣，请展开下一个单元格。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "M4TCYuB7XQXn"
      },
      "outputs": [],
      "source": [
        "# @title Live class with multiple messages (just run this cell)\n",
        "\n",
        "import collections.abc\n",
        "import inspect\n",
        "from asyncio.exceptions import CancelledError\n",
        "import traceback\n",
        "\n",
        "class Live:\n",
        "  def __init__(self, client):\n",
        "    self.client = client\n",
        "\n",
        "\n",
        "  async def run(self, config, functions=None, messages=None):\n",
        "    self.config = config\n",
        "    self.send_queue = asyncio.Queue()\n",
        "    self.tool_call_queue = asyncio.Queue()\n",
        "\n",
        "    try:\n",
        "      async with (\n",
        "            client.aio.live.connect(model=MODEL_ID, config=config) as session,\n",
        "            asyncio.TaskGroup() as tg\n",
        "      ):\n",
        "        self.session = session\n",
        "        recv_task = tg.create_task(self._recv())\n",
        "        send_task = tg.create_task(self._send())\n",
        "        tool_call_task = tg.create_task(self._run_tool_calls(functions))\n",
        "        read_text= tg.create_task(self._read_text(messages))\n",
        "\n",
        "\n",
        "        await read_text\n",
        "        await asyncio.sleep(20) # Keeping the socket open for 20s to wait for the FC and different messages\n",
        "\n",
        "        raise CancelledError\n",
        "    except CancelledError:\n",
        "      pass\n",
        "    except ExceptionGroup as EG:\n",
        "      traceback.print_exception(EG)\n",
        "\n",
        "  async def _recv(self):\n",
        "    try:\n",
        "      mode = None\n",
        "      while True:\n",
        "        async for response in self.session.receive():\n",
        "          logger.debug(str(response))\n",
        "          if response.server_content and response.server_content.model_turn and response.server_content.model_turn.parts and hasattr(response.server_content.model_turn.parts[0], 'text'):\n",
        "            if text := response.server_content.model_turn.parts[0].text:\n",
        "              if mode != 'text':\n",
        "                mode = 'text'\n",
        "                print()\n",
        "              print(text)\n",
        "          else:\n",
        "            if mode == 'text':\n",
        "              mode = 'other'\n",
        "              print()\n",
        "            print(f'<<<  {response.model_dump_json(exclude_none=True)}\\n')\n",
        "\n",
        "          tool_call = response.tool_call\n",
        "          if tool_call is not None:\n",
        "            await self.tool_call_queue.put(tool_call)\n",
        "\n",
        "    except asyncio.CancelledError:\n",
        "      pass\n",
        "\n",
        "  async def _send(self):\n",
        "    while True:\n",
        "      msg = await self.send_queue.get()\n",
        "      print(f'>>> {repr(msg)}\\n')\n",
        "      await self.session.send_client_content(turns=msg,turn_complete=True)\n",
        "\n",
        "  async def _run_tool_calls(self, functions):\n",
        "    while True:\n",
        "      tool_call = await self.tool_call_queue.get()\n",
        "      for fc in tool_call.function_calls:\n",
        "        fun = functions[fc.name]\n",
        "        called = fun(**fc.args)\n",
        "        if inspect.iscoroutine(called):\n",
        "          print(f'>> Starting {fc.name}\\n')\n",
        "          result = await called\n",
        "          print(f'>> Done {fc.name} >>> {repr(result)}\\n')\n",
        "          result = self._wrap_function_result(fc, result)\n",
        "          await self.session.send_tool_response(function_responses=[result])\n",
        "        elif isinstance(called, collections.abc.AsyncIterable):\n",
        "          async for result in called:\n",
        "            result.will_continue=True\n",
        "            result = self._wrap_function_result(fc, result)\n",
        "            print(f\">>> {repr(result)}\\n\")\n",
        "            await self.session.send_tool_response(function_responses=[result])\n",
        "\n",
        "          result = self._wrap_function_result(\n",
        "              fc,\n",
        "              types.FunctionResponse(will_continue=False)\n",
        "          )\n",
        "          print(f\">>> {repr(result)}\\n\")\n",
        "          await self.session.send_tool_response(\n",
        "              function_responses=[result]\n",
        "          )\n",
        "\n",
        "\n",
        "        else:\n",
        "          raise TypeError(f\"expected {fc.name} to return a coroutine, or an \"\n",
        "                          f\"AsyncIterable, got {type(fun)}\")\n",
        "\n",
        "  def _wrap_function_result(self, fc, result):\n",
        "    if result is None:\n",
        "      return types.FunctionResponse(\n",
        "          name=fc.name,\n",
        "          id=fc.id,\n",
        "          response={'result': 'ok'}\n",
        "      )\n",
        "    elif isinstance(result, types.FunctionResponse):\n",
        "      result.name = fc.name\n",
        "      result.id = fc.id\n",
        "      return result\n",
        "    else:\n",
        "      return types.FunctionResponse(\n",
        "          name=fc.name,\n",
        "          id=fc.id,\n",
        "          response= {'result': result}\n",
        "      )\n",
        "\n",
        "  async def _read_text(self, messages):\n",
        "    if messages:\n",
        "        for n, message in enumerate(messages):\n",
        "            await self.send_queue.put({\n",
        "                'role': 'user',\n",
        "                'parts': [{'text': message}]\n",
        "            })\n",
        "            if n+1 < len(messages):\n",
        "              await asyncio.sleep(5)\n",
        "    else:\n",
        "        while True:\n",
        "            message = await asyncio.to_thread(input, \"message > \")\n",
        "            if message.lower() == \"q\":\n",
        "                break\n",
        "            await self.send_queue.put({\n",
        "                'role': 'user',\n",
        "                'parts': [{'text': message}]\n",
        "            })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVStsmfrZX9x"
      },
      "source": [
        "### 默认行为：阻塞\n",
        "\n",
        "我们先来看默认行为。首先定义一个模拟天气函数，通过等待 10 秒来模拟计算时间。\n",
        "\n",
        "默认行为类似于先进先出 (FIFO) 队列：函数调用会被添加到队列中，任何后续请求都会被排队（阻塞）在其后，直到该函数处理完成。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DSp2PU0MbfBR",
        "outputId": "f083267e-77e9-4af8-caee-0ea1ade5d9d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> {'role': 'user', 'parts': [{'text': '拉斯维加斯的天气怎么样？'}]}\n",
            "\n",
            "<<<  {\"tool_call\":{\"function_calls\":[{\"id\":\"function-call-12948117924596791327\",\"args\":{},\"name\":\"get_weather_vegas\"}]}}\n",
            "\n",
            ">> Starting get_weather_vegas\n",
            "\n",
            ">>> {'role': 'user', 'parts': [{'text': '与此同时，请告诉我有关巴黎赌场的情况。'}]}\n",
            "\n",
            ">> Done get_weather_vegas >>> {'weather': 'Sunny, 42 degrees'}\n",
            "\n",
            "\n",
            "拉斯维加斯\n",
            "现在是晴天，42度。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":175,\"response_token_count\":28,\"total_token_count\":203,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":175}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":28}]}}\n",
            "\n",
            "\n",
            "我对巴黎\n",
            "赌场一无所知。\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":198,\"response_token_count\":8,\"total_token_count\":206,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":198}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":8}]}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mock function, takes 10s to process\n",
        "async def get_weather_vegas():\n",
        "  await asyncio.sleep(10)\n",
        "  return {'weather': \"Sunny, 42 degrees\"}\n",
        "\n",
        "# multiple prompts, they are going to be asked with 5s delay between each of them.\n",
        "questions = [\n",
        "    \"拉斯维加斯的天气怎么样？\",\n",
        "    \"与此同时，请告诉我有关巴黎赌场的情况。\"\n",
        "]\n",
        "\n",
        "await Live(client).run(\n",
        "    messages=questions,\n",
        "    functions={\n",
        "        'get_weather_vegas': get_weather_vegas,\n",
        "    },\n",
        "    config={\n",
        "        \"response_modalities\": [\"TEXT\"],\n",
        "        \"tools\": [\n",
        "            {\n",
        "                'function_declarations': [\n",
        "                    {'name': 'get_weather_vegas',  \"behavior\": \"UNSPECIFIED\"}, # This is default behavior, equivalent to BLOCKING\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siPiuJ8LW0BC"
      },
      "source": [
        "如您所见，模型立即调用了 `get_weather_vegas` 函数，但由于模型仍在等待函数调用结果，因此忽略了第二个问题。直到函数调用结果出来后，模型才开始回答第二个问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI2LZVgHXNLB"
      },
      "source": [
        "### **中断**：停止当前操作并处理结果\n",
        "\n",
        "这次，`behavior` 设置为 `NON_BLOCKING`，这意味着它将使用异步函数调用。\n",
        "\n",
        "此时，您需要定义模型在收到函数调用结果后将执行的操作。这可以在函数内部或处理函数调用的脚本中进行管理（因为自动函数调用不可用），方法是在 `FunctionResponse` 中添加 `scheduling` 值。\n",
        "\n",
        "这次的 `scheduling` 行为是“**`INTERRUPT`**”，这意味着模型一旦收到响应，就会立即停止当前操作并处理响应。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "e7-Sq7VpXNLC",
        "outputId": "c711d29d-bb61-4c4b-f2d0-b25e6997a95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> {'role': 'user', 'parts': [{'text': '拉斯维加斯的天气怎么样？'}]}\n",
            "\n",
            "<<<  {\"tool_call\":{\"function_calls\":[{\"id\":\"function-call-111365119741752038\",\"args\":{},\"name\":\"get_weather_vegas\"}]}}\n",
            "\n",
            ">> Starting get_weather_vegas\n",
            "\n",
            "\n",
            "我现在\n",
            "正在获取拉斯维加斯的天气信息。请稍等。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":456,\"response_token_count\":30,\"total_token_count\":486,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":456}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":30}]}}\n",
            "\n",
            ">>> {'role': 'user', 'parts': [{'text': '与此同时，告诉我你对巴黎赌场了解多少，里面都有哪些娱乐活动和景点。然后继续跟我说说拉斯维加斯的赌场，直到我让你闭嘴为止。别问我，只管不停地说。那么，你能告诉我你最喜欢的太阳马戏团表演是什么吗？'}]}\n",
            "\n",
            "\n",
            "我知道\n",
            "您对巴黎赌场和拉斯维加斯赌场有兴趣，也想了解\n",
            "我最喜欢的太阳马戏团表演。但是，由于我还在获取拉斯维加斯的天气信息，而且您要求我提供大量的信息，我担心\n",
            "可能会超出我的能力范围。首先，让我专注于提供您要求的拉斯维加斯天气信息。一旦我完成了，我将尽力满足您其他的要求\n",
            "。请您耐心等待。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":531,\"response_token_count\":89,\"total_token_count\":620,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":531}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":89}]}}\n",
            "\n",
            ">> Done get_weather_vegas >>> FunctionResponse(\n",
            "  response={\n",
            "    'weather': 'Sunny, 42 degrees'\n",
            "  },\n",
            "  scheduling=<FunctionResponseScheduling.INTERRUPT: 'INTERRUPT'>\n",
            ")\n",
            "\n",
            "\n",
            "拉斯\n",
            "维加斯现在是晴天，42度。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":689,\"response_token_count\":14,\"total_token_count\":703,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":689}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":14}]}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mock function, takes 10s to process\n",
        "async def get_weather_vegas():\n",
        "  await asyncio.sleep(10)\n",
        "  return types.FunctionResponse(\n",
        "      response={'weather': \"Sunny, 42 degrees\"},\n",
        "      scheduling=\"INTERRUPT\"\n",
        "  )\n",
        "\n",
        "# multiple prompts, they are going to be asked with 5s delay between each of them.\n",
        "questions = [\n",
        "    \"拉斯维加斯的天气怎么样？\",\n",
        "    \"与此同时，告诉我你对巴黎赌场了解多少，里面都有哪些娱乐活动和景点。然后继续跟我说说拉斯维加斯的赌场，直到我让你闭嘴为止。别问我，只管不停地说。\"\n",
        "    \"那么，你能告诉我你最喜欢的太阳马戏团表演是什么吗？\"\n",
        "]\n",
        "\n",
        "await Live(client).run(\n",
        "    messages=questions,\n",
        "    functions={\n",
        "        'get_weather_vegas': get_weather_vegas,\n",
        "    },\n",
        "    config={\n",
        "        \"response_modalities\": [\"TEXT\"],\n",
        "        \"tools\": [\n",
        "            {\n",
        "                'function_declarations': [\n",
        "                    {'name': 'get_weather_vegas',  \"behavior\": \"NON_BLOCKING\"},\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YObbWmcW24sH"
      },
      "source": [
        "如您所见，这次模型确认了我们的请求，并说了类似“‘拉斯维加斯天气请求正在运行。完成后我会通知您’”之类的话，然后继续处理您向它提出的问题，当函数响应返回时，它停止了正在做的事情，告诉我们天气情况，然后继续谈论它正在谈论的内容。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLbBme4MTBy7"
      },
      "source": [
        "### **等待空闲**：在处理此结果之前，请先完成当前操作\n",
        "\n",
        "同样，`behavior` 设置为 `NON_BLOCKING`，这意味着它将使用异步函数调用，并且您需要在 `FunctionResponse` 中添加 `scheduling` 值。\n",
        "\n",
        "这次的 `scheduling` 行为设置为 `W​​hen_idle`，这意味着模型将**等待完成**当前操作，然后再告知您请求的结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bhMQLAVqTBy8",
        "outputId": "1529f43c-a4f2-4a62-d749-7a66ae6b425c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> {'role': 'user', 'parts': [{'text': '拉斯维加斯的天气怎么样？'}]}\n",
            "\n",
            "<<<  {\"tool_call\":{\"function_calls\":[{\"id\":\"function-call-16238183825586039880\",\"args\":{},\"name\":\"get_weather_vegas\"}]}}\n",
            "\n",
            ">> Starting get_weather_vegas\n",
            "\n",
            "\n",
            "我\n",
            "正在查询拉斯维加斯的天气。请稍后查看。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":458,\"response_token_count\":30,\"total_token_count\":488,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":458}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":30}]}}\n",
            "\n",
            ">>> {'role': 'user', 'parts': [{'text': '与此同时，请不要使用任何工具，告诉我你对巴黎赌场以及里面所有娱乐和景点的了解。也请告诉我拉斯维加斯大道上每家赌场的情况！'}]}\n",
            "\n",
            "\n",
            "好吧\n",
            "，我会尽力告诉你我知道的关于巴黎赌场和拉斯维加斯大道\n",
            "上每家赌场的信息，但我无法访问实时数据库或网络。因此，我的信息可能并不完全是最新的。\n",
            "\n",
            "**巴黎拉斯维加斯赌场\n",
            "**\n",
            "\n",
            "巴黎拉斯维加斯赌场当然以其标志性的埃菲尔铁塔复制品而闻名，它本身就是一个景点。游客可以乘坐电梯到\n",
            "塔顶，欣赏拉斯维加斯大道的壮丽景色。赌场内部的设计旨在营造一种巴黎的氛围，拥有鹅卵石人行道、法国\n",
            "风格的商店和餐厅。\n",
            "\n",
            "*   **赌场:** 巴黎赌场拥有各种赌博游戏，包括老虎机、扑克和桌上游戏。\n",
            "*\n",
            "   **娱乐:** 除了赌场，巴黎还提供各种娱乐选择，如音乐会、喜剧表演和歌舞表演。\n",
            "*   **餐饮:** \n",
            "巴黎拉斯维加斯拥有各种餐厅，从小咖啡馆到高档餐厅，提供各种美食，包括法国菜。\n",
            "*   **景点:** 除了\n",
            "埃菲尔铁塔，巴黎还拥有复制的香榭丽舍大街、凯旋门和巴黎歌剧院。\n",
            "\n",
            "**拉斯维加斯大道赌场\n",
            ">> Done get_weather_vegas >>> FunctionResponse(\n",
            "  response={\n",
            "    'weather': 'Sunny, 42 degres'\n",
            "  },\n",
            "  scheduling=<FunctionResponseScheduling.WHEN_IDLE: 'WHEN_IDLE'>\n",
            ")\n",
            "\n",
            "（一些例子）**\n",
            "\n",
            "由于大道上的赌场太多，我无法提供所有赌场的详细信息，但我可以提供一些著名的赌场的例子：\n",
            "\n",
            "*   **\n",
            "贝拉吉奥:** 以其优雅和美丽而闻名，拥有壮观的喷泉表演、一个大型植物园和一个美术馆。\n",
            "*\n",
            "   **凯撒宫:** 以其罗马主题、豪华的套房和众多高档商店而闻名。它还拥有一个巨大的圆形剧场\n",
            "，举办各种演出。\n",
            "*   **威尼斯人和宫殿:** 这两个赌场连接在一起，营造出威尼斯的氛围，运河和\n",
            "贡多拉。\n",
            "*   **永利和安可:** 这两家赌场以其豪华、高档的氛围和精美的艺术收藏而闻名。\n",
            "\n",
            "*   **米高梅大酒店:** 是拉斯维加斯最大的酒店之一，拥有一个巨大的赌场、多个游泳池和一个大型竞技场。\n",
            "\n",
            "\n",
            "这些只是拉斯维加斯大道上众多赌场的一些例子。每个赌场都有其独特的风格和氛围，所以值得探索不同的赌场，找到你最喜欢的。\n",
            "\n",
            "\n",
            "请记住，在访问之前最好查看赌场的网站以获取最新信息，因为娱乐，餐饮和景点可能会发生变化。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":510,\"response_token_count\":508,\"total_token_count\":1018,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":510}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":508}]}}\n",
            "\n",
            "\n",
            "好的\n",
            "。拉斯维加斯天气晴朗，42度。\n",
            "\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":1089,\"response_token_count\":15,\"total_token_count\":1104,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":1089}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":15}]}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Mock function, takes 6s to process\n",
        "async def get_weather_vegas():\n",
        "  await asyncio.sleep(6)\n",
        "  return types.FunctionResponse(\n",
        "      response={'weather': \"Sunny, 42 degres\"},\n",
        "      scheduling=\"WHEN_IDLE\"\n",
        "  )\n",
        "\n",
        "# multiple prompts, they are going to be asked with 5s delay between each of them.\n",
        "questions = [\n",
        "    \"拉斯维加斯的天气怎么样？\",\n",
        "    \"与此同时，请不要使用任何工具，告诉我你对巴黎赌场以及里面所有娱乐和景点的了解。也请告诉我拉斯维加斯大道上每家赌场的情况！\"\n",
        "]\n",
        "\n",
        "await Live(client).run(\n",
        "    messages=questions,\n",
        "    functions={\n",
        "        'get_weather_vegas': get_weather_vegas,\n",
        "    },\n",
        "    config={\n",
        "        \"response_modalities\": [\"TEXT\"],\n",
        "        \"tools\": [\n",
        "            {\n",
        "                'function_declarations': [\n",
        "                    {'name': 'get_weather_vegas',  \"behavior\": \"NON_BLOCKING\"},\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xXyeaTR_VpM"
      },
      "source": [
        "如您所见，这一次，即使在回答有关赌场的问题时收到了函数调用响应（参见 `>> Done get_weather_vegas >>> [...] response={'weather': 'Sunny, 42 degres'})` 行），它也等到完成当前回答后才告知天气情况。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMRlAIkeTq1E"
      },
      "source": [
        "### 静默模式：将所学信息保留在自己手中\n",
        "\n",
        "这次，`behavior` 仍然设置为 `NON_BLOCKING`，这意味着它将使用异步函数调用，并且需要在 `FunctionResponse` 中设置 `scheduling` 值。\n",
        "\n",
        "这次的 `scheduling` 行为设置为“SILENT”(静默)，这意味着模型不会通知您函数调用何时完成，但它可能在后续对话中仍然会用到这些信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Cf36tYwITq1F",
        "outputId": "85a7fafa-c315-489e-d2f8-b4015a74c0a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> {'role': 'user', 'parts': [{'text': '拉斯维加斯的天气怎么样？'}]}\n",
            "\n",
            "<<<  {\"tool_call\":{\"function_calls\":[{\"id\":\"function-call-11792910172795837443\",\"args\":{},\"name\":\"get_weather_vegas\"}]}}\n",
            "\n",
            ">> Starting get_weather_vegas\n",
            "\n",
            ">> Done get_weather_vegas >>> FunctionResponse(\n",
            "  response={\n",
            "    'weather': 'Sunny, 42 degres'\n",
            "  },\n",
            "  scheduling=<FunctionResponseScheduling.SILENT: 'SILENT'>\n",
            ")\n",
            "\n",
            "\n",
            "我\n",
            "正在查询拉斯维加斯的天气。请稍后回来查看。\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":458,\"response_token_count\":30,\"total_token_count\":488,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":458}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":30}]}}\n",
            "\n",
            ">>> {'role': 'user', 'parts': [{'text': '与此同时，请你告诉我一些关于巴黎赌场的情况。'}]}\n",
            "\n",
            "\n",
            "我对巴黎\n",
            "赌场一无所知。\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":546,\"response_token_count\":8,\"total_token_count\":554,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":546}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":8}]}}\n",
            "\n",
            ">>> {'role': 'user', 'parts': [{'text': '温度超过40度了吗？'}]}\n",
            "\n",
            "\n",
            "当前\n",
            "拉斯维加斯的气温是 42 度。\n",
            "\n",
            "<<<  {\"server_content\":{\"generation_complete\":true}}\n",
            "\n",
            "<<<  {\"server_content\":{\"turn_complete\":true},\"usage_metadata\":{\"prompt_token_count\":571,\"response_token_count\":13,\"total_token_count\":584,\"prompt_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":571}],\"response_tokens_details\":[{\"modality\":\"TEXT\",\"token_count\":13}]}}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Mock function, takes 5s to process\n",
        "async def get_weather_vegas():\n",
        "  time.sleep(10)\n",
        "  return types.FunctionResponse(\n",
        "      response={'weather': \"Sunny, 42 degres\"},\n",
        "      scheduling=\"SILENT\"\n",
        "  )\n",
        "\n",
        "# multiple prompts, they are going to be asked with 5s delay between each of them.\n",
        "questions = [\n",
        "    \"拉斯维加斯的天气怎么样？\",\n",
        "    \"与此同时，请你告诉我一些关于巴黎赌场的情况。\",\n",
        "    \"温度超过40度了吗？\"\n",
        "]\n",
        "\n",
        "await Live(client).run(\n",
        "    messages=questions,\n",
        "    functions={\n",
        "        'get_weather_vegas': get_weather_vegas,\n",
        "    },\n",
        "    config={\n",
        "        \"response_modalities\": [\"TEXT\"],\n",
        "        \"tools\": [\n",
        "            {\n",
        "                'function_declarations': [\n",
        "                    {'name': 'get_weather_vegas',  \"behavior\": \"NON_BLOCKING\"},\n",
        "                ]\n",
        "            }\n",
        "        ]\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25R0uj7F_KB0"
      },
      "source": [
        "这一次，正如你所看到的，当函数调用结束时，模型什么也没做，但当再次询问同一问题时，它却在没有进行新的函数调用的情况下回答了这个问题。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCnCiTbhqE8q"
      },
      "source": [
        "## Code execution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4ptRBNY4N8Q"
      },
      "source": [
        "`code_execution` 允许模型编写并运行 Python 代码。尝试用它来解决一个模型无法凭记忆解决的数学问题："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "k4dURhC-QoSw",
        "outputId": "43de052c-2895-4edc-8ff1-e3147696f3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "你能计算出小于 100000 的最大素数回文串吗？"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "以下是我"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "解决此问题的方法：\n\n1.  **回文定义：**首先"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "，回文数字从前往后和从后往前读取时都一样。例如，121, 353 和 9009 "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "都是回文。\n2.  **素数定义：**素数是可以被 1 和它自身整除的数字。\n3.  **"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "范围：**我们需要在小于 100000 的数字中搜索。\n4.  **策略：**我将生成回文数"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "（从最大可能的数字开始），然后检查它们是否为素数，直到我找到一个素数回文数。由于我们正在寻找最大值，因此"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "从较大的数字开始会更快。\n\n现在，我将使用 Python 来实现这个逻辑。\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\ndef is_prime(n):\n    \"\"\"检查数字是否为素数.\"\"\"\n    if n < 2:\n        return False\n    for i in range(2, int(n**0.5) + 1):\n        if n % i == 0:\n            return False\n    return True\n\ndef generate_palindromes():\n    \"\"\"生成小于 100000 的回文数，从最大的开始.\"\"\"\n    # 5 位回文数：abcba\n    for a in range(9, -1, -1):\n        for b in range(9, -1, -1):\n            for c in range(9, -1, -1):\n                yield int(str(a) + str(b) + str(c) + str(b) + str(a))\n\n    # 4 位回文数：abba\n    for a in range(9, -1, -1):\n        for b in range(9, -1, -1):\n            yield int(str(a) + str(b) + str(b) + str(a))\n\n    # 3 位回文数：aba\n    for a in range(9, -1, -1):\n        for b in range(9, -1, -1):\n            yield int(str(a) + str(b) + str(a))\n\n    # 2 位回文数：aa\n    for a in range(9, -1, -1):\n      yield int(str(a) + str(a))\n\n    # 1 位回文数：a\n    for a in range(9, -1, -1):\n        yield a\n\n# 查找最大的素数回文数\nfor palindrome in generate_palindromes():\n    if palindrome < 100000 and is_prime(palindrome):\n        print(palindrome)\n        break\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \n98689\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "最大"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "素数回文小于 100000 是 986"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "89。"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt=\"你能计算出小于 100000 的最大素数回文串吗？\"\n",
        "\n",
        "tools = [\n",
        "    {'code_execution': {}}\n",
        "]\n",
        "\n",
        "await run(prompt, tools=tools, modality=\"TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueeerkpX5F-v"
      },
      "source": [
        "## 组合式函数调用\n",
        "\n",
        "组合式函数调用是指能够使用 `code_execution` 工具将用户自定义函数组合起来。模型会将这些函数写入更大的代码块中，然后在等待您为每个调用返回响应时暂停执行。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XzKyL_Rq5sG3",
        "outputId": "774e7597-9966-4df1-cdd9-dad1f0a5b8ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "能否编写一些代码，循环遍历并打印 1 到 20 之间的整数，每次遇到 3 的倍数时打开灯，每次遇到 5 的倍数时关闭灯？"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "当然"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "，这是实现该目标的 Python 代码：\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\nfor i in range(1, 21):\n    print(i)\n    if i % 3 == 0:\n        default_api.turn_on_the_lights()\n    if i % 5 == 0:\n        default_api.turn_off_the_lights()\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-3739458337160023292',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-15146055125664033134',\n",
            "  name='turn_off_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-15407822005768767923',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-15146055125664032351',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-6349727572494443973',\n",
            "  name='turn_off_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-15407822005768767030',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-6349727572494444250',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-8187699536938362648',\n",
            "  name='turn_off_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-15407822005768766137',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n",
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-6349727572494446453',\n",
            "  name='turn_off_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "此"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "代码循环访问数字 1 到 20。对于每个数字，它"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "首先打印该数字。然后，它检查该数字是否是 3 的倍数。如果是，则使用 `default_api.turn_on_"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "the_lights()` 打开灯。接下来，它检查该数字是否是 5 的倍数。如果是，则使用 `default_api.turn_"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "off_the_lights()` 关闭灯。\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#prompt=\"Can write some code to loop through and print integers from 1-20, and every time you hit a multiple of 3 turn on the lights, and every time you hit a multiple of 5 turn them off?\"\n",
        "prompt = \"能否编写一些代码，循环遍历并打印 1 到 20 之间的整数，每次遇到 3 的倍数时打开灯，每次遇到 5 的倍数时关闭灯？\"\n",
        "tools = [\n",
        "    {'code_execution': {}},\n",
        "    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}\n",
        "]\n",
        "\n",
        "await run(prompt, tools=tools, modality=\"TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G78sxDEcqHyO"
      },
      "source": [
        "## Google search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW10vRPN6UNp"
      },
      "source": [
        "`google_search` 工具允许模型执行 Google 搜索。例如，您可以尝试询问一些发生时间太近、尚未包含在训练数据中的事件。\n",
        "\n",
        "搜索仍将以 `AUDIO` 模式执行，但您不会看到详细的搜索结果："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QKvWzROJic60",
        "outputId": "a523caa4-5e68-401a-c3d6-8a5787a58596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "巴西对阵阿根廷的足球比赛是什么时候进行的？最终比分是多少？"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\nprint(google_search.search(queries=[\"巴西对阵阿根廷足球比赛时间及比分\", \"Brazil vs Argentina soccer game date and score\"]))\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \nLooking up information on Google Search.\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "根据"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "我搜索到的信息，巴西和阿根廷最近一次足球比赛是在20"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "25年3月26日进行的世界杯预选赛上，阿根廷以4-1战胜巴西。比赛在阿根廷布"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "宜诺斯艾利斯的Estadio Mâs Monumental体育场举行。\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG2Q7rOlpISMmrNUfSjNuHfHr6CJdu2IXQyfOQdXXP9HW16Q7jODWE3KVBTMBna3ozjB7VWEETiqhPpCXJE4H7hWke6k-VTQGEhV0gbQxPSQ_VAFLngyYbZ4-AIL_b9pkYz0m95pag4d0tNfuDrx_0r3KuueJwDSRZ51pFrkGzqed0CApH2q50Ia25nwz9DDqUVYkUH2QjidR0LqSOySqpem69GAmSyQ6WquDXJ\">Brazil vs Argentina soccer game date and score</a>\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEbaWpuCtRiPQctlytS9s80rsVB5eo0U6dF6_e_eqNRkASFTG0kbOk7Hf1bqRJwAm9_8W3lxpEmhiMVYcpBCU1TIO1TyaU6VjoWXgMKntzMwvKmKBNoXiMURIT8sKf5nm6dDttym8zdzDXWMfwFsReMxd2VXGHo2PD2CD9salRM4c97ERGh5ebonOjHjtVBqVccpPeTeLYa_unXKsSBxNyKmDRtO3gIqTBMoOdFrIObzvZ_Z5wefwAl_cMUpALVkjh1s4iapMr_dYeMyyi1XUG6kbR1eR6Qj4Rohb8ll9zyQqkdnK6CqsAsfP3qc0ynpI45NgEDsC6KaHaq37Blag_eBepWqJLfUCLN8c9NhH6_\">巴西对阵阿根廷足球比赛时间及比分</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt=\"巴西对阵阿根廷的足球比赛是什么时候进行的？最终比分是多少？\"\n",
        "\n",
        "tools = [\n",
        "   {'google_search': {}}\n",
        "]\n",
        "\n",
        "await run(prompt, tools=tools, modality=\"TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM9y5rwfqKfY"
      },
      "source": [
        "## Multi-tool\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrxAQjYA6vQX"
      },
      "source": [
        "新版 API 的最大区别在于，您不再受限于每次请求只能使用一个工具。尝试将前面章节中的任务组合起来使用："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "QmB_4XPOslyA",
        "outputId": "5c0f1724-1561-42c5-a238-d430a1c100b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "  嘿，我需要你帮我做三件事。\n\n1. 计算小于 100000 的最大素数平面。\n\n2. 用谷歌搜索查找关于 2024 年 12 月 5 日当周加州最大地震的信息。\n\n3. 打开灯。\n\n谢谢！\n  "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "好的"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "，没问题！我会依次处理这些任务。\n\n首先，计算小于 10"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "0000 的最大素数。\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\nimport sympy\n\ndef find_largest_prime_below(limit):\n  \"\"\"Finds the largest prime number less than the given limit.\"\"\"\n  n = limit\n  while n > 2:\n    n -= 1\n    if sympy.isprime(n):\n      return n\n  return None\n\nlargest_prime = find_largest_prime_below(100000)\nprint(largest_prime)\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \n99991\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "好的"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "，小于 100000 的最大素数是 9"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "9991。\n\n接下来，我将搜索关于 2024 年 12 月 5 日当周加州最大地震的信息。\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\nconcise_search(\"largest earthquake California week of December 5, 2024\", max_num_results=5)\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \nLooking up information on Google Search.\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "根据"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "搜索结果，2024 年 12 月 5 日左右"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "加州发生了一次大地震，震级为 7.0 级，震中位于门多西诺角附近的海上。 它引发了海"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "啸警报，但造成的破坏很小。\n\n最后，我将尝试打开灯。\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` python\ntry:\n  result = default_api.turn_on_the_lights()\n  print(result)\nexcept Exception as e:\n  print(f\"Error turning on lights: {e}\")\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              ".container {\n",
              "  align-items: center;\n",
              "  border-radius: 8px;\n",
              "  display: flex;\n",
              "  font-family: Google Sans, Roboto, sans-serif;\n",
              "  font-size: 14px;\n",
              "  line-height: 20px;\n",
              "  padding: 8px 12px;\n",
              "}\n",
              ".chip {\n",
              "  display: inline-block;\n",
              "  border: solid 1px;\n",
              "  border-radius: 16px;\n",
              "  min-width: 14px;\n",
              "  padding: 5px 16px;\n",
              "  text-align: center;\n",
              "  user-select: none;\n",
              "  margin: 0 8px;\n",
              "  -webkit-tap-highlight-color: transparent;\n",
              "}\n",
              ".carousel {\n",
              "  overflow: auto;\n",
              "  scrollbar-width: none;\n",
              "  white-space: nowrap;\n",
              "  margin-right: -12px;\n",
              "}\n",
              ".headline {\n",
              "  display: flex;\n",
              "  margin-right: 4px;\n",
              "}\n",
              ".gradient-container {\n",
              "  position: relative;\n",
              "}\n",
              ".gradient {\n",
              "  position: absolute;\n",
              "  transform: translate(3px, -9px);\n",
              "  height: 36px;\n",
              "  width: 9px;\n",
              "}\n",
              "@media (prefers-color-scheme: light) {\n",
              "  .container {\n",
              "    background-color: #fafafa;\n",
              "    box-shadow: 0 0 0 1px #0000000f;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #1f1f1f;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #ffffff;\n",
              "    border-color: #d2d2d2;\n",
              "    color: #5e5e5e;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #f2f2f2;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #d8d8d8;\n",
              "    border-color: #b6b6b6;\n",
              "  }\n",
              "  .logo-dark {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
              "  }\n",
              "}\n",
              "@media (prefers-color-scheme: dark) {\n",
              "  .container {\n",
              "    background-color: #1f1f1f;\n",
              "    box-shadow: 0 0 0 1px #ffffff26;\n",
              "  }\n",
              "  .headline-label {\n",
              "    color: #fff;\n",
              "  }\n",
              "  .chip {\n",
              "    background-color: #2c2c2c;\n",
              "    border-color: #3c4043;\n",
              "    color: #fff;\n",
              "    text-decoration: none;\n",
              "  }\n",
              "  .chip:hover {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:focus {\n",
              "    background-color: #353536;\n",
              "  }\n",
              "  .chip:active {\n",
              "    background-color: #464849;\n",
              "    border-color: #53575b;\n",
              "  }\n",
              "  .logo-light {\n",
              "    display: none;\n",
              "  }\n",
              "  .gradient {\n",
              "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
              "  }\n",
              "}\n",
              "</style>\n",
              "<div class=\"container\">\n",
              "  <div class=\"headline\">\n",
              "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
              "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
              "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
              "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
              "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
              "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
              "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
              "    </svg>\n",
              "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
              "  </div>\n",
              "  <div class=\"carousel\">\n",
              "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEXoakRuB5sRNWvn0gKpZKefsDHd0Z522RlbpnyxBnsYxK9hb-3s1pWNp1AoiyPSeFGuyXU5NsrdYQvgh8T5v61JOghYX42Y4U7i6bbN4j1UkS9GZKuSYXyuZBVOgLrZ9VufZnZACbaL2lSe4k2bNS0n74nfgwL7V58aBocNCVXPeFnPMellTjgGUMgjnNpD4c7nGO34--67SBT2alRz4bl_9oY-UrpQbf9DLho0Mo1L0MRgjwF\">largest earthquake California week of December 5, 2024</a>\n",
              "  </div>\n",
              "</div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool call:\n",
            ">>>  [FunctionResponse(\n",
            "  id='function-call-12208865589107067837',\n",
            "  name='turn_on_the_lights',\n",
            "  response={\n",
            "    'result': 'ok'\n",
            "  }\n",
            ")]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "``` \n{'result': 'ok'}\n\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "-------------------------------"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "好的"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "，灯已经打开了。\n\n我已经完成了你要求的所有三项任务："
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "计算了小于 100000 的最大素数（99991），搜索了关于 2024 年 1"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "2 月 5 日当周加州最大地震的信息，并打开了灯。\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "prompt = \"\"\"\\\n",
        "  嘿，我需要你帮我做三件事。\n",
        "\n",
        "1. 计算小于 100000 的最大素数平面。\n",
        "\n",
        "2. 用谷歌搜索查找关于 2024 年 12 月 5 日当周加州最大地震的信息。\n",
        "\n",
        "3. 打开灯。\n",
        "\n",
        "谢谢！\n",
        "  \"\"\"\n",
        "\n",
        "tools = [\n",
        "    {'google_search': {}},\n",
        "    {'code_execution': {}},\n",
        "    {'function_declarations': [turn_on_the_lights, turn_off_the_lights]}\n",
        "]\n",
        "\n",
        "await run(prompt, tools=tools, modality=\"TEXT\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0OhM95KkMzl"
      },
      "source": [
        "## 后续步骤\n",
        "\n",
        "- 有关 SDK 的更多信息，请参阅 [SDK 文档](https://googleapis.github.io/python-genai/)\n",
        "\n",
        "或者，您可以查看 [Cookbook](https://github.com/google-gemini/cookbook/tree/main/quickstarts) 中的其他 Gemini 2.5 功能，特别是另一个 [Search_Grounding](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Search_Grounding.ipynb) 示例以及关于 Gemini [空间功能](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Spatial_understanding.ipynb) 的示例。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}