{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xVoZohKLvzCQ"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOJ2QCXXbJ4pC2s6NZZKqxc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/achatbot_Qwen2_5_Omni.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "Gf2QRIf-CHpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && rm -rf achatbot && git clone https://github.com/ai-bot-pro/achatbot.git"
      ],
      "metadata": {
        "id": "KgWkCIBAxn-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvgRFMqRjlY"
      },
      "outputs": [],
      "source": [
        "%cd /content/achatbot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "x389A5GV4Vp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEpbiR_SRnwl"
      },
      "outputs": [],
      "source": [
        "!bash scripts/pypi_achatbot.sh dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.10-py3-none-any.whl[llm_transformers_manual_vision_voice_qwen]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AVHWLtY4pdB",
        "outputId": "5e5bfe47-59b7-4aee-a7c2-53ba26685965"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.0/103.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.2/35.2 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers@v4.51.3-Qwen2.5-Omni-preview"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A5s-lqL6S3C",
        "outputId": "a2d5e3e0-e20d-49f1-ce04-1f59a2b37773"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers@v4.51.3-Qwen2.5-Omni-preview\n",
            "  Cloning https://github.com/huggingface/transformers (to revision v4.51.3-Qwen2.5-Omni-preview) to /tmp/pip-req-build-jvxoar0d\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-jvxoar0d\n",
            "  Running command git checkout -q d24cea78bcf93e16d520392416a320e7cecd5b32\n",
            "  Resolved https://github.com/huggingface/transformers to commit d24cea78bcf93e16d520392416a320e7cecd5b32\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (1.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.52.0.dev0) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.52.0.dev0) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.52.0.dev0) (2025.4.26)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.52.0.dev0-py3-none-any.whl size=11459193 sha256=76cdd3800fcd5c809ce08030feff46ca3aca10eb361dc8f81e053208b3bd6b47\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-srl55ctm/wheels/9d/a4/d1/9bf234fcabd7d01ba2e55b65f426d7b52be31a63631cd091eb\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "Successfully installed transformers-4.52.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U flash-attn --no-build-isolation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpOaV8EjJ69R",
        "outputId": "4a11eee9-1ada-4901-89d6-710c5acd4bb6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/6.0 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/6.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK8tWbDguJck"
      },
      "source": [
        "# download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download FunAudioLLM/SenseVoiceSmall --quiet --local-dir /content/models/FunAudioLLM/SenseVoiceSmall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoKxtNoA4y2s",
        "outputId": "8225cd14-f222-4d73-e91b-d88271bd2438"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/FunAudioLLM/SenseVoiceSmall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y4QJvMXAfrGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f995322-0ae0-4ed3-93f9-fb89d1c90272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/Qwen/Qwen2.5-Omni-7B\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download Qwen/Qwen2.5-Omni-7B --quiet --local-dir /content/models/Qwen/Qwen2.5-Omni-7B"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# asr test"
      ],
      "metadata": {
        "id": "XxJljfKl6ZNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI8OtLdx6cLx",
        "outputId": "4081a056-08d4-4f5d-de15-00646247743d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/achatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/achatbot/test/audio_files/asr_example_zh.wav\")"
      ],
      "metadata": {
        "id": "3fCejayPGuT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/Qwen/Qwen2.5-Omni-7B \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    THINKER_LLM_GEN_TEMPERATURE=0.9 \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_qwen2_5omni_asr.TestQwen2_5OmniASR.test_transcribe_stream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE8I7IYc6kET",
        "outputId": "98d3c967-37f2-4213-cbf1-f40208d7a891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-22 09:36:24,533 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:41 - initASREngine - initASREngine: qwen2_5omni_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False}\n",
            "2025-04-22 09:36:28,608 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-04-22 09:36:29.864260: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-22 09:36:30.343379: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745314590.568268    2326 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745314590.629244    2326 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-22 09:36:30.986001: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-22 09:36:33,246 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-04-22 09:36:35,871 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use qwen2_5omni_asr engine\n",
            "2025-04-22 09:36:35,871 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.qwen2_5omni_asr.Qwen2_5OmniAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False}\n",
            "2025-04-22 09:36:35,872 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:56 - __init__ - Model args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': 'You are a speech recognition model', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': True}\n",
            "2025-04-22 09:36:35,872 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:57 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.9, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-04-22 09:36:35,872 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-04-22 09:36:35,872 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "2025-04-22 09:36:35,972 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  4.72it/s]\n",
            "2025-04-22 09:36:43,524 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:138 - warmup - Warming up TransformersManualAudioQwen2_5OmniLLM device: cuda:0\n",
            "2025-04-22 09:36:43,525 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:336 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:612: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n",
            "  warnings.warn(\n",
            "2025-04-22 09:36:44,614 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:211 - warmup - step 0 warnup TTFT(chunk) time: 0.8784143480000353 s\n",
            "2025-04-22 09:36:44,614 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:217 - warmup - TransformersManualAudioQwen2_5OmniLLM:  warmed up! time: 1.074 s\n",
            "2025-04-22 09:36:44,615 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: qwen2_5omni_asr, TAG:qwen2_5omni_asr | Qwen2_5OmniAsr\n",
            "2025-04-22 09:36:56,503 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:336 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "欢迎大家\n",
            "来\n",
            "体验\n",
            "达\n",
            "摩\n",
            "院\n",
            "推出的\n",
            "语音\n",
            "识别\n",
            "模型\n",
            "2025-04-22 09:36:58,319 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:473 - thinker_stream - thinker generate [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.9647925919999807 s, 13 tokens cost time: 1.870835522999812 s\n",
            "。\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 33.798s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/Qwen/Qwen2.5-Omni-7B \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    THINKER_LLM_GEN_TEMPERATURE=0.9 \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_qwen2_5omni_asr.TestQwen2_5OmniASR.test_transcribe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCYSFTMRwKB1",
        "outputId": "d40f441e-b08b-4717-a452-88e4105310d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-22 09:37:11,565 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:41 - initASREngine - initASREngine: qwen2_5omni_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False}\n",
            "2025-04-22 09:37:13,116 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-04-22 09:37:13.876075: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-22 09:37:13.893862: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745314633.914984    2623 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745314633.921516    2623 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-22 09:37:13.942560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-22 09:37:16,199 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-04-22 09:37:17,877 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use qwen2_5omni_asr engine\n",
            "2025-04-22 09:37:17,877 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.qwen2_5omni_asr.Qwen2_5OmniAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False}\n",
            "2025-04-22 09:37:17,877 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:56 - __init__ - Model args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': 'You are a speech recognition model', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': True}\n",
            "2025-04-22 09:37:17,877 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:57 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.9, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-04-22 09:37:17,877 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-04-22 09:37:17,878 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "2025-04-22 09:37:17,975 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  4.65it/s]\n",
            "2025-04-22 09:37:26,061 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:138 - warmup - Warming up TransformersManualAudioQwen2_5OmniLLM device: cuda:0\n",
            "2025-04-22 09:37:26,061 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:336 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:612: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n",
            "  warnings.warn(\n",
            "2025-04-22 09:37:26,892 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:211 - warmup - step 0 warnup TTFT(chunk) time: 0.6235564569999497 s\n",
            "2025-04-22 09:37:26,892 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:217 - warmup - TransformersManualAudioQwen2_5OmniLLM:  warmed up! time: 0.818 s\n",
            "2025-04-22 09:37:26,892 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: qwen2_5omni_asr, TAG:qwen2_5omni_asr | Qwen2_5OmniAsr\n",
            "2025-04-22 09:37:27,791 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:336 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-04-22 09:37:28,879 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:473 - thinker_stream - thinker generate [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.301337037000053 s, 13 tokens cost time: 1.1959776419997752 s\n",
            "{'language': 'zh', 'language_probability': None, 'text': '欢迎大家来体验达摩院推出的语音识别模型。', 'words': []}\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 17.323s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/Qwen/Qwen2.5-Omni-7B \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    THINKER_LLM_GEN_TEMPERATURE=0.9 \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_qwen2_5omni_asr.TestQwen2_5OmniASR.test_transcribe_with_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TaURKmwnkU",
        "outputId": "4a91e752-53c8-4b49-b46c-517ad42e73c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-04-22 09:37:46,129 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:41 - initASREngine - initASREngine: qwen2_5omni_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False}\n",
            "2025-04-22 09:37:47,734 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-04-22 09:37:48.522459: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-22 09:37:48.539587: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1745314668.560824    2862 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1745314668.567295    2862 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-04-22 09:37:48.588303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-04-22 09:37:50,935 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-04-22 09:37:52,675 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use qwen2_5omni_asr engine\n",
            "2025-04-22 09:37:52,675 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.qwen2_5omni_asr.Qwen2_5OmniAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False}\n",
            "2025-04-22 09:37:52,675 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:56 - __init__ - Model args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': 'You are a speech recognition model', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': True}\n",
            "2025-04-22 09:37:52,675 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:57 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.9, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-04-22 09:37:52,675 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-04-22 09:37:52,675 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "2025-04-22 09:37:52,783 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  4.61it/s]\n",
            "2025-04-22 09:38:00,397 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:138 - warmup - Warming up TransformersManualAudioQwen2_5OmniLLM device: cuda:0\n",
            "2025-04-22 09:38:00,397 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:336 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:612: UserWarning: `pad_token_id` should be positive but got -1. This will cause errors when batch generating, if there is padding. Please set `pad_token_id` explicitly as `model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\n",
            "  warnings.warn(\n",
            "2025-04-22 09:38:01,238 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:211 - warmup - step 0 warnup TTFT(chunk) time: 0.6313425350000443 s\n",
            "2025-04-22 09:38:01,238 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:217 - warmup - TransformersManualAudioQwen2_5OmniLLM:  warmed up! time: 0.828 s\n",
            "2025-04-22 09:38:01,238 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: qwen2_5omni_asr, TAG:qwen2_5omni_asr | Qwen2_5OmniAsr\n",
            "2025-04-22 09:38:01,242 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:336 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-04-22 09:38:02,331 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:473 - thinker_stream - thinker generate [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.296102626999982 s, 13 tokens cost time: 1.1828651079999872 s\n",
            "{'language': 'zh', 'language_probability': None, 'text': '欢迎大家来体验达摩院推出的语音识别模型。', 'words': []}\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 16.212s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# webrtc chat bot"
      ],
      "metadata": {
        "id": "CLl_oYeRrOWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.9.post9-py3-none-any.whl[fastapi_bot_server,daily_room_audio_stream,livekit_room_audio_stream,silero_vad_analyzer,sense_voice_asr,llm_transformers_manual_vision_voice_qwen,queue]\"\n"
      ],
      "metadata": {
        "id": "VxnoCiG8myuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DAILY_API_KEY=userdata.get('DAILY_API_KEY')\n",
        "\n",
        "LIVEKIT_URL=userdata.get('LIVEKIT_URL')\n",
        "LIVEKIT_API_KEY=userdata.get('LIVEKIT_API_KEY')\n",
        "LIVEKIT_API_SECRET=userdata.get('LIVEKIT_API_SECRET')"
      ],
      "metadata": {
        "id": "fxnIc7Plnc27"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYziEG-lnofg",
        "outputId": "59801ab1-5eef-4021-9efc-4c24e5b7c39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/achatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## voice webrtc chat bot"
      ],
      "metadata": {
        "id": "5ECHDBcumuQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_asr_qwen2_5omni_voice_bot.json\n"
      ],
      "metadata": {
        "id": "8sFq3h0V0QqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_qwen2_5omni_voice_bot.json\n"
      ],
      "metadata": {
        "id": "05HvpTnMnxCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## omni webrtc chat bot"
      ],
      "metadata": {
        "id": "sr2A2UshqW0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!!DAILY_API_KEY=$DAILY_API_KEY \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_2_5omni_vision_voice_bot.json\n"
      ],
      "metadata": {
        "id": "42H02B1cqZrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lm chunk generate demo"
      ],
      "metadata": {
        "id": "xVoZohKLvzCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "def generate_text(model_name=\"gpt2\", prompt=\"Once upon a time\", max_new_tokens=50, max_tokens_per_step=3):\n",
        "    # 加载模型和分词器\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model.eval()\n",
        "\n",
        "    # 设置 pad_token_id\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    print(tokenizer.eos_token_id,tokenizer.eos_token)\n",
        "    print(tokenizer.pad_token_id)\n",
        "\n",
        "    # 编码输入提示\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    generated_ids = input_ids\n",
        "    total_new_tokens = 0\n",
        "    generated_text = \"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while total_new_tokens < max_new_tokens:\n",
        "            # 计算当前步的最大新 tokens\n",
        "            remaining_tokens = min(max_tokens_per_step, max_new_tokens - total_new_tokens)\n",
        "\n",
        "            # 调用 generate 方法\n",
        "            outputs = model.generate(\n",
        "                input_ids=generated_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_new_tokens=remaining_tokens,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                use_cache=True,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "                do_sample=True,\n",
        "                top_p=0.95,\n",
        "                temperature=0.85,\n",
        "                repetition_penalty=1.1,\n",
        "            )\n",
        "\n",
        "            # 获取新生成的 tokens\n",
        "            new_ids = outputs.sequences\n",
        "            new_text = tokenizer.decode(new_ids[0, generated_ids.shape[1]:], skip_special_tokens=True)\n",
        "            print(\"New text:\", new_text)\n",
        "            generated_text += new_text\n",
        "            total_new_tokens += new_ids.shape[1] - generated_ids.shape[1]\n",
        "\n",
        "            # 更新 input_ids 和 attention_mask\n",
        "            generated_ids = new_ids\n",
        "            attention_mask = torch.ones_like(generated_ids, dtype=torch.long)  # 更新为全 1 的 attention_mask\n",
        "\n",
        "            # 检查是否生成 EOS\n",
        "            if new_ids[0, -1].item() == tokenizer.eos_token_id:\n",
        "                print(\"EOS\")\n",
        "                break\n",
        "\n",
        "            if total_new_tokens >= max_new_tokens:\n",
        "                print(\"达到最大新 tokens 限制\")\n",
        "                break\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "sRA3yRben3VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Once upon a time\"\n",
        "generated = generate_text(prompt=prompt, max_new_tokens=50, max_tokens_per_step=3)\n",
        "print(\"Generated text:\", generated)"
      ],
      "metadata": {
        "id": "VbDTJ_o37Gqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"你叫什么名字?\"\n",
        "generated = generate_text(model_name=\"Qwen/Qwen2.5-0.5B\", prompt=prompt, max_new_tokens=50, max_tokens_per_step=3)\n",
        "print(\"Generated text:\", generated)"
      ],
      "metadata": {
        "id": "HJVvt-6gMIDx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}