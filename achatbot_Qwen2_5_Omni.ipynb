{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xVoZohKLvzCQ"
      ],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPE8hTsN5c/ImkfLGoD7MoK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/achatbot_Qwen2_5_Omni.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "Gf2QRIf-CHpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && rm -rf achatbot && git clone https://github.com/ai-bot-pro/achatbot.git"
      ],
      "metadata": {
        "id": "KgWkCIBAxn-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvgRFMqRjlY"
      },
      "outputs": [],
      "source": [
        "%cd /content/achatbot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "x389A5GV4Vp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEpbiR_SRnwl"
      },
      "outputs": [],
      "source": [
        "!bash scripts/pypi_achatbot.sh dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.10-py3-none-any.whl[llm_transformers_manual_vision_voice_qwen]\""
      ],
      "metadata": {
        "id": "9AVHWLtY4pdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers@v4.51.3-Qwen2.5-Omni-preview"
      ],
      "metadata": {
        "id": "5A5s-lqL6S3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "fpOaV8EjJ69R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK8tWbDguJck"
      },
      "source": [
        "# download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download FunAudioLLM/SenseVoiceSmall --quiet --local-dir /content/models/FunAudioLLM/SenseVoiceSmall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoKxtNoA4y2s",
        "outputId": "8225cd14-f222-4d73-e91b-d88271bd2438"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/FunAudioLLM/SenseVoiceSmall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Y4QJvMXAfrGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f995322-0ae0-4ed3-93f9-fb89d1c90272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/Qwen/Qwen2.5-Omni-7B\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download Qwen/Qwen2.5-Omni-7B --quiet --local-dir /content/models/Qwen/Qwen2.5-Omni-7B"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# asr test"
      ],
      "metadata": {
        "id": "XxJljfKl6ZNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI8OtLdx6cLx",
        "outputId": "4081a056-08d4-4f5d-de15-00646247743d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/achatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/achatbot/test/audio_files/asr_example_zh.wav\")"
      ],
      "metadata": {
        "id": "3fCejayPGuT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/Qwen/Qwen2.5-Omni-7B \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    THINKER_LLM_GEN_TEMPERATURE=0.9 \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_qwen2_5omni_asr.TestQwen2_5OmniASR.test_transcribe_stream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE8I7IYc6kET",
        "outputId": "28aef6f5-c08f-4555-ff77-6564cf4d61ad"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-03 03:25:21,614 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: qwen2_5omni_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:25:23,561 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-05-03 03:25:24.188658: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-03 03:25:24.206288: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746242724.227705    5998 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746242724.234301    5998 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-03 03:25:24.255940: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-03 03:25:26,449 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-03 03:25:28,075 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use qwen2_5omni_asr engine\n",
            "2025-05-03 03:25:28,075 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.qwen2_5omni_asr.Qwen2_5OmniAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:25:28,076 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': 'You are a speech recognition model', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': True, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:25:28,076 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.9, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:25:28,076 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:60 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:25:28,076 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:61 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "2025-05-03 03:25:28,176 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  4.72it/s]\n",
            "2025-05-03 03:25:35,516 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:144 - warmup - Warming up TransformersManualAudioQwen2_5OmniLLM device: cuda:0 with 1 steps\n",
            "2025-05-03 03:25:35,517 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:337 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-05-03 03:25:35,527 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:169 - warmup - Warmup text: [\"<|im_start|>system\\nYou are a speech recognition model<|im_end|>\\n<|im_start|>user\\nRepeat the word 'weedge niu bi'.<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
            "2025-05-03 03:25:37,483 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 0 chunk: We edge, , warmup time: 1.9534638779998659 s\n",
            "2025-05-03 03:25:37,747 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 1 chunk:  we need no , warmup time: 0.26392667100003564 s\n",
            "2025-05-03 03:25:37,963 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 2 chunk:  be. , warmup time: 0.21550485699981436 s\n",
            "2025-05-03 03:25:38,220 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 3 chunk:  (It's , warmup time: 0.2573497270000189 s\n",
            "2025-05-03 03:25:38,478 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 4 chunk:  not clear what , warmup time: 0.256779411000025 s\n",
            "2025-05-03 03:25:38,737 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 5 chunk:  you're asking , warmup time: 0.25895829199998843 s\n",
            "2025-05-03 03:25:38,737 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:459 - thinker_generate_chunk - Max new tokens limit reached.\n",
            "2025-05-03 03:25:38,737 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 17 | thinker_max_tokens_per_step: 3 | first chunk generated cost: 1.9532892649999667 s | total cost: 3.204690217000234 s\n",
            "2025-05-03 03:25:38,737 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:236 - warmup - step 0 warmup TTFT(chunk) time: 1.9534638779998659 s | total: 3.205982835999748 s\n",
            "2025-05-03 03:25:38,738 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:246 - warmup - TransformersManualAudioQwen2_5OmniLLM:  warmed up! time: 3.208 s\n",
            "2025-05-03 03:25:38,738 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:45 - initASREngine - initASREngine: qwen2_5omni_asr, TAG:qwen2_5omni_asr | Qwen2_5OmniAsr\n",
            "2025-05-03 03:25:39,900 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:337 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "欢迎大家\n",
            "来\n",
            "体验\n",
            "达\n",
            "摩\n",
            "院\n",
            "推出的\n",
            "语音\n",
            "识别\n",
            "模型\n",
            "2025-05-03 03:25:40,722 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:523 - thinker_stream - thinker generate [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.2500335610000093 s, 13 tokens cost time: 0.8685011120005584 s\n",
            "。\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 19.119s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/Qwen/Qwen2.5-Omni-7B \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    THINKER_LLM_GEN_TEMPERATURE=0.9 \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_qwen2_5omni_asr.TestQwen2_5OmniASR.test_transcribe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCYSFTMRwKB1",
        "outputId": "1c9ce129-1d79-4931-827c-79d85375472d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-03 03:25:44,884 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: qwen2_5omni_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:25:46,837 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-05-03 03:25:47.461698: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-03 03:25:47.478726: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746242747.499758    6192 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746242747.506103    6192 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-03 03:25:47.527113: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-03 03:25:49,763 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-03 03:25:51,398 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use qwen2_5omni_asr engine\n",
            "2025-05-03 03:25:51,399 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.qwen2_5omni_asr.Qwen2_5OmniAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:25:51,399 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': 'You are a speech recognition model', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': True, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:25:51,399 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.9, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:25:51,399 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:60 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:25:51,399 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:61 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "2025-05-03 03:25:51,498 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  4.71it/s]\n",
            "2025-05-03 03:25:58,800 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:144 - warmup - Warming up TransformersManualAudioQwen2_5OmniLLM device: cuda:0 with 1 steps\n",
            "2025-05-03 03:25:58,800 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:337 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-05-03 03:25:58,811 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:169 - warmup - Warmup text: [\"<|im_start|>system\\nYou are a speech recognition model<|im_end|>\\n<|im_start|>user\\nRepeat the word 'weedge niu bi'.<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
            "2025-05-03 03:26:00,776 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 0 chunk: weedge nh , warmup time: 1.9630787599999167 s\n",
            "2025-05-03 03:26:00,997 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 1 chunk:  bi , warmup time: 0.2198573519999627 s\n",
            "2025-05-03 03:26:00,997 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 03:26:00,997 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 5 | thinker_max_tokens_per_step: 3 | first chunk generated cost: 1.9628845419999834 s | total cost: 2.182464515999982 s\n",
            "2025-05-03 03:26:00,997 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:236 - warmup - step 0 warmup TTFT(chunk) time: 1.9630787599999167 s | total: 2.1829361119998794 s\n",
            "2025-05-03 03:26:00,997 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:246 - warmup - TransformersManualAudioQwen2_5OmniLLM:  warmed up! time: 2.184 s\n",
            "2025-05-03 03:26:00,997 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:45 - initASREngine - initASREngine: qwen2_5omni_asr, TAG:qwen2_5omni_asr | Qwen2_5OmniAsr\n",
            "2025-05-03 03:26:02,169 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:337 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-05-03 03:26:03,000 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:523 - thinker_stream - thinker generate [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.24722063400008665 s, 13 tokens cost time: 0.8913087659996108 s\n",
            "{'language': 'zh', 'language_probability': None, 'text': '欢迎大家来体验达摩院推出的语音识别模型。', 'words': []}\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 18.125s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/Qwen/Qwen2.5-Omni-7B \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    THINKER_LLM_GEN_TEMPERATURE=0.9 \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_qwen2_5omni_asr.TestQwen2_5OmniASR.test_transcribe_with_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TaURKmwnkU",
        "outputId": "3b72c3af-0d63-4189-b72a-1f722322d460"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-03 03:26:07,149 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: qwen2_5omni_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:26:09,105 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-05-03 03:26:09.727827: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-03 03:26:09.744319: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746242769.765840    6371 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746242769.772211    6371 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-03 03:26:09.793239: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-03 03:26:11,985 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-03 03:26:13,623 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use qwen2_5omni_asr engine\n",
            "2025-05-03 03:26:13,623 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.qwen2_5omni_asr.Qwen2_5OmniAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': False, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:26:13,624 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': 'You are a speech recognition model', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': ['.', '。'], 'thinker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.9, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_args': {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': 'HuggingFaceTB/SmolLM-360M-Instruct', 'lm_device_map': None, 'lm_device': None, 'lm_torch_dtype': 'auto', 'lm_attn_impl': 'eager', 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 2, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': None, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4'}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'model_path': '/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'save_wav': False, 'disable_talker': True, 'thinker_all_talker_stream': False, 'mask_embedding': True}\n",
            "2025-05-03 03:26:13,624 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.9, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:26:13,624 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:60 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:26:13,624 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:61 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/achatbot/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "2025-05-03 03:26:13,725 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  4.76it/s]\n",
            "2025-05-03 03:26:21,054 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:144 - warmup - Warming up TransformersManualAudioQwen2_5OmniLLM device: cuda:0 with 1 steps\n",
            "2025-05-03 03:26:21,055 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:337 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-05-03 03:26:21,065 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:169 - warmup - Warmup text: [\"<|im_start|>system\\nYou are a speech recognition model<|im_end|>\\n<|im_start|>user\\nRepeat the word 'weedge niu bi'.<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
            "2025-05-03 03:26:23,031 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 0 chunk: Weedge N , warmup time: 1.9639606330001698 s\n",
            "2025-05-03 03:26:23,298 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:227 - warmup - 1 chunk: iu Bi , warmup time: 0.2662451559999681 s\n",
            "2025-05-03 03:26:23,298 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 03:26:23,298 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 6 | thinker_max_tokens_per_step: 3 | first chunk generated cost: 1.963782411000011 s | total cost: 2.229703440000094 s\n",
            "2025-05-03 03:26:23,298 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:236 - warmup - step 0 warmup TTFT(chunk) time: 1.9639606330001698 s | total: 2.230205789000138 s\n",
            "2025-05-03 03:26:23,299 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:246 - warmup - TransformersManualAudioQwen2_5OmniLLM:  warmed up! time: 2.232 s\n",
            "2025-05-03 03:26:23,299 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:45 - initASREngine - initASREngine: qwen2_5omni_asr, TAG:qwen2_5omni_asr | Qwen2_5OmniAsr\n",
            "2025-05-03 03:26:23,302 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py:337 - apply_chat_template - System prompt modified, audio output may not work as expected. Audio output mode only works when using default system prompt 'You are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.'\n",
            "2025-05-03 03:26:24,131 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:523 - thinker_stream - thinker generate [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.24704028299993297 s, 13 tokens cost time: 0.8841349219997028 s\n",
            "{'language': 'zh', 'language_probability': None, 'text': '欢迎大家来体验达摩院推出的语音识别模型。', 'words': []}\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 16.992s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# webrtc chat bot"
      ],
      "metadata": {
        "id": "CLl_oYeRrOWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.10-py3-none-any.whl[fastapi_bot_server,daily_room_audio_stream,livekit_room_audio_stream,silero_vad_analyzer,sense_voice_asr,llm_transformers_manual_vision_voice_qwen,queue]\"\n"
      ],
      "metadata": {
        "id": "VxnoCiG8myuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb29b90a-8984-4bfc-8a7b-1c34c59ab190"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/298.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m297.0/298.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.6/255.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.2 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DAILY_API_KEY=userdata.get('DAILY_API_KEY')\n",
        "\n",
        "LIVEKIT_URL=userdata.get('LIVEKIT_URL')\n",
        "LIVEKIT_API_KEY=userdata.get('LIVEKIT_API_KEY')\n",
        "LIVEKIT_API_SECRET=userdata.get('LIVEKIT_API_SECRET')"
      ],
      "metadata": {
        "id": "fxnIc7Plnc27"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYziEG-lnofg",
        "outputId": "884b4f11-f4d3-44b0-f3f1-a90fe72c2456"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/achatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## voice webrtc chat bot"
      ],
      "metadata": {
        "id": "5ECHDBcumuQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_asr_qwen2_5omni_voice_bot.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sFq3h0V0QqF",
        "outputId": "d9f81998-c342-437d-d944-bc8467dc7f0d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"chat_bot_name\": \"LivekitAsrQwen2_5OmniVoiceBot\",\n",
            "    \"config\": {\n",
            "        \"asr\": {\n",
            "            \"args\": {\n",
            "                \"language\": \"zn\",\n",
            "                \"model_name_or_path\": \"/content/models/FunAudioLLM/SenseVoiceSmall\"\n",
            "            },\n",
            "            \"tag\": \"sense_voice_asr\"\n",
            "        },\n",
            "        \"vad\": {\n",
            "            \"args\": {\n",
            "                \"stop_secs\": 0.7\n",
            "            },\n",
            "            \"tag\": \"silero_vad_analyzer\"\n",
            "        },\n",
            "        \"voice_llm\": {\n",
            "            \"args\": {\n",
            "                \"chat_history_size\": 0,\n",
            "                \"code2wav_args\": {\n",
            "                    \"batched_chunk\": 3,\n",
            "                    \"code2wav_dynamic_batch\": false,\n",
            "                    \"device\": \"cuda\",\n",
            "                    \"enable_torch_compile\": true,\n",
            "                    \"enable_torch_compile_first_chunk\": true,\n",
            "                    \"frequency\": \"50hz\",\n",
            "                    \"guidance_scale\": 0.5,\n",
            "                    \"model_path\": \"/content/models/Qwen/Qwen2.5-Omni-7B\",\n",
            "                    \"num_steps\": 10,\n",
            "                    \"odeint_method\": \"euler\",\n",
            "                    \"odeint_method_relaxed\": false,\n",
            "                    \"sway_coefficient\": -1.0\n",
            "                },\n",
            "                \"is_use_sliding_window_code2wav\": true,\n",
            "                \"lm_attn_impl\": \"flash_attention_2\",\n",
            "                \"lm_device\": \"cuda\",\n",
            "                \"lm_model_name_or_path\": \"/content/models/Qwen/Qwen2.5-Omni-7B\",\n",
            "                \"lm_torch_dtype\": \"bfloat16\",\n",
            "                \"no_stream_sleep_time\": 0.5,\n",
            "                \"speaker\": \"Chelsie\",\n",
            "                \"talker_args\": {\n",
            "                    \"lm_gen_max_new_tokens\": 2048,\n",
            "                    \"lm_gen_min_new_tokens\": 1,\n",
            "                    \"lm_gen_repetition_penalty\": 1.1,\n",
            "                    \"lm_gen_temperature\": 0.95,\n",
            "                    \"lm_gen_top_k\": 20,\n",
            "                    \"lm_gen_top_p\": 0.9\n",
            "                },\n",
            "                \"talker_eos_token_ids\": [\n",
            "                    8292,\n",
            "                    8294\n",
            "                ],\n",
            "                \"talker_skip_thinker_token_ids\": [],\n",
            "                \"thinker_args\": {\n",
            "                    \"lm_gen_max_new_tokens\": 1024,\n",
            "                    \"lm_gen_max_tokens_per_step\": 10,\n",
            "                    \"lm_gen_min_new_tokens\": 1,\n",
            "                    \"lm_gen_repetition_penalty\": 1.1,\n",
            "                    \"lm_gen_temperature\": 0.95,\n",
            "                    \"lm_gen_top_k\": 20,\n",
            "                    \"lm_gen_top_p\": 0.9\n",
            "                },\n",
            "                \"thinker_eos_token_ids\": [\n",
            "                    151644,\n",
            "                    151645\n",
            "                ],\n",
            "                \"warmup_steps\": 1\n",
            "            },\n",
            "            \"tag\": \"llm_transformers_manual_qwen2_5omni_text_voice\"\n",
            "        }\n",
            "    },\n",
            "    \"config_list\": [],\n",
            "    \"room_manager\": {\n",
            "        \"args\": {\n",
            "            \"bot_name\": \"LivekitAsrQwen2_5OmniVoiceBot\",\n",
            "            \"is_common_session\": false\n",
            "        },\n",
            "        \"tag\": \"livekit_room\"\n",
            "    },\n",
            "    \"room_name\": \"chat-room\",\n",
            "    \"room_url\": \"\",\n",
            "    \"services\": {\n",
            "        \"asr\": \"sense_voice\",\n",
            "        \"pipeline\": \"achatbot\",\n",
            "        \"vad\": \"silero\",\n",
            "        \"voice_llm\": \"llm_transformers_manual_qwen2_5omni_text_voice\"\n",
            "    },\n",
            "    \"token\": \"\"\n",
            "}\n",
            "2025-05-03 03:35:45,604 - chat-bot - INFO - /content/achatbot/src/cmd/bots/main.py:63 - <module> - bot_config:{'chat_bot_name': 'LivekitAsrQwen2_5OmniVoiceBot', 'room_name': 'chat-room', 'room_url': '', 'token': '', 'room_manager': {'tag': 'livekit_room', 'args': {'bot_name': 'LivekitAsrQwen2_5OmniVoiceBot', 'is_common_session': False}}, 'services': {'pipeline': 'achatbot', 'vad': 'silero', 'asr': 'sense_voice', 'voice_llm': 'llm_transformers_manual_qwen2_5omni_text_voice'}, 'config': {'vad': {'tag': 'silero_vad_analyzer', 'args': {'stop_secs': 0.7}}, 'asr': {'tag': 'sense_voice_asr', 'args': {'language': 'zn', 'model_name_or_path': '/content/models/FunAudioLLM/SenseVoiceSmall'}}, 'voice_llm': {'tag': 'llm_transformers_manual_qwen2_5omni_text_voice', 'args': {'no_stream_sleep_time': 0.5, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': True, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}}}, 'config_list': []}\n",
            "2025-05-03 03:35:45,605 - chat-bot - INFO - /content/achatbot/src/cmd/bots/run.py:33 - __init__ - run_bot_info: is_agent=False chat_bot_name='LivekitAsrQwen2_5OmniVoiceBot' config={'vad': {'tag': 'silero_vad_analyzer', 'args': {'stop_secs': 0.7}}, 'asr': {'tag': 'sense_voice_asr', 'args': {'language': 'zn', 'model_name_or_path': '/content/models/FunAudioLLM/SenseVoiceSmall'}}, 'voice_llm': {'tag': 'llm_transformers_manual_qwen2_5omni_text_voice', 'args': {'no_stream_sleep_time': 0.5, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': True, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}}} room_name='chat-room' room_url='' token='' config_list=[] services={'pipeline': 'achatbot', 'vad': 'silero', 'asr': 'sense_voice', 'voice_llm': 'llm_transformers_manual_qwen2_5omni_text_voice'} websocket_server_host='localhost' websocket_server_port=8765 transport_type='room' handle_sigint=True task_connector=None room_manager=EngineClassInfo(tag='livekit_room', args={'bot_name': 'LivekitAsrQwen2_5OmniVoiceBot', 'is_common_session': False})\n",
            "2025-05-03 03:35:45,798 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use livekit_room engine\n",
            "2025-05-03 03:35:45,798 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.services.help.livekit_room.LivekitRoom'> args: {'bot_name': 'LivekitAsrQwen2_5OmniVoiceBot', 'is_common_session': False}\n",
            "2025-05-03 03:35:45,798 - chat-bot - INFO - /content/achatbot/src/services/help/__init__.py:37 - initEngine - initEngine: livekit_room, TAG:livekit_room | LivekitRoom\n",
            "2025-05-03 03:35:48,086 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base.py:80 - init_bot_config - ai bot_config: vad=VADConfig(tag='silero_vad_analyzer', args={'stop_secs': 0.7}) asr=ASRConfig(tag='sense_voice_asr', args={'language': 'zn', 'model_name_or_path': '/content/models/FunAudioLLM/SenseVoiceSmall'}) llm=LLMConfig(base_url=None, model=None, language=None, messages=None, tools=None, tag=None, args=None) nlp_task_llm=None voice_llm=LLMConfig(base_url=None, model=None, language=None, messages=None, tools=None, tag='llm_transformers_manual_qwen2_5omni_text_voice', args={'no_stream_sleep_time': 0.5, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': True, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}) vision_llm=None omni_llm=None vision_detector=None vision_ocr=None tts=None img_gen=None extends=None\n",
            "2025-05-03 03:35:48,097 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use silero_vad_analyzer engine\n",
            "2025-05-03 03:35:48,098 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.vad_analyzer.silero.SileroVADAnalyzer'> args: {'sample_rate': 16000, 'num_channels': 1, 'confidence': 0.7, 'start_secs': 0.2, 'stop_secs': 0.8, 'min_volume': 0.6, 'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'source': 'github', 'force_reload': False, 'trust_repo': True, 'verbose': True, 'onnx': False, 'silero_sensitivity': 0.4, 'is_pad_tensor': True, 'check_frames_mode': 1}\n",
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n",
            "2025-05-03 03:35:48,532 - chat-bot - INFO - /content/achatbot/src/modules/speech/vad_analyzer/__init__.py:59 - initVADAnalyzerEngine - initVADEngine: silero_vad_analyzer, TAG:silero_vad_analyzer | SileroVADAnalyzer\n",
            "2025-05-03 03:35:48,534 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use sense_voice_asr engine\n",
            "2025-05-03 03:35:48,534 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.sense_voice_asr.SenseVoiceAsr'> args: {'download_path': '', 'model_name_or_path': '/content/models/FunAudioLLM/SenseVoiceSmall', 'language': 'zn', 'verbose': True, 'prompt': '', 'sample_rate': 16000, 'device': None}\n",
            "2025-05-03 03:35:49,018 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-03 03:35:53,229 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/funasr/auto/auto_model.py:179 - build_model - download models from model hub: ms\n",
            "Detect model requirements, begin to install it: /content/models/FunAudioLLM/SenseVoiceSmall/requirements.txt\n",
            "install model requirements successfully\n",
            "Loading remote code failed: model, No module named 'model'\n",
            "2025-05-03 03:35:58,101 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/funasr/auto/auto_model.py:271 - build_model - Loading pretrained params from /content/models/FunAudioLLM/SenseVoiceSmall/model.pt\n",
            "2025-05-03 03:35:58,106 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/funasr/train_utils/load_pretrained_model.py:36 - load_pretrained_model - ckpt: /content/models/FunAudioLLM/SenseVoiceSmall/model.pt\n",
            "2025-05-03 03:35:59,169 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/funasr/train_utils/load_pretrained_model.py:52 - load_pretrained_model - scope_map: ['module.', 'None']\n",
            "2025-05-03 03:35:59,169 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/funasr/train_utils/load_pretrained_model.py:58 - load_pretrained_model - excludes: None\n",
            "2025-05-03 03:35:59,245 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/funasr/train_utils/load_pretrained_model.py:103 - load_pretrained_model - Loading ckpt: /content/models/FunAudioLLM/SenseVoiceSmall/model.pt, status: <All keys matched successfully>\n",
            "2025-05-03 03:36:00,673 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-05-03 03:36:01.282255: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-03 03:36:01.298168: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746243361.316473    9204 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746243361.321895    9204 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-03 03:36:01.340236: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-03 03:36:04,631 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model args: {'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': True, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'disable_talker': False}\n",
            "2025-05-03 03:36:04,631 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.95, lm_gen_top_k=20, lm_gen_top_p=0.9, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=10, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:36:04,631 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:60 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=2048, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.95, lm_gen_top_k=20, lm_gen_top_p=0.9, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:36:04,631 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:61 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=True, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
            "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
            "Qwen2_5OmniToken2WavModel must inference with fp32, but flash_attention_2 only supports fp16 and bf16, attention implementation of Qwen2_5OmniToken2WavModel will fallback to sdpa.\n",
            "2025-05-03 03:36:04,913 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "2025-05-03 03:36:04,914 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_talker 1351.360256 M parameters\n",
            "2025-05-03 03:36:04,916 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_token2wav 449.051264 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  3.39it/s]\n",
            "2025-05-03 03:36:14,138 - chat-bot - INFO - /content/achatbot/src/thirdparty/qwen2_code2wav/engine.py:32 - __init__ - Code2WavEngine starting up on device cuda, with model /content/models/Qwen/Qwen2.5-Omni-7B, method: euler, relaxed: False\n",
            "Loading safetensors checkpoint shards: 100% 5/5 [00:00<00:00, 63.27it/s]\n",
            "Loading safetensors checkpoint shards: 100% 5/5 [00:00<00:00, 61.53it/s]\n",
            "Removing weight norm...\n",
            "2025-05-03 03:36:21,501 - chat-bot - INFO - /content/achatbot/src/thirdparty/qwen2_code2wav/engine.py:148 - torch_compile_model - Code2Wav model torch compiled\n",
            "2025-05-03 03:36:21,554 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:108 - __init__ - use Code2WavEngine, delete _model.token2wav\n",
            "2025-05-03 03:36:21,563 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:144 - warmup - Warming up TransformersManualTextVoiceQwen2_5OmniLLM device: cuda:0 with 1 steps\n",
            "2025-05-03 03:36:21,573 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:169 - warmup - Warmup text: [\"<|im_start|>system\\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\\n<|im_start|>user\\nRepeat the word 'weedge niu bi'.<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
            "2025-05-03 03:36:23,775 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:38:17,342 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 0 chunk: Weidge nbiu weige nbiu | torch.Size([12480]) , warmup time: 115.76639643399994 s\n",
            "2025-05-03 03:40:53,172 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 1 chunk: Weidge nbiu weige nbiu | torch.Size([17280]) , warmup time: 155.82882367799994 s\n",
            "2025-05-03 03:40:53,245 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 2 chunk: Weidge nbiu weige nbiu | torch.Size([17280]) , warmup time: 0.07336198600000898 s\n",
            "2025-05-03 03:40:55,152 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 3 chunk: Weidge nbiu weige nbiu | torch.Size([25920]) , warmup time: 1.9066718650001349 s\n",
            "2025-05-03 03:40:55,152 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.045497403000126724 s, 152 tokens cost time: 1.9315514569993866 s\n",
            "2025-05-03 03:40:55,152 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 111.63087372099994 s | cost: 269.43877004699993 s\n",
            "2025-05-03 03:40:55,369 - chat-bot - WARNING - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:502 - talker_generate_chunk - thinker_generate_ids: tensor([[13]], device='cuda:0') | len(thinker_generate_hidden_states): 1 < 2\n",
            "2025-05-03 03:40:55,369 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 4 chunk: . | torch.Size([0]) , warmup time: 0.2166084839998348 s\n",
            "2025-05-03 03:40:55,999 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:41:16,091 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 5 chunk:  If you want to know more about this strange word | torch.Size([12480]) , warmup time: 20.721658386999934 s\n",
            "2025-05-03 03:41:17,500 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 6 chunk:  If you want to know more about this strange word | torch.Size([17280]) , warmup time: 1.4084506199999396 s\n",
            "2025-05-03 03:41:18,946 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 7 chunk:  If you want to know more about this strange word | torch.Size([17280]) , warmup time: 1.4459282049997455 s\n",
            "2025-05-03 03:42:28,772 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 8 chunk:  If you want to know more about this strange word | torch.Size([12000]) , warmup time: 69.8253564759998 s\n",
            "2025-05-03 03:42:28,772 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04200567099996988 s, 123 tokens cost time: 4.497946828001432 s\n",
            "2025-05-03 03:42:28,772 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 18.257715420000068 s | cost: 88.2667316250006 s\n",
            "2025-05-03 03:42:28,773 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:459 - thinker_generate_chunk - Max new tokens limit reached.\n",
            "2025-05-03 03:42:28,773 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 21 | thinker_max_tokens_per_step: 10 | first chunk generated cost: 2.1996479409999665 s | total cost: 3.0436096290000023 s\n",
            "2025-05-03 03:42:28,773 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:236 - warmup - step 0 warmup TTFT(chunk) time: 115.76639643399994 s | total: 367.1932561349993 s\n",
            "2025-05-03 03:42:28,774 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:246 - warmup - TransformersManualTextVoiceQwen2_5OmniLLM:  warmed up! time: 367.200 s\n",
            "2025-05-03 03:42:28,774 - chat-bot - INFO - /content/achatbot/src/transports/livekit.py:43 - __init__ - LivekitTransport register event names: dict_keys(['on_connected', 'on_error', 'on_connection_state_changed', 'on_disconnected', 'on_participant_connected', 'on_participant_disconnected', 'on_audio_track_subscribed', 'on_audio_track_unsubscribed', 'on_video_track_subscribed', 'on_video_track_unsubscribed', 'on_data_received', 'on_first_participant_joined'])\n",
            "2025-05-03 03:42:28,776 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:157 - _join - LivekitAsrQwen2_5OmniVoiceBot Connecting to chat-room, current remote participants:[]\n",
            "2025-05-03 03:42:28,778 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_ffi::server:133:livekit_ffi::server - initializing ffi server v0.12.1\n",
            "2025-05-03 03:42:28,779 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.1\n",
            "2025-05-03 03:42:28,780 - chat-bot - INFO - /content/achatbot/src/processors/voice/qwen2_5omni_voice_processor.py:75 - start - start done\n",
            "2025-05-03 03:42:28,780 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:194 - join - LivekitAsrQwen2_5OmniVoiceBot has connected chat-room\n",
            "2025-05-03 03:42:28,783 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://chat-bot-3siyyeda.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=1&adaptive_stream=0&version=0.17.6&access_token=...\n",
            "2025-05-03 03:42:29,029 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:182 - _join - local_participant:rtc.LocalParticipant(sid=PA_EUZHthizgTxZ, identity=54d8aa3b-d499-450c-afd3-6f78c4f0bc9c, name=LivekitAsrQwen2_5OmniVoiceBot) joined room: chat-room connection_state: 1\n",
            "2025-05-03 03:42:29,031 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:390 - _async_on_participant_connected - Participant:rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=) connected\n",
            "2025-05-03 03:42:29,032 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base_livekit.py:121 - on_first_participant_joined - on_first_participant_joined---->rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:42:29,032 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:484 - capture_participant_audio - participant_id PA_MiuPssMX3oZg no audio track\n",
            "2025-05-03 03:42:29,032 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base_livekit.py:121 - on_first_participant_joined - on_first_participant_joined---->rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:42:29,032 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:484 - capture_participant_audio - participant_id PA_MiuPssMX3oZg no audio track\n",
            "2025-05-03 03:42:29,045 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:216 - join - audio track local publication rtc.LocalTrackPublication(sid=TR_AMUBZQggrHjA3n, name=achatbot-out-audio, kind=1, source=2)\n",
            "2025-05-03 03:42:29,045 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:246 - join - u can access sandbox url: https://ultra-terminal-re8nmd.sandbox.livekit.io/rooms/chat-room\n",
            "2025-05-03 03:42:29,045 - chat-bot - INFO - /content/achatbot/src/processors/livekit_input_transport_processor.py:78 - _audio_in_task_handler - Start sub room in audio stream task\n",
            "2025-05-03 03:42:29,206 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:408 - _async_on_track_subscribed - track subscribed: rtc.RemoteAudioTrack(sid=TR_AMx5KYiepHYzok, name=) from participant rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:42:29,207 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:431 - _process_audio_stream - Started processing audio stream for participant PA_MiuPssMX3oZg\n",
            "2025-05-03 03:42:29,207 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:408 - _async_on_track_subscribed - track subscribed: rtc.RemoteVideoTrack(sid=TR_VCk64CAqrQ9Y5i, name=) from participant rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:42:48,971 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:42:52,189 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:42:53,458 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [o]\n",
            "2025-05-03 03:42:54,716 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [ok]\n",
            "2025-05-03 03:43:02,859 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [okay]\n",
            "2025-05-03 03:43:06,694 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [oh]\n",
            "2025-05-03 03:43:13,716 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yh]\n",
            "2025-05-03 03:43:21,763 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:43:22,874 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:43:31,269 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [と]\n",
            "2025-05-03 03:43:46,514 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:43:50,367 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [o]\n",
            "2025-05-03 03:43:54,967 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:43:56,878 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:44:12,777 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:44:14,987 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [theah]\n",
            "2025-05-03 03:44:17,325 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:44:17,805 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [あ]\n",
            "2025-05-03 03:44:28,307 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:44:36,327 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [okay]\n",
            "2025-05-03 03:44:40,191 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:44:41,794 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yeah]\n",
            "2025-05-03 03:44:43,828 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:44:48,514 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [i]\n",
            "2025-05-03 03:44:52,787 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:44:56,450 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [ok]\n",
            "2025-05-03 03:44:59,464 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:45:00,673 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:45:04,536 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:45:08,005 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:45:11,371 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:45:12,455 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yh]\n",
            "2025-05-03 03:45:15,566 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [你好]\n",
            "2025-05-03 03:45:15,803 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserResponseAggregator#0 ---> FrameLogger#0 Frame: TextFrame#0(text: 你好)\n",
            "2025-05-03 03:45:16,506 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:45:18,808 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#1(text: 嗨！有啥好玩的事儿想跟我分享)\n",
            "2025-05-03 03:45:18,809 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#0(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:20,812 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#2(text: 嗨！有啥好玩的事儿想跟我分享)\n",
            "2025-05-03 03:45:20,812 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#1(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:22,316 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#3(text: 嗨！有啥好玩的事儿想跟我分享)\n",
            "2025-05-03 03:45:22,316 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#2(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:25,098 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04655823099983536 s, 139 tokens cost time: 5.688850405003905 s\n",
            "2025-05-03 03:45:25,099 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.20480067200014673 s | cost: 2.8946594030003325 s\n",
            "2025-05-03 03:45:25,314 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#4(text: 嗨！有啥好玩的事儿想跟我分享)\n",
            "2025-05-03 03:45:25,315 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#3(size: 39360, frames: 19680, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:25,442 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:45:27,769 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.042954309000379 s, 33 tokens cost time: 1.419104994000918 s\n",
            "2025-05-03 03:45:27,769 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.9040235970001049 s | cost: 0.9040235970001049 s\n",
            "2025-05-03 03:45:27,769 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 03:45:27,769 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 13 | thinker_max_tokens_per_step: 10 | first chunk generated cost: 0.7000653479999528 s | total cost: 1.0425483630001509 s\n",
            "2025-05-03 03:45:27,818 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#5(text: 不？)\n",
            "2025-05-03 03:45:27,818 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#4(size: 31680, frames: 15840, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:28,140 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [ok]\n",
            "2025-05-03 03:45:33,422 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yh]\n",
            "2025-05-03 03:45:35,381 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [你叫什么名字]\n",
            "2025-05-03 03:45:35,732 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserResponseAggregator#0 ---> FrameLogger#0 Frame: TextFrame#6(text: 你叫什么名字)\n",
            "2025-05-03 03:45:36,423 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:45:38,736 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#7(text: 我叫通义千问，是阿里云)\n",
            "2025-05-03 03:45:38,736 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#5(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:40,239 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#8(text: 我叫通义千问，是阿里云)\n",
            "2025-05-03 03:45:40,239 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#6(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:44,015 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#9(text: 我叫通义千问，是阿里云)\n",
            "2025-05-03 03:45:44,017 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#7(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:44,302 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04424911699970835 s, 127 tokens cost time: 5.189299366998057 s\n",
            "2025-05-03 03:45:44,302 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13448291600025186 s | cost: 2.681766459999835 s\n",
            "2025-05-03 03:45:44,519 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#10(text: 我叫通义千问，是阿里云)\n",
            "2025-05-03 03:45:44,519 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#8(size: 27840, frames: 13920, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:44,996 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:45:47,524 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#11(text: 研发的大规模语言模型，有什么我可以帮助你的)\n",
            "2025-05-03 03:45:47,524 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#9(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:49,027 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#12(text: 研发的大规模语言模型，有什么我可以帮助你的)\n",
            "2025-05-03 03:45:49,027 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#10(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:50,531 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#13(text: 研发的大规模语言模型，有什么我可以帮助你的)\n",
            "2025-05-03 03:45:50,531 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#11(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:52,035 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#14(text: 研发的大规模语言模型，有什么我可以帮助你的)\n",
            "2025-05-03 03:45:52,035 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#12(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:55,726 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.047991594999984954 s, 191 tokens cost time: 7.913851913002418 s\n",
            "2025-05-03 03:45:55,726 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13818617100014308 s | cost: 2.8047818980003285 s\n",
            "2025-05-03 03:45:55,953 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#15(text: 研发的大规模语言模型，有什么我可以帮助你的)\n",
            "2025-05-03 03:45:55,954 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#13(size: 54720, frames: 27360, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:45:56,085 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:45:58,337 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04492753600015931 s, 33 tokens cost time: 1.4245434440013014 s\n",
            "2025-05-03 03:45:58,337 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.8232015170001432 s | cost: 0.8232015170001432 s\n",
            "2025-05-03 03:45:58,337 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 03:45:58,337 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 23 | thinker_max_tokens_per_step: 10 | first chunk generated cost: 0.688303752000138 s | total cost: 1.7397373320000042 s\n",
            "2025-05-03 03:45:58,457 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#16(text: 吗？)\n",
            "2025-05-03 03:45:58,457 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#14(size: 31680, frames: 15840, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:46:00,090 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [ok]\n",
            "2025-05-03 03:46:00,988 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:46:01,767 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:46:08,073 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [讲一个故事]\n",
            "2025-05-03 03:46:08,442 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserResponseAggregator#0 ---> FrameLogger#0 Frame: TextFrame#17(text: 讲一个故事)\n",
            "2025-05-03 03:46:08,771 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:46:11,432 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04563022100001035 s, 42 tokens cost time: 1.8235348149992205 s\n",
            "2025-05-03 03:46:11,433 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.8335856499998044 s | cost: 0.8335856499998044 s\n",
            "2025-05-03 03:46:11,576 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#18(text: 行吧。)\n",
            "2025-05-03 03:46:11,577 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#15(size: 40320, frames: 20160, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:46:12,143 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:46:14,583 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#19(text: 有个人叫阿强，他一直想环)\n",
            "2025-05-03 03:46:14,583 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#16(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:46:16,087 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#20(text: 有个人叫阿强，他一直想环)\n",
            "2025-05-03 03:46:16,087 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#17(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:46:18,091 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#21(text: 有个人叫阿强，他一直想环)\n",
            "2025-05-03 03:46:18,092 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#18(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:46:19,651 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#22(text: 有个人叫阿强，他一直想环)\n",
            "2025-05-03 03:46:19,666 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#19(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:47:58,774 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04894102100024611 s, 158 tokens cost time: 6.641790327000763 s\n",
            "2025-05-03 03:47:58,774 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13441104300000006 s | cost: 99.97906258100056 s\n",
            "2025-05-03 03:47:58,939 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#23(text: 有个人叫阿强，他一直想环)\n",
            "2025-05-03 03:47:58,939 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#20(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:47:59,389 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:02,944 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#24(text: 游世界呢。)\n",
            "2025-05-03 03:48:02,944 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#21(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:04,448 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#25(text: 游世界呢。)\n",
            "2025-05-03 03:48:04,448 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#22(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:07,839 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.08275875000026645 s, 102 tokens cost time: 5.424033722000786 s\n",
            "2025-05-03 03:48:07,839 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13655025200023374 s | cost: 3.015700072000527 s\n",
            "2025-05-03 03:48:08,032 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#26(text: 游世界呢。)\n",
            "2025-05-03 03:48:08,032 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#23(size: 38400, frames: 19200, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:08,552 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:11,037 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#27(text: 有一天啊，他终于攒够了钱就)\n",
            "2025-05-03 03:48:11,037 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#24(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:12,540 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#28(text: 有一天啊，他终于攒够了钱就)\n",
            "2025-05-03 03:48:12,540 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#25(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:14,042 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#29(text: 有一天啊，他终于攒够了钱就)\n",
            "2025-05-03 03:48:14,042 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#26(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:17,484 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04297024800007421 s, 140 tokens cost time: 5.794043997000699 s\n",
            "2025-05-03 03:48:17,485 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13344361899999058 s | cost: 3.1298929659997157 s\n",
            "2025-05-03 03:48:17,670 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#30(text: 有一天啊，他终于攒够了钱就)\n",
            "2025-05-03 03:48:17,670 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#27(size: 40320, frames: 20160, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:17,862 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:20,175 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#31(text: 出发了。)\n",
            "2025-05-03 03:48:20,175 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#28(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:20,216 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04680217899976924 s, 50 tokens cost time: 2.1211789810008668 s\n",
            "2025-05-03 03:48:20,216 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13324782099971344 s | cost: 0.22718401999964044 s\n",
            "2025-05-03 03:48:20,677 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#32(text: 出发了。)\n",
            "2025-05-03 03:48:20,678 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#29(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:20,924 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:23,182 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#33(text: 他去了好多国家，在法国巴黎看埃菲尔)\n",
            "2025-05-03 03:48:23,182 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#30(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:24,685 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#34(text: 他去了好多国家，在法国巴黎看埃菲尔)\n",
            "2025-05-03 03:48:24,686 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#31(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:26,689 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#35(text: 他去了好多国家，在法国巴黎看埃菲尔)\n",
            "2025-05-03 03:48:26,689 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#32(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:28,193 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#36(text: 他去了好多国家，在法国巴黎看埃菲尔)\n",
            "2025-05-03 03:48:28,193 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#33(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:31,184 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04472292099990227 s, 169 tokens cost time: 6.992468008998912 s\n",
            "2025-05-03 03:48:31,184 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13440237600025284 s | cost: 3.256352713000979 s\n",
            "2025-05-03 03:48:31,373 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#37(text: 他去了好多国家，在法国巴黎看埃菲尔)\n",
            "2025-05-03 03:48:31,373 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#34(size: 33600, frames: 16800, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:31,901 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:34,377 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#38(text: 铁塔的时候，差点被一个小偷给骗)\n",
            "2025-05-03 03:48:34,378 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#35(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:35,882 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#39(text: 铁塔的时候，差点被一个小偷给骗)\n",
            "2025-05-03 03:48:35,882 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#36(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:37,385 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#40(text: 铁塔的时候，差点被一个小偷给骗)\n",
            "2025-05-03 03:48:37,385 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#37(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:39,029 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.044055853000372736 s, 158 tokens cost time: 6.560594016998948 s\n",
            "2025-05-03 03:48:39,029 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13745030299969585 s | cost: 0.557009898999695 s\n",
            "2025-05-03 03:48:39,389 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#41(text: 铁塔的时候，差点被一个小偷给骗)\n",
            "2025-05-03 03:48:39,389 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#38(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:39,390 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#42(text: 铁塔的时候，差点被一个小偷给骗)\n",
            "2025-05-03 03:48:39,390 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#39(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:39,753 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:42,395 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#43(text: 走了钱包，那真是吓死他了。)\n",
            "2025-05-03 03:48:42,395 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#40(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:43,898 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#44(text: 走了钱包，那真是吓死他了。)\n",
            "2025-05-03 03:48:43,899 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#41(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:45,401 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#45(text: 走了钱包，那真是吓死他了。)\n",
            "2025-05-03 03:48:45,401 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#42(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:46,708 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04907570399973338 s, 155 tokens cost time: 6.509390064002218 s\n",
            "2025-05-03 03:48:46,708 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13573446800000966 s | cost: 0.4358179070004553 s\n",
            "2025-05-03 03:48:46,904 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#46(text: 走了钱包，那真是吓死他了。)\n",
            "2025-05-03 03:48:46,905 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#43(size: 54720, frames: 27360, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:47,438 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:49,909 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#47(text: 不过后来他在德国的慕尼黑找到了一份)\n",
            "2025-05-03 03:48:49,909 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#44(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:51,412 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#48(text: 不过后来他在德国的慕尼黑找到了一份)\n",
            "2025-05-03 03:48:51,413 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#45(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:52,916 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#49(text: 不过后来他在德国的慕尼黑找到了一份)\n",
            "2025-05-03 03:48:52,916 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#46(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:56,973 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04654197900026702 s, 151 tokens cost time: 6.396434062999106 s\n",
            "2025-05-03 03:48:56,973 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13593215299988515 s | cost: 3.127894496999943 s\n",
            "2025-05-03 03:48:57,172 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#50(text: 不过后来他在德国的慕尼黑找到了一份)\n",
            "2025-05-03 03:48:57,172 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#47(size: 50880, frames: 25440, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:48:57,329 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:48:59,677 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#51(text: 临时的工作。)\n",
            "2025-05-03 03:48:59,678 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#48(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:03,202 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04624145399975532 s, 70 tokens cost time: 2.941535574002046 s\n",
            "2025-05-03 03:49:03,203 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13652366199994503 s | cost: 2.925303119000091 s\n",
            "2025-05-03 03:49:03,385 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#52(text: 临时的工作。)\n",
            "2025-05-03 03:49:03,385 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#49(size: 42240, frames: 21120, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:03,931 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:06,391 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#53(text: 在工作期间呢，他还交了个好朋友。)\n",
            "2025-05-03 03:49:06,391 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#50(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:07,894 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#54(text: 在工作期间呢，他还交了个好朋友。)\n",
            "2025-05-03 03:49:07,894 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#51(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:09,397 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#55(text: 在工作期间呢，他还交了个好朋友。)\n",
            "2025-05-03 03:49:09,398 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#52(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:10,941 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.050140250000367814 s, 155 tokens cost time: 6.552034790002381 s\n",
            "2025-05-03 03:49:10,941 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.1381202980001035 s | cost: 0.44858623000027364 s\n",
            "2025-05-03 03:49:11,402 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#56(text: 在工作期间呢，他还交了个好朋友。)\n",
            "2025-05-03 03:49:11,402 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#53(size: 54720, frames: 27360, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:11,565 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:13,906 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#57(text: 最后他带着满满的回忆回到了家。)\n",
            "2025-05-03 03:49:13,907 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#54(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:15,410 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#58(text: 最后他带着满满的回忆回到了家。)\n",
            "2025-05-03 03:49:15,410 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#55(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:17,413 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#59(text: 最后他带着满满的回忆回到了家。)\n",
            "2025-05-03 03:49:17,413 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#56(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:18,917 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#60(text: 最后他带着满满的回忆回到了家。)\n",
            "2025-05-03 03:49:18,917 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#57(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:22,633 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04681169300010879 s, 183 tokens cost time: 7.811301173999709 s\n",
            "2025-05-03 03:49:22,633 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13429677299973264 s | cost: 3.246349990999988 s\n",
            "2025-05-03 03:49:22,838 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#61(text: 最后他带着满满的回忆回到了家。)\n",
            "2025-05-03 03:49:22,839 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#58(size: 47040, frames: 23520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:23,315 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:25,844 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#62(text: 你要是还想听别的类型的故事，可以跟我说)\n",
            "2025-05-03 03:49:25,844 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#59(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:27,348 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#63(text: 你要是还想听别的类型的故事，可以跟我说)\n",
            "2025-05-03 03:49:27,348 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#60(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:29,352 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#64(text: 你要是还想听别的类型的故事，可以跟我说)\n",
            "2025-05-03 03:49:29,352 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#61(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:30,855 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#65(text: 你要是还想听别的类型的故事，可以跟我说)\n",
            "2025-05-03 03:49:30,855 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#62(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:31,699 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.047857538999778626 s, 183 tokens cost time: 7.81537758900231 s\n",
            "2025-05-03 03:49:31,699 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13113717700025518 s | cost: 0.5578694970008655 s\n",
            "2025-05-03 03:49:31,858 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#66(text: 你要是还想听别的类型的故事，可以跟我说)\n",
            "2025-05-03 03:49:31,859 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#63(size: 47040, frames: 23520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:32,012 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:34,773 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04454301299983854 s, 44 tokens cost time: 1.8872375720006858 s\n",
            "2025-05-03 03:49:34,773 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.8691441440000744 s | cost: 0.8691441440000744 s\n",
            "2025-05-03 03:49:34,914 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#67(text: 呀。)\n",
            "2025-05-03 03:49:34,914 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#64(size: 42240, frames: 21120, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:35,390 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:37,920 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#68(text: 比如恐怖故事或者爱情故事之类的。)\n",
            "2025-05-03 03:49:37,920 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#65(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:39,423 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#69(text: 比如恐怖故事或者爱情故事之类的。)\n",
            "2025-05-03 03:49:39,424 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#66(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:40,926 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#70(text: 比如恐怖故事或者爱情故事之类的。)\n",
            "2025-05-03 03:49:40,926 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#67(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:42,929 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#71(text: 比如恐怖故事或者爱情故事之类的。)\n",
            "2025-05-03 03:49:42,929 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#68(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:44,376 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.046466877999591816 s, 195 tokens cost time: 8.22146886100154 s\n",
            "2025-05-03 03:49:44,376 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.13585802599982344 s | cost: 0.7526522279995334 s\n",
            "2025-05-03 03:49:44,532 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#72(text: 比如恐怖故事或者爱情故事之类的。)\n",
            "2025-05-03 03:49:44,533 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#69(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:44,534 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#73(text: 比如恐怖故事或者爱情故事之类的。)\n",
            "2025-05-03 03:49:44,534 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#70(size: 24000, frames: 12000, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:44,913 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:47,540 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#74(text: 嗯…我还有很多呢。)\n",
            "2025-05-03 03:49:47,541 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#71(size: 24960, frames: 12480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:49,044 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#75(text: 嗯…我还有很多呢。)\n",
            "2025-05-03 03:49:49,045 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#72(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:49,550 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.048411236999982066 s, 102 tokens cost time: 4.3088275190002605 s\n",
            "2025-05-03 03:49:49,550 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.1345265590002782 s | cost: 0.32107027200027005 s\n",
            "2025-05-03 03:49:49,885 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:49:50,047 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#76(text: 嗯…我还有很多呢。)\n",
            "2025-05-03 03:49:50,047 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#73(size: 38400, frames: 19200, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:52,559 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:303 - code2wav_sliding_window_chunk_stream - talker generate first token cost time: 0.04621893000012278 s, 42 tokens cost time: 1.8576912730000004 s\n",
            "2025-05-03 03:49:52,559 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:306 - code2wav_sliding_window_chunk_stream - code2wav sliding window streaming first chunk time: 0.8117532680003023 s | cost: 0.8117532680003023 s\n",
            "2025-05-03 03:49:52,560 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 03:49:52,560 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 120 | thinker_max_tokens_per_step: 10 | first chunk generated cost: 0.3257900610001343 s | total cost: 9.795670008998513 s\n",
            "2025-05-03 03:49:53,052 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: TextFrame#77(text: 怎么样？)\n",
            "2025-05-03 03:49:53,052 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniTextVoiceProcessor#0 ---> FrameLogger#1 Frame: AudioRawFrame#74(size: 40320, frames: 20160, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:49:53,646 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yh]\n",
            "2025-05-03 03:49:54,536 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [o]\n",
            "2025-05-03 03:49:55,411 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [oh]\n",
            "2025-05-03 03:49:56,716 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:50:00,546 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:50:02,521 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:50:02,678 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:50:04,139 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:50:05,498 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:50:09,597 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [y]\n",
            "2025-05-03 03:51:01,297 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [the]\n",
            "2025-05-03 03:51:17,616 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "2025-05-03 03:51:20,008 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [i]\n",
            "2025-05-03 03:51:52,426 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [と]\n",
            "2025-05-03 03:51:58,276 - chat-bot - INFO - /content/achatbot/src/processors/speech/asr/asr_processor.py:69 - run_asr - sense_voice_asr Transcription: [yah]\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "KeyboardInterrupt\n",
            "2025-05-03 03:52:20,534 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/apipeline/pipeline/runner.py:53 - _sig_handler - Interruption detected. Canceling runner PipelineRunner#0\n",
            "2025-05-03 03:52:20,534 - chat-bot - INFO - /content/achatbot/src/processors/voice/qwen2_5omni_voice_processor.py:87 - cancel - cancel done\n",
            "2025-05-03 03:52:20,534 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/apipeline/pipeline/runner.py:53 - _sig_handler - Interruption detected. Canceling runner PipelineRunner#0\n",
            "2025-05-03 03:52:20,535 - chat-bot - INFO - /content/achatbot/src/processors/voice/qwen2_5omni_voice_processor.py:87 - cancel - cancel done\n",
            "2025-05-03 03:52:20,535 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:278 - leave - LivekitAsrQwen2_5OmniVoiceBot Disconnecting from chat-room\n",
            "2025-05-03 03:52:20,535 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:272 - leave - LivekitAsrQwen2_5OmniVoiceBot unconnect chat-room, don't to leave\n",
            "2025-05-03 03:52:21,535 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:463 - _async_on_disconnected - Disconnected from chat-room. Reason: Leave Room.\n",
            "2025-05-03 03:52:21,535 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base_livekit.py:79 - on_disconnected - on_disconnected----> reason Leave Room., Exiting.\n",
            "2025-05-03 03:52:21,535 - chat-bot - INFO - /content/achatbot/src/processors/voice/qwen2_5omni_voice_processor.py:81 - stop - stop done\n",
            "2025-05-03 03:52:21,536 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:272 - leave - LivekitAsrQwen2_5OmniVoiceBot unconnect chat-room, don't to leave\n",
            "2025-05-03 03:52:21,536 - chat-bot - INFO - /content/achatbot/src/processors/livekit_input_transport_processor.py:85 - _audio_in_task_handler - Cancelled sub room in audio stream task\n",
            "2025-05-03 03:52:21,536 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:272 - leave - LivekitAsrQwen2_5OmniVoiceBot unconnect chat-room, don't to leave\n",
            "2025-05-03 03:52:21,869 - chat-bot - INFO - /content/achatbot/src/common/task_manager/multiprocessing_task_manager.py:30 - cleanup - pid:9204 tag:chat-room proc: <Process name='LivekitAsrQwen2_5OmniVoiceBot' parent=9167 closed> close\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_qwen2_5omni_voice_bot.json\n"
      ],
      "metadata": {
        "id": "05HvpTnMnxCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f475fc8a-e3f4-43db-a279-6e933fb33869"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"chat_bot_name\": \"LivekitQwen2_5OmniVoiceBot\",\n",
            "    \"config\": {\n",
            "        \"vad\": {\n",
            "            \"args\": {\n",
            "                \"stop_secs\": 0.7\n",
            "            },\n",
            "            \"tag\": \"silero_vad_analyzer\"\n",
            "        },\n",
            "        \"voice_llm\": {\n",
            "            \"args\": {\n",
            "                \"chat_history_size\": 0,\n",
            "                \"code2wav_args\": {\n",
            "                    \"batched_chunk\": 3,\n",
            "                    \"code2wav_dynamic_batch\": false,\n",
            "                    \"device\": \"cuda\",\n",
            "                    \"enable_torch_compile\": true,\n",
            "                    \"enable_torch_compile_first_chunk\": true,\n",
            "                    \"frequency\": \"50hz\",\n",
            "                    \"guidance_scale\": 0.5,\n",
            "                    \"model_path\": \"/content/models/Qwen/Qwen2.5-Omni-7B\",\n",
            "                    \"num_steps\": 10,\n",
            "                    \"odeint_method\": \"euler\",\n",
            "                    \"odeint_method_relaxed\": false,\n",
            "                    \"sway_coefficient\": -1.0\n",
            "                },\n",
            "                \"is_use_sliding_window_code2wav\": false,\n",
            "                \"lm_attn_impl\": \"flash_attention_2\",\n",
            "                \"lm_device\": \"cuda\",\n",
            "                \"lm_model_name_or_path\": \"/content/models/Qwen/Qwen2.5-Omni-7B\",\n",
            "                \"lm_torch_dtype\": \"bfloat16\",\n",
            "                \"no_stream_sleep_time\": 0.9,\n",
            "                \"speaker\": \"Chelsie\",\n",
            "                \"talker_args\": {\n",
            "                    \"lm_gen_max_new_tokens\": 2048,\n",
            "                    \"lm_gen_min_new_tokens\": 1,\n",
            "                    \"lm_gen_repetition_penalty\": 1.1,\n",
            "                    \"lm_gen_temperature\": 0.95,\n",
            "                    \"lm_gen_top_k\": 20,\n",
            "                    \"lm_gen_top_p\": 0.9\n",
            "                },\n",
            "                \"talker_eos_token_ids\": [\n",
            "                    8292,\n",
            "                    8294\n",
            "                ],\n",
            "                \"talker_skip_thinker_token_ids\": [],\n",
            "                \"thinker_all_talker_stream\": false,\n",
            "                \"thinker_args\": {\n",
            "                    \"lm_gen_max_new_tokens\": 1024,\n",
            "                    \"lm_gen_max_tokens_per_step\": 10,\n",
            "                    \"lm_gen_min_new_tokens\": 1,\n",
            "                    \"lm_gen_repetition_penalty\": 1.1,\n",
            "                    \"lm_gen_temperature\": 0.95,\n",
            "                    \"lm_gen_top_k\": 20,\n",
            "                    \"lm_gen_top_p\": 0.9\n",
            "                },\n",
            "                \"thinker_eos_token_ids\": [\n",
            "                    151644,\n",
            "                    151645\n",
            "                ],\n",
            "                \"thinker_stop_strings_per_step\": [\n",
            "                    \",\",\n",
            "                    \"\\uff0c\",\n",
            "                    \".\",\n",
            "                    \"\\u3002\"\n",
            "                ],\n",
            "                \"warmup_steps\": 1\n",
            "            },\n",
            "            \"tag\": \"llm_transformers_manual_qwen2_5omni_audio_voice\"\n",
            "        }\n",
            "    },\n",
            "    \"config_list\": [],\n",
            "    \"room_manager\": {\n",
            "        \"args\": {\n",
            "            \"bot_name\": \"LivekitQwen2_5OmniVoiceBot\",\n",
            "            \"is_common_session\": false\n",
            "        },\n",
            "        \"tag\": \"livekit_room\"\n",
            "    },\n",
            "    \"room_name\": \"chat-room\",\n",
            "    \"room_url\": \"\",\n",
            "    \"services\": {\n",
            "        \"pipeline\": \"achatbot\",\n",
            "        \"vad\": \"silero\",\n",
            "        \"voice_llm\": \"llm_transformers_manual_qwen2_5omni_audio_voice\"\n",
            "    },\n",
            "    \"token\": \"\"\n",
            "}\n",
            "2025-05-03 03:53:51,156 - chat-bot - INFO - /content/achatbot/src/cmd/bots/main.py:63 - <module> - bot_config:{'chat_bot_name': 'LivekitQwen2_5OmniVoiceBot', 'room_name': 'chat-room', 'room_url': '', 'token': '', 'room_manager': {'tag': 'livekit_room', 'args': {'bot_name': 'LivekitQwen2_5OmniVoiceBot', 'is_common_session': False}}, 'services': {'pipeline': 'achatbot', 'vad': 'silero', 'voice_llm': 'llm_transformers_manual_qwen2_5omni_audio_voice'}, 'config': {'vad': {'tag': 'silero_vad_analyzer', 'args': {'stop_secs': 0.7}}, 'voice_llm': {'tag': 'llm_transformers_manual_qwen2_5omni_audio_voice', 'args': {'no_stream_sleep_time': 0.9, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}}}, 'config_list': []}\n",
            "2025-05-03 03:53:51,156 - chat-bot - INFO - /content/achatbot/src/cmd/bots/run.py:33 - __init__ - run_bot_info: is_agent=False chat_bot_name='LivekitQwen2_5OmniVoiceBot' config={'vad': {'tag': 'silero_vad_analyzer', 'args': {'stop_secs': 0.7}}, 'voice_llm': {'tag': 'llm_transformers_manual_qwen2_5omni_audio_voice', 'args': {'no_stream_sleep_time': 0.9, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}}} room_name='chat-room' room_url='' token='' config_list=[] services={'pipeline': 'achatbot', 'vad': 'silero', 'voice_llm': 'llm_transformers_manual_qwen2_5omni_audio_voice'} websocket_server_host='localhost' websocket_server_port=8765 transport_type='room' handle_sigint=True task_connector=None room_manager=EngineClassInfo(tag='livekit_room', args={'bot_name': 'LivekitQwen2_5OmniVoiceBot', 'is_common_session': False})\n",
            "2025-05-03 03:53:51,350 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use livekit_room engine\n",
            "2025-05-03 03:53:51,351 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.services.help.livekit_room.LivekitRoom'> args: {'bot_name': 'LivekitQwen2_5OmniVoiceBot', 'is_common_session': False}\n",
            "2025-05-03 03:53:51,351 - chat-bot - INFO - /content/achatbot/src/services/help/__init__.py:37 - initEngine - initEngine: livekit_room, TAG:livekit_room | LivekitRoom\n",
            "2025-05-03 03:53:53,778 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base.py:80 - init_bot_config - ai bot_config: vad=VADConfig(tag='silero_vad_analyzer', args={'stop_secs': 0.7}) asr=None llm=LLMConfig(base_url=None, model=None, language=None, messages=None, tools=None, tag=None, args=None) nlp_task_llm=None voice_llm=LLMConfig(base_url=None, model=None, language=None, messages=None, tools=None, tag='llm_transformers_manual_qwen2_5omni_audio_voice', args={'no_stream_sleep_time': 0.9, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}) vision_llm=None omni_llm=None vision_detector=None vision_ocr=None tts=None img_gen=None extends=None\n",
            "2025-05-03 03:53:53,791 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use silero_vad_analyzer engine\n",
            "2025-05-03 03:53:53,791 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.vad_analyzer.silero.SileroVADAnalyzer'> args: {'sample_rate': 16000, 'num_channels': 1, 'confidence': 0.7, 'start_secs': 0.2, 'stop_secs': 0.8, 'min_volume': 0.6, 'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'source': 'github', 'force_reload': False, 'trust_repo': True, 'verbose': True, 'onnx': False, 'silero_sensitivity': 0.4, 'is_pad_tensor': True, 'check_frames_mode': 1}\n",
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n",
            "2025-05-03 03:53:54,227 - chat-bot - INFO - /content/achatbot/src/modules/speech/vad_analyzer/__init__.py:59 - initVADAnalyzerEngine - initVADEngine: silero_vad_analyzer, TAG:silero_vad_analyzer | SileroVADAnalyzer\n",
            "2025-05-03 03:53:56,306 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-05-03 03:53:56.926950: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-03 03:53:56.944830: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746244436.966522   15600 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746244436.973029   15600 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-03 03:53:56.994918: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-03 03:53:59,481 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-03 03:54:00,982 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model args: {'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 10, 'lm_gen_repetition_penalty': 1.1}, 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': True, 'enable_torch_compile_first_chunk': True, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'disable_talker': False}\n",
            "2025-05-03 03:54:00,982 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.95, lm_gen_top_k=20, lm_gen_top_p=0.9, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=10, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:54:00,982 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:60 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=2048, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.95, lm_gen_top_k=20, lm_gen_top_p=0.9, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:54:00,982 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:61 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=True, enable_torch_compile_first_chunk=True, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
            "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
            "Qwen2_5OmniToken2WavModel must inference with fp32, but flash_attention_2 only supports fp16 and bf16, attention implementation of Qwen2_5OmniToken2WavModel will fallback to sdpa.\n",
            "2025-05-03 03:54:01,266 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "2025-05-03 03:54:01,267 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_talker 1351.360256 M parameters\n",
            "2025-05-03 03:54:01,269 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_token2wav 449.051264 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  3.38it/s]\n",
            "2025-05-03 03:54:10,496 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:144 - warmup - Warming up TransformersManualVoiceQwen2_5OmniLLM device: cuda:0 with 1 steps\n",
            "2025-05-03 03:54:10,506 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:169 - warmup - Warmup text: [\"<|im_start|>system\\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\\n<|im_start|>user\\nRepeat the word 'weedge niu bi'.<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
            "2025-05-03 03:54:13,290 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:54:17,474 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 0 chunk: Weedge niu bi. | torch.Size([17280]) , warmup time: 6.964994560999912 s\n",
            "2025-05-03 03:54:19,883 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 1 chunk: Weedge niu bi. | torch.Size([11520]) , warmup time: 2.4086120249999112 s\n",
            "2025-05-03 03:54:21,315 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 2 chunk: Weedge niu bi. | torch.Size([11520]) , warmup time: 1.4310814899999968 s\n",
            "2025-05-03 03:54:22,735 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 3 chunk: Weedge niu bi. | torch.Size([11520]) , warmup time: 1.4203032079999502 s\n",
            "2025-05-03 03:54:22,735 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04230433299971992 s, 114 tokens cost time: 1.3519693869998264 s\n",
            "2025-05-03 03:54:24,258 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 4 chunk: Weedge niu bi. | torch.Size([2400]) , warmup time: 1.5224271409997527 s\n",
            "2025-05-03 03:54:24,258 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.8290603560003547 s | cost: 9.611077387000478 s\n",
            "2025-05-03 03:54:24,868 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:54:28,828 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 5 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([17280]) , warmup time: 4.569418543000211 s\n",
            "2025-05-03 03:54:31,379 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 6 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([11520]) , warmup time: 2.5507650949998606 s\n",
            "2025-05-03 03:54:33,917 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 7 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([11520]) , warmup time: 2.5374660309998944 s\n",
            "2025-05-03 03:54:35,390 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 8 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([11520]) , warmup time: 1.4733838410002136 s\n",
            "2025-05-03 03:54:36,840 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 9 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([11520]) , warmup time: 1.4497697010001502 s\n",
            "2025-05-03 03:54:38,269 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 10 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([11520]) , warmup time: 1.4280916289999368 s\n",
            "2025-05-03 03:54:38,269 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.03985218299976623 s, 163 tokens cost time: 1.3719932590006465 s\n",
            "2025-05-03 03:54:39,812 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 11 chunk:  你是不是有什么特殊的用途或者想法呢？ | torch.Size([2880]) , warmup time: 1.5431592180002554 s\n",
            "2025-05-03 03:54:39,812 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.5848135440000988 s | cost: 13.56687984500013 s\n",
            "2025-05-03 03:54:39,813 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:459 - thinker_generate_chunk - Max new tokens limit reached.\n",
            "2025-05-03 03:54:39,813 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 16 | thinker_max_tokens_per_step: 10 | first chunk generated cost: 2.7810615469998083 s | total cost: 3.3904284779996487 s\n",
            "2025-05-03 03:54:39,813 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:236 - warmup - step 0 warmup TTFT(chunk) time: 6.964994560999912 s | total: 29.299472483000045 s\n",
            "2025-05-03 03:54:39,814 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:246 - warmup - TransformersManualVoiceQwen2_5OmniLLM:  warmed up! time: 29.305 s\n",
            "2025-05-03 03:54:39,814 - chat-bot - INFO - /content/achatbot/src/transports/livekit.py:43 - __init__ - LivekitTransport register event names: dict_keys(['on_connected', 'on_error', 'on_connection_state_changed', 'on_disconnected', 'on_participant_connected', 'on_participant_disconnected', 'on_audio_track_subscribed', 'on_audio_track_unsubscribed', 'on_video_track_subscribed', 'on_video_track_unsubscribed', 'on_data_received', 'on_first_participant_joined'])\n",
            "2025-05-03 03:54:39,816 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:157 - _join - LivekitQwen2_5OmniVoiceBot Connecting to chat-room, current remote participants:[]\n",
            "2025-05-03 03:54:39,828 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_ffi::server:133:livekit_ffi::server - initializing ffi server v0.12.1\n",
            "2025-05-03 03:54:39,829 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.1\n",
            "2025-05-03 03:54:39,829 - chat-bot - INFO - /content/achatbot/src/processors/voice/qwen2_5omni_voice_processor.py:75 - start - start done\n",
            "2025-05-03 03:54:39,829 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:194 - join - LivekitQwen2_5OmniVoiceBot has connected chat-room\n",
            "2025-05-03 03:54:39,833 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://chat-bot-3siyyeda.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=1&adaptive_stream=0&version=0.17.6&access_token=...\n",
            "2025-05-03 03:54:40,117 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:182 - _join - local_participant:rtc.LocalParticipant(sid=PA_DXQjNq6GcgJD, identity=ffb3b5d6-fc12-49fa-a665-1978325ec04e, name=LivekitQwen2_5OmniVoiceBot) joined room: chat-room connection_state: 1\n",
            "2025-05-03 03:54:40,119 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:390 - _async_on_participant_connected - Participant:rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=) connected\n",
            "2025-05-03 03:54:40,120 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base_livekit.py:121 - on_first_participant_joined - on_first_participant_joined---->rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:54:40,120 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:484 - capture_participant_audio - participant_id PA_MiuPssMX3oZg no audio track\n",
            "2025-05-03 03:54:40,120 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base_livekit.py:121 - on_first_participant_joined - on_first_participant_joined---->rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:54:40,120 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:484 - capture_participant_audio - participant_id PA_MiuPssMX3oZg no audio track\n",
            "2025-05-03 03:54:40,133 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:216 - join - audio track local publication rtc.LocalTrackPublication(sid=TR_AMvk5EG2oiLRG8, name=achatbot-out-audio, kind=1, source=2)\n",
            "2025-05-03 03:54:40,133 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:246 - join - u can access sandbox url: https://ultra-terminal-re8nmd.sandbox.livekit.io/rooms/chat-room\n",
            "2025-05-03 03:54:40,133 - chat-bot - INFO - /content/achatbot/src/processors/livekit_input_transport_processor.py:78 - _audio_in_task_handler - Start sub room in audio stream task\n",
            "2025-05-03 03:54:40,296 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:408 - _async_on_track_subscribed - track subscribed: rtc.RemoteVideoTrack(sid=TR_VCk64CAqrQ9Y5i, name=) from participant rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:54:40,296 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:408 - _async_on_track_subscribed - track subscribed: rtc.RemoteAudioTrack(sid=TR_AMx5KYiepHYzok, name=) from participant rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:54:40,296 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:431 - _process_audio_stream - Started processing audio stream for participant PA_MiuPssMX3oZg\n",
            "2025-05-03 03:54:45,381 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserAudioResponseAggregator#0 ---> FrameLogger#0 Frame: user_id:PA_MiuPssMX3oZg UserAudioRawFrame#507(size: 32960, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:54:46,364 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:54:50,788 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#0(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:54:50,789 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#0(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:54:54,392 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#1(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:54:54,393 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#1(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:54:57,096 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#2(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:54:57,097 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#2(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:54:58,900 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#3(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:54:58,900 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#3(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:00,703 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#4(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:55:00,704 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#4(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:02,506 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#5(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:55:02,506 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#5(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:03,193 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04379423499995028 s, 181 tokens cost time: 1.516210079000757 s\n",
            "2025-05-03 03:55:03,193 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.8748209000000315 s | cost: 15.307993071000055 s\n",
            "2025-05-03 03:55:03,408 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#6(text: 嗨！有啥事儿吗？你可以随时跟我说)\n",
            "2025-05-03 03:55:03,408 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#6(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:03,475 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:55:06,676 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.0427423659998567 s, 40 tokens cost time: 1.540550904000611 s\n",
            "2025-05-03 03:55:07,011 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#7(text: 哦。)\n",
            "2025-05-03 03:55:07,011 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#7(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:08,368 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 1.6576743600003283 s | cost: 3.349167791000582 s\n",
            "2025-05-03 03:55:08,814 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#8(text: 哦。)\n",
            "2025-05-03 03:55:08,814 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#8(size: 2880, frames: 1440, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:08,923 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:55:13,319 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#9(text: 希望我们聊得开心呀，)\n",
            "2025-05-03 03:55:13,319 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#9(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:16,021 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#10(text: 希望我们聊得开心呀，)\n",
            "2025-05-03 03:55:16,021 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#10(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:16,665 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04193778399985604 s, 89 tokens cost time: 1.5285019280008783 s\n",
            "2025-05-03 03:55:16,923 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#11(text: 希望我们聊得开心呀，)\n",
            "2025-05-03 03:55:16,923 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#11(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:18,230 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.698154190999958 s | cost: 7.775586672000372 s\n",
            "2025-05-03 03:55:18,725 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#12(text: 希望我们聊得开心呀，)\n",
            "2025-05-03 03:55:18,725 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#12(size: 3840, frames: 1920, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:18,895 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:55:23,230 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#13(text: 你要是有啥想法可以随时告诉我呢。)\n",
            "2025-05-03 03:55:23,230 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#13(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:26,835 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#14(text: 你要是有啥想法可以随时告诉我呢。)\n",
            "2025-05-03 03:55:26,835 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#14(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:29,538 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#15(text: 你要是有啥想法可以随时告诉我呢。)\n",
            "2025-05-03 03:55:29,538 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#15(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:30,440 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#16(text: 你要是有啥想法可以随时告诉我呢。)\n",
            "2025-05-03 03:55:30,441 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#16(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:31,846 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.042921923999983846 s, 156 tokens cost time: 1.5460899170057019 s\n",
            "2025-05-03 03:55:32,243 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#17(text: 你要是有啥想法可以随时告诉我呢。)\n",
            "2025-05-03 03:55:32,243 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#17(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:33,393 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.6673773369998344 s | cost: 12.94759423800042 s\n",
            "2025-05-03 03:55:33,966 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:55:34,044 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#18(text: 你要是有啥想法可以随时告诉我呢。)\n",
            "2025-05-03 03:55:34,045 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#18(size: 22080, frames: 11040, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:38,549 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#19(text: 嗯…期待和你的聊天呢。)\n",
            "2025-05-03 03:55:38,550 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#19(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:41,253 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#20(text: 嗯…期待和你的聊天呢。)\n",
            "2025-05-03 03:55:41,253 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#20(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:43,055 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#21(text: 嗯…期待和你的聊天呢。)\n",
            "2025-05-03 03:55:43,055 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#21(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:43,988 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.0433906289999868 s, 113 tokens cost time: 1.5587834950028991 s\n",
            "2025-05-03 03:55:44,857 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#22(text: 嗯…期待和你的聊天呢。)\n",
            "2025-05-03 03:55:44,858 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#22(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:45,529 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.7956698870002583 s | cost: 10.001026416000059 s\n",
            "2025-05-03 03:55:45,760 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#23(text: 嗯…期待和你的聊天呢。)\n",
            "2025-05-03 03:55:45,760 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#23(size: 3840, frames: 1920, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:46,002 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:55:51,166 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#24(text: 有什么事尽管说哈。)\n",
            "2025-05-03 03:55:51,166 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#24(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:52,968 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#25(text: 有什么事尽管说哈。)\n",
            "2025-05-03 03:55:52,968 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#25(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:54,770 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#26(text: 有什么事尽管说哈。)\n",
            "2025-05-03 03:55:54,770 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#26(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:55:55,900 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.046594172999903094 s, 109 tokens cost time: 1.5446589289977055 s\n",
            "2025-05-03 03:55:55,900 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.7789447559998735 s | cost: 8.349126682999668 s\n",
            "2025-05-03 03:55:56,471 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:55:56,573 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#27(text: 有什么事尽管说哈。)\n",
            "2025-05-03 03:55:56,573 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmniAudioVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#27(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "Exception ignored in atexit callback: <function _exit_function at 0x790009d8f6a0>\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "KeyboardInterrupt\n",
            "2025-05-03 03:55:59,234 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/apipeline/pipeline/runner.py:53 - _sig_handler - Interruption detected. Canceling runner PipelineRunner#0\n",
            "2025-05-03 03:56:04,238 - chat-bot - ERROR - /content/achatbot/src/common/task_manager/multiprocessing_task_manager.py:34 - cleanup - Error while cleaning up process 15600: Cannot close a process while it is still running. You should first call join() or terminate().\n",
            "2025-05-03 03:56:04,239 - chat-bot - WARNING - /content/achatbot/src/common/task_manager/multiprocessing_task_manager.py:37 - cleanup - pid:15600 tag:chat-room proc: <Process name='LivekitQwen2_5OmniVoiceBot' pid=15600 parent=15563 started> killed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## omni webrtc chat bot"
      ],
      "metadata": {
        "id": "sr2A2UshqW0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_qwen2_5omni_vision_voice_bot.json\n"
      ],
      "metadata": {
        "id": "42H02B1cqZrE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77ac8bf9-6fb8-4250-9ca2-41a1d7d89c14"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"chat_bot_name\": \"LivekitQwen2_5OmniVisionVoiceBot\",\n",
            "    \"config\": {\n",
            "        \"omni_llm\": {\n",
            "            \"args\": {\n",
            "                \"chat_history_size\": 0,\n",
            "                \"code2wav_args\": {\n",
            "                    \"batched_chunk\": 3,\n",
            "                    \"code2wav_dynamic_batch\": false,\n",
            "                    \"device\": \"cuda\",\n",
            "                    \"enable_torch_compile\": false,\n",
            "                    \"enable_torch_compile_first_chunk\": false,\n",
            "                    \"frequency\": \"50hz\",\n",
            "                    \"guidance_scale\": 0.5,\n",
            "                    \"model_path\": \"/content/models/Qwen/Qwen2.5-Omni-7B\",\n",
            "                    \"num_steps\": 10,\n",
            "                    \"odeint_method\": \"euler\",\n",
            "                    \"odeint_method_relaxed\": false,\n",
            "                    \"sway_coefficient\": -1.0\n",
            "                },\n",
            "                \"is_use_sliding_window_code2wav\": false,\n",
            "                \"lm_attn_impl\": \"flash_attention_2\",\n",
            "                \"lm_device\": \"cuda\",\n",
            "                \"lm_model_name_or_path\": \"/content/models/Qwen/Qwen2.5-Omni-7B\",\n",
            "                \"lm_torch_dtype\": \"bfloat16\",\n",
            "                \"no_stream_sleep_time\": 0.9,\n",
            "                \"speaker\": \"Chelsie\",\n",
            "                \"talker_args\": {\n",
            "                    \"lm_gen_max_new_tokens\": 2048,\n",
            "                    \"lm_gen_min_new_tokens\": 1,\n",
            "                    \"lm_gen_repetition_penalty\": 1.1,\n",
            "                    \"lm_gen_temperature\": 0.95,\n",
            "                    \"lm_gen_top_k\": 20,\n",
            "                    \"lm_gen_top_p\": 0.9\n",
            "                },\n",
            "                \"talker_eos_token_ids\": [\n",
            "                    8292,\n",
            "                    8294\n",
            "                ],\n",
            "                \"talker_skip_thinker_token_ids\": [],\n",
            "                \"thinker_all_talker_stream\": false,\n",
            "                \"thinker_args\": {\n",
            "                    \"lm_gen_max_new_tokens\": 1024,\n",
            "                    \"lm_gen_max_tokens_per_step\": 20,\n",
            "                    \"lm_gen_min_new_tokens\": 1,\n",
            "                    \"lm_gen_repetition_penalty\": 1.1,\n",
            "                    \"lm_gen_temperature\": 0.95,\n",
            "                    \"lm_gen_top_k\": 20,\n",
            "                    \"lm_gen_top_p\": 0.9\n",
            "                },\n",
            "                \"thinker_eos_token_ids\": [\n",
            "                    151644,\n",
            "                    151645\n",
            "                ],\n",
            "                \"thinker_stop_strings_per_step\": [\n",
            "                    \",\",\n",
            "                    \"\\uff0c\",\n",
            "                    \".\",\n",
            "                    \"\\u3002\"\n",
            "                ],\n",
            "                \"warmup_steps\": 1\n",
            "            },\n",
            "            \"tag\": \"llm_transformers_manual_qwen2_5omni_vision_voice\"\n",
            "        },\n",
            "        \"vad\": {\n",
            "            \"args\": {\n",
            "                \"stop_secs\": 0.7\n",
            "            },\n",
            "            \"tag\": \"silero_vad_analyzer\"\n",
            "        }\n",
            "    },\n",
            "    \"config_list\": [],\n",
            "    \"room_manager\": {\n",
            "        \"args\": {\n",
            "            \"bot_name\": \"LivekitQwen2_5OmniVisionVoiceBot\",\n",
            "            \"is_common_session\": false\n",
            "        },\n",
            "        \"tag\": \"livekit_room\"\n",
            "    },\n",
            "    \"room_name\": \"chat-room\",\n",
            "    \"room_url\": \"\",\n",
            "    \"services\": {\n",
            "        \"omni_llm\": \"llm_transformers_manual_qwen2_5omni_vision_voice\",\n",
            "        \"pipeline\": \"achatbot\",\n",
            "        \"vad\": \"silero\"\n",
            "    },\n",
            "    \"token\": \"\"\n",
            "}\n",
            "2025-05-03 03:56:42,388 - chat-bot - INFO - /content/achatbot/src/cmd/bots/main.py:63 - <module> - bot_config:{'chat_bot_name': 'LivekitQwen2_5OmniVisionVoiceBot', 'room_name': 'chat-room', 'room_url': '', 'token': '', 'room_manager': {'tag': 'livekit_room', 'args': {'bot_name': 'LivekitQwen2_5OmniVisionVoiceBot', 'is_common_session': False}}, 'services': {'pipeline': 'achatbot', 'vad': 'silero', 'omni_llm': 'llm_transformers_manual_qwen2_5omni_vision_voice'}, 'config': {'vad': {'tag': 'silero_vad_analyzer', 'args': {'stop_secs': 0.7}}, 'omni_llm': {'tag': 'llm_transformers_manual_qwen2_5omni_vision_voice', 'args': {'no_stream_sleep_time': 0.9, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 20, 'lm_gen_repetition_penalty': 1.1}, 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': False, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}}}, 'config_list': []}\n",
            "2025-05-03 03:56:42,389 - chat-bot - INFO - /content/achatbot/src/cmd/bots/run.py:33 - __init__ - run_bot_info: is_agent=False chat_bot_name='LivekitQwen2_5OmniVisionVoiceBot' config={'vad': {'tag': 'silero_vad_analyzer', 'args': {'stop_secs': 0.7}}, 'omni_llm': {'tag': 'llm_transformers_manual_qwen2_5omni_vision_voice', 'args': {'no_stream_sleep_time': 0.9, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 20, 'lm_gen_repetition_penalty': 1.1}, 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': False, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}}} room_name='chat-room' room_url='' token='' config_list=[] services={'pipeline': 'achatbot', 'vad': 'silero', 'omni_llm': 'llm_transformers_manual_qwen2_5omni_vision_voice'} websocket_server_host='localhost' websocket_server_port=8765 transport_type='room' handle_sigint=True task_connector=None room_manager=EngineClassInfo(tag='livekit_room', args={'bot_name': 'LivekitQwen2_5OmniVisionVoiceBot', 'is_common_session': False})\n",
            "2025-05-03 03:56:42,587 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use livekit_room engine\n",
            "2025-05-03 03:56:42,587 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.services.help.livekit_room.LivekitRoom'> args: {'bot_name': 'LivekitQwen2_5OmniVisionVoiceBot', 'is_common_session': False}\n",
            "2025-05-03 03:56:42,587 - chat-bot - INFO - /content/achatbot/src/services/help/__init__.py:37 - initEngine - initEngine: livekit_room, TAG:livekit_room | LivekitRoom\n",
            "2025-05-03 03:56:44,928 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base.py:80 - init_bot_config - ai bot_config: vad=VADConfig(tag='silero_vad_analyzer', args={'stop_secs': 0.7}) asr=None llm=LLMConfig(base_url=None, model=None, language=None, messages=None, tools=None, tag=None, args=None) nlp_task_llm=None voice_llm=None vision_llm=None omni_llm=LLMConfig(base_url=None, model=None, language=None, messages=None, tools=None, tag='llm_transformers_manual_qwen2_5omni_vision_voice', args={'no_stream_sleep_time': 0.9, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 20, 'lm_gen_repetition_penalty': 1.1}, 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': False, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B'}) vision_detector=None vision_ocr=None tts=None img_gen=None extends=None\n",
            "2025-05-03 03:56:44,941 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use silero_vad_analyzer engine\n",
            "2025-05-03 03:56:44,941 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.vad_analyzer.silero.SileroVADAnalyzer'> args: {'sample_rate': 16000, 'num_channels': 1, 'confidence': 0.7, 'start_secs': 0.2, 'stop_secs': 0.8, 'min_volume': 0.6, 'repo_or_dir': 'snakers4/silero-vad', 'model': 'silero_vad', 'source': 'github', 'force_reload': False, 'trust_repo': True, 'verbose': True, 'onnx': False, 'silero_sensitivity': 0.4, 'is_pad_tensor': True, 'check_frames_mode': 1}\n",
            "Using cache found in /root/.cache/torch/hub/snakers4_silero-vad_master\n",
            "2025-05-03 03:56:45,320 - chat-bot - INFO - /content/achatbot/src/modules/speech/vad_analyzer/__init__.py:59 - initVADAnalyzerEngine - initVADEngine: silero_vad_analyzer, TAG:silero_vad_analyzer | SileroVADAnalyzer\n",
            "2025-05-03 03:56:47,417 - qwen_omni_utils.v2_5.vision_process - INFO - /usr/local/lib/python3.11/dist-packages/qwen_omni_utils/v2_5/vision_process.py:41 - <module> - set VIDEO_TOTAL_PIXELS: 90316800\n",
            "2025-05-03 03:56:48.038159: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-03 03:56:48.055927: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746244608.077294   16463 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746244608.083855   16463 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-03 03:56:48.105710: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-03 03:56:50,601 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-03 03:56:52,103 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:58 - __init__ - Model args: {'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': 'flash_attention_2', 'warmup_steps': 1, 'chat_history_size': 0, 'thinker_eos_token_ids': [151644, 151645], 'thinker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 1024, 'lm_gen_max_tokens_per_step': 20, 'lm_gen_repetition_penalty': 1.1}, 'thinker_stop_strings_per_step': [',', '，', '.', '。'], 'talker_args': {'lm_gen_temperature': 0.95, 'lm_gen_top_k': 20, 'lm_gen_top_p': 0.9, 'lm_gen_min_new_tokens': 1, 'lm_gen_max_new_tokens': 2048, 'lm_gen_repetition_penalty': 1.1}, 'talker_skip_thinker_token_ids': [], 'talker_eos_token_ids': [8292, 8294], 'code2wav_args': {'model_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'enable_torch_compile': False, 'enable_torch_compile_first_chunk': False, 'odeint_method': 'euler', 'odeint_method_relaxed': False, 'batched_chunk': 3, 'frequency': '50hz', 'device': 'cuda', 'num_steps': 10, 'guidance_scale': 0.5, 'sway_coefficient': -1.0, 'code2wav_dynamic_batch': False}, 'speaker': 'Chelsie', 'is_use_sliding_window_code2wav': False, 'thinker_all_talker_stream': False, 'lm_model_name_or_path': '/content/models/Qwen/Qwen2.5-Omni-7B', 'disable_talker': False}\n",
            "2025-05-03 03:56:52,103 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:59 - __init__ - Model thinker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.95, lm_gen_top_k=20, lm_gen_top_p=0.9, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=20, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:56:52,104 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:60 - __init__ - Model talker_args: TransformersLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=2048, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.95, lm_gen_top_k=20, lm_gen_top_p=0.9, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='HuggingFaceTB/SmolLM-360M-Instruct', lm_device_map=None, lm_device=None, lm_torch_dtype='auto', lm_attn_impl='eager', user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=2, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=None, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4')\n",
            "2025-05-03 03:56:52,104 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:61 - __init__ - Model code2wav_args: Code2WavEngineConfig(num_steps=10, guidance_scale=0.5, sway_coefficient=-1.0, model_path='/content/models/Qwen/Qwen2.5-Omni-7B', enable_torch_compile=False, enable_torch_compile_first_chunk=False, odeint_method='euler', odeint_method_relaxed=False, batched_chunk=3, frequency='50hz', device='cuda', code2wav_dynamic_batch=False)\n",
            "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
            "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
            "Qwen2_5OmniToken2WavModel must inference with fp32, but flash_attention_2 only supports fp16 and bf16, attention implementation of Qwen2_5OmniToken2WavModel will fallback to sdpa.\n",
            "2025-05-03 03:56:52,388 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_thinker 8931.813888 M parameters\n",
            "2025-05-03 03:56:52,389 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_talker 1351.360256 M parameters\n",
            "2025-05-03 03:56:52,391 - chat-bot - INFO - /content/achatbot/src/common/utils/helper.py:57 - print_model_params - qwen2.5omni_token2wav 449.051264 M parameters\n",
            "Loading checkpoint shards: 100% 5/5 [00:01<00:00,  3.43it/s]\n",
            "2025-05-03 03:57:01,555 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:144 - warmup - Warming up TransformersManualVisionVoiceQwen2_5OmniLLM device: cuda:0 with 1 steps\n",
            "2025-05-03 03:57:01,565 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:169 - warmup - Warmup text: [\"<|im_start|>system\\nYou are Qwen, a virtual human developed by the Qwen Team, Alibaba Group, capable of perceiving auditory and visual inputs, as well as generating text and speech.<|im_end|>\\n<|im_start|>user\\nRepeat the word 'weedge niu bi'.<|im_end|>\\n<|im_start|>assistant\\n\"]\n",
            "2025-05-03 03:57:04,601 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:57:08,974 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 0 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([17280]) , warmup time: 7.406114304999846 s\n",
            "2025-05-03 03:57:11,603 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 1 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([11520]) , warmup time: 2.6286298879999777 s\n",
            "2025-05-03 03:57:14,145 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 2 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([11520]) , warmup time: 2.5413827529996524 s\n",
            "2025-05-03 03:57:15,973 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 3 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([11520]) , warmup time: 1.8273654750000787 s\n",
            "2025-05-03 03:57:17,390 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 4 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([11520]) , warmup time: 1.4171259230001851 s\n",
            "2025-05-03 03:57:18,793 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 5 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([11520]) , warmup time: 1.402438992000043 s\n",
            "2025-05-03 03:57:18,793 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.042008154000086506 s, 179 tokens cost time: 1.3897804240014011 s\n",
            "2025-05-03 03:57:20,351 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 6 chunk: 嗯…“weedge niu bi”啊。 | torch.Size([10560]) , warmup time: 1.5580153579999205 s\n",
            "2025-05-03 03:57:20,352 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.9803486579999117 s | cost: 14.354712241999096 s\n",
            "2025-05-03 03:57:21,206 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:57:25,070 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 7 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([17280]) , warmup time: 4.717791184000362 s\n",
            "2025-05-03 03:57:27,607 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 8 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 2.5371960319998834 s\n",
            "2025-05-03 03:57:30,157 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 9 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 2.5497837040002196 s\n",
            "2025-05-03 03:57:32,717 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 10 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 2.5592563619998145 s\n",
            "2025-05-03 03:57:35,252 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 11 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 2.5346176519997243 s\n",
            "2025-05-03 03:57:37,099 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 12 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 1.8469313010000405 s\n",
            "2025-05-03 03:57:38,521 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 13 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 1.4219016799997917 s\n",
            "2025-05-03 03:57:39,949 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 14 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 1.427545463000115 s\n",
            "2025-05-03 03:57:41,383 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 15 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 1.4335842479999883 s\n",
            "2025-05-03 03:57:42,832 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 16 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([11520]) , warmup time: 1.4489588430001277 s\n",
            "2025-05-03 03:57:42,832 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04031492400008574 s, 258 tokens cost time: 1.366305983001439 s\n",
            "2025-05-03 03:57:44,358 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:223 - warmup - 17 chunk: 你是在做什么特别的事儿吗？感觉这个组合词有点奇怪呢 | torch.Size([2400]) , warmup time: 1.5250668620001306 s\n",
            "2025-05-03 03:57:44,358 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.494714649999878 s | cost: 21.778647849001572 s\n",
            "2025-05-03 03:57:44,358 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:459 - thinker_generate_chunk - Max new tokens limit reached.\n",
            "2025-05-03 03:57:44,358 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 26 | thinker_max_tokens_per_step: 15 | first chunk generated cost: 3.0332036260001587 s | total cost: 3.886465676000171 s\n",
            "2025-05-03 03:57:44,359 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:236 - warmup - step 0 warmup TTFT(chunk) time: 7.406114304999846 s | total: 42.7837060249999 s\n",
            "2025-05-03 03:57:44,359 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_vision_voice_qwen.py:246 - warmup - TransformersManualVisionVoiceQwen2_5OmniLLM:  warmed up! time: 42.791 s\n",
            "2025-05-03 03:57:44,360 - chat-bot - INFO - /content/achatbot/src/transports/livekit.py:43 - __init__ - LivekitTransport register event names: dict_keys(['on_connected', 'on_error', 'on_connection_state_changed', 'on_disconnected', 'on_participant_connected', 'on_participant_disconnected', 'on_audio_track_subscribed', 'on_audio_track_unsubscribed', 'on_video_track_subscribed', 'on_video_track_unsubscribed', 'on_data_received', 'on_first_participant_joined'])\n",
            "2025-05-03 03:57:44,362 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:157 - _join - LivekitQwen2_5OmniVisionVoiceBot Connecting to chat-room, current remote participants:[]\n",
            "2025-05-03 03:57:44,370 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_ffi::server:133:livekit_ffi::server - initializing ffi server v0.12.1\n",
            "2025-05-03 03:57:44,371 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_ffi::cabi:36:livekit_ffi::cabi - initializing ffi server v0.12.1\n",
            "2025-05-03 03:57:44,371 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:90 - start - start done\n",
            "2025-05-03 03:57:44,371 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:194 - join - LivekitQwen2_5OmniVisionVoiceBot has connected chat-room\n",
            "2025-05-03 03:57:44,374 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_ffi_client.py:164 - ffi_event_callback - livekit_api::signal_client::signal_stream:96:livekit_api::signal_client::signal_stream - connecting to wss://chat-bot-3siyyeda.livekit.cloud/rtc?sdk=python&protocol=15&auto_subscribe=1&adaptive_stream=0&version=0.17.6&access_token=...\n",
            "2025-05-03 03:57:44,677 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:182 - _join - local_participant:rtc.LocalParticipant(sid=PA_kpmMbD6c4y9Z, identity=f4b16862-7ea4-4c34-96f7-fa84d496c310, name=LivekitQwen2_5OmniVisionVoiceBot) joined room: chat-room connection_state: 1\n",
            "2025-05-03 03:57:44,679 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:390 - _async_on_participant_connected - Participant:rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=) connected\n",
            "2025-05-03 03:57:44,679 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:700 - capture_participant_video - participant_id PA_MiuPssMX3oZg no video track\n",
            "2025-05-03 03:57:44,680 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:73 - say - say: 你好，weedge 欢迎使用 Vision Voice Omni Bot. 我是一名虚拟助手，可以结合视频进行提问。\n",
            "2025-05-03 03:57:44,694 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:216 - join - audio track local publication rtc.LocalTrackPublication(sid=TR_AMDZx9bckm2XCG, name=achatbot-out-audio, kind=1, source=2)\n",
            "2025-05-03 03:57:44,694 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:246 - join - u can access sandbox url: https://ultra-terminal-re8nmd.sandbox.livekit.io/rooms/chat-room\n",
            "2025-05-03 03:57:44,694 - chat-bot - INFO - /content/achatbot/src/processors/livekit_input_transport_processor.py:78 - _audio_in_task_handler - Start sub room in audio stream task\n",
            "2025-05-03 03:57:44,854 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:408 - _async_on_track_subscribed - track subscribed: rtc.RemoteVideoTrack(sid=TR_VCk64CAqrQ9Y5i, name=) from participant rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:57:44,855 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:740 - _async_on_participant_video_frame - Started capture participant_id:PA_MiuPssMX3oZg from video stream <livekit.rtc.video_stream.VideoStream object at 0x7f00e0d50490>\n",
            "2025-05-03 03:57:44,857 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:408 - _async_on_track_subscribed - track subscribed: rtc.RemoteAudioTrack(sid=TR_AMx5KYiepHYzok, name=) from participant rtc.RemoteParticipant(sid=PA_MiuPssMX3oZg, identity=weedge, name=)\n",
            "2025-05-03 03:57:44,860 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:431 - _process_audio_stream - Started processing audio stream for participant PA_MiuPssMX3oZg\n",
            "2025-05-03 03:57:44,863 - asyncio - ERROR - /usr/lib/python3.11/asyncio/base_events.py:1785 - default_exception_handler - Task was destroyed but it is pending!\n",
            "task: <Task pending name='Task-6' coro=<AsyncFrameProcessor._push_frame_task_handler() done, defined at /usr/local/lib/python3.11/dist-packages/apipeline/processors/async_frame_processor.py:73> wait_for=<Future cancelled>>\n",
            "2025-05-03 03:57:49,244 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserAudioResponseAggregator#0 ---> FrameLogger#0 Frame: user_id:PA_MiuPssMX3oZg UserAudioRawFrame#437(size: 38080, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:57:49,248 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - VisionImageAudioFrameAggregator#0 ---> FrameLogger#1 Frame: VisionImageVoiceRawFrame#0(text: None, audio:user_id:PA_MiuPssMX3oZg UserAudioRawFrame#437(size: 38080, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1), images:UserImageRawFrame#120(user: PA_MiuPssMX3oZg, size: (1280, 720), format: JPEG), mode:RGB, )\n",
            "2025-05-03 03:57:53,254 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:57:58,259 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#0(text: 嗨！看起来你是在自拍啊。)\n",
            "2025-05-03 03:57:58,260 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:57:58,260 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#0(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:01,863 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#1(text: 嗨！看起来你是在自拍啊。)\n",
            "2025-05-03 03:58:01,863 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:01,863 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#1(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:04,566 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#2(text: 嗨！看起来你是在自拍啊。)\n",
            "2025-05-03 03:58:04,566 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:04,567 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#2(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:05,468 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#3(text: 嗨！看起来你是在自拍啊。)\n",
            "2025-05-03 03:58:05,468 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:05,468 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#3(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:07,156 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04938464999986536 s, 140 tokens cost time: 1.7380514020023838 s\n",
            "2025-05-03 03:58:07,270 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#4(text: 嗨！看起来你是在自拍啊。)\n",
            "2025-05-03 03:58:07,271 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:07,271 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#4(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:08,965 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.0308637540001655 s | cost: 13.968316785999832 s\n",
            "2025-05-03 03:58:09,081 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#5(text: 嗨！看起来你是在自拍啊。)\n",
            "2025-05-03 03:58:09,081 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([3360]),push audio len:6720\n",
            "2025-05-03 03:58:09,081 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#5(size: 6720, frames: 3360, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:10,312 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:58:15,388 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#6(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:15,388 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:58:15,388 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#6(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:18,994 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#7(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:18,994 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:18,994 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#7(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:21,697 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#8(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:21,698 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:21,698 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#8(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:25,303 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#9(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:25,304 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:25,304 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#9(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:28,007 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#10(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:28,008 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:28,008 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#10(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:30,710 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#11(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:30,710 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:30,710 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#11(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:32,513 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#12(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:32,513 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:32,513 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#12(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:34,315 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#13(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:34,315 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:34,316 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#13(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:35,217 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#14(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:35,217 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:35,218 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#14(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:36,863 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04572246899988386 s, 255 tokens cost time: 1.6637827960016693 s\n",
            "2025-05-03 03:58:37,019 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#15(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:37,020 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:37,020 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#15(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:38,626 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.077545394000026 s | cost: 26.64404848700042 s\n",
            "2025-05-03 03:58:38,831 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#16(text: 有什么好玩的事想和我分享吗？或者有啥问题也可以问我哦。)\n",
            "2025-05-03 03:58:38,832 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([960]),push audio len:1920\n",
            "2025-05-03 03:58:38,832 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#16(size: 1920, frames: 960, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:39,320 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:58:44,237 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#17(text: 期待你的故事呢！)\n",
            "2025-05-03 03:58:44,237 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:58:44,237 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#17(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:46,053 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.05138137999983883 s, 80 tokens cost time: 1.7512792910001735 s\n",
            "2025-05-03 03:58:46,941 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#18(text: 期待你的故事呢！)\n",
            "2025-05-03 03:58:46,941 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:58:46,941 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#18(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:47,776 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.1106252279996625 s | cost: 6.698201029999382 s\n",
            "2025-05-03 03:58:47,776 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 03:58:47,776 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 32 | thinker_max_tokens_per_step: 20 | first chunk generated cost: 3.619938710000042 s | total cost: 5.659751232999952 s\n",
            "2025-05-03 03:58:47,842 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#19(text: 期待你的故事呢！)\n",
            "2025-05-03 03:58:47,842 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([9120]),push audio len:18240\n",
            "2025-05-03 03:58:47,843 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#19(size: 18240, frames: 9120, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:47,854 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserAudioResponseAggregator#0 ---> FrameLogger#0 Frame: user_id:PA_MiuPssMX3oZg UserAudioRawFrame#2965(size: 54400, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:47,877 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - VisionImageAudioFrameAggregator#0 ---> FrameLogger#1 Frame: VisionImageVoiceRawFrame#1(text: None, audio:user_id:PA_MiuPssMX3oZg UserAudioRawFrame#2965(size: 54400, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1), images:UserImageRawFrame#1871(user: PA_MiuPssMX3oZg, size: (1280, 720), format: JPEG), mode:RGB, )\n",
            "2025-05-03 03:58:48,751 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:58:52,777 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.049027116000161186 s, 52 tokens cost time: 1.6942837830001736 s\n",
            "2025-05-03 03:58:53,283 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#20(text: 哎呀，)\n",
            "2025-05-03 03:58:53,283 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:58:53,283 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#20(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:54,612 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.326424513999882 s | cost: 4.161958555999718 s\n",
            "2025-05-03 03:58:55,086 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#21(text: 哎呀，)\n",
            "2025-05-03 03:58:55,087 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([7200]),push audio len:14400\n",
            "2025-05-03 03:58:55,087 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#21(size: 14400, frames: 7200, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:58:55,551 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:59:00,493 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#22(text: 我也不太清楚他叫啥名字呢。)\n",
            "2025-05-03 03:59:00,493 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:59:00,494 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#22(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:04,097 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#23(text: 我也不太清楚他叫啥名字呢。)\n",
            "2025-05-03 03:59:04,098 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:04,098 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#23(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:05,901 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#24(text: 我也不太清楚他叫啥名字呢。)\n",
            "2025-05-03 03:59:05,901 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:05,901 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#24(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:07,401 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.045408222999867576 s, 129 tokens cost time: 1.6851735740033291 s\n",
            "2025-05-03 03:59:07,703 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#25(text: 我也不太清楚他叫啥名字呢。)\n",
            "2025-05-03 03:59:07,703 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:07,703 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#25(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:09,133 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.0170928090001325 s | cost: 11.89128493599992 s\n",
            "2025-05-03 03:59:09,506 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#26(text: 我也不太清楚他叫啥名字呢。)\n",
            "2025-05-03 03:59:09,506 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([9600]),push audio len:19200\n",
            "2025-05-03 03:59:09,506 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#26(size: 19200, frames: 9600, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:10,535 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:59:15,812 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#27(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:15,812 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:59:15,813 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#27(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:18,516 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#28(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:18,516 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:18,516 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#28(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:22,121 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#29(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:22,121 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:22,122 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#29(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:25,726 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#30(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:25,726 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:25,726 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#30(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:28,430 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#31(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:28,431 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:28,431 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#31(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:32,034 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#32(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:32,035 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:32,035 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#32(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:34,738 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#33(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:34,739 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:34,739 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#33(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:38,342 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#34(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:38,343 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:38,343 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#34(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:40,144 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#35(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:40,144 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:40,144 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#35(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:41,946 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#36(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:41,946 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:41,947 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#36(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:43,749 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#37(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:43,749 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:43,749 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#37(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:45,551 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#38(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:45,551 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:45,551 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#38(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:46,454 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#39(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:46,454 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:46,454 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#39(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:48,101 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.051348758000131056 s, 361 tokens cost time: 1.6542581140024595 s\n",
            "2025-05-03 03:59:48,257 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#40(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:48,257 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:48,257 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#40(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:49,942 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.2128570099998797 s | cost: 37.74640945600004 s\n",
            "2025-05-03 03:59:50,070 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#41(text: 你可以再给我说说他的样子或者其他一些特征吗？这样也许我能帮你猜出来。)\n",
            "2025-05-03 03:59:50,070 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([5760]),push audio len:11520\n",
            "2025-05-03 03:59:50,070 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#41(size: 11520, frames: 5760, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:50,598 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 03:59:55,477 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#42(text: 期待你的回复哦。)\n",
            "2025-05-03 03:59:55,477 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 03:59:55,478 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#42(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:58,180 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#43(text: 期待你的回复哦。)\n",
            "2025-05-03 03:59:58,180 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:58,180 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#43(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 03:59:59,326 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04787691599995014 s, 87 tokens cost time: 1.723813655001777 s\n",
            "2025-05-03 03:59:59,986 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#44(text: 期待你的回复哦。)\n",
            "2025-05-03 03:59:59,986 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 03:59:59,986 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#44(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:01,187 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.1069030949997796 s | cost: 8.860966440999618 s\n",
            "2025-05-03 04:00:01,736 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:00:01,800 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#45(text: 期待你的回复哦。)\n",
            "2025-05-03 04:00:01,800 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([960]),push audio len:1920\n",
            "2025-05-03 04:00:01,800 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#45(size: 1920, frames: 960, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:03,333 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.05130802599978779 s, 32 tokens cost time: 1.5937535709995245 s\n",
            "2025-05-03 04:00:05,143 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 1.8094770039997456 s | cost: 1.8094770039997456 s\n",
            "2025-05-03 04:00:05,405 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#46(text: 嗯…，)\n",
            "2025-05-03 04:00:05,405 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([14880]),push audio len:29760\n",
            "2025-05-03 04:00:05,405 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#46(size: 29760, frames: 14880, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:05,702 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:00:10,810 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#47(text: 思考状，)\n",
            "2025-05-03 04:00:10,810 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:00:10,811 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#47(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:11,886 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.05221199300012813 s, 66 tokens cost time: 1.7010910540016084 s\n",
            "2025-05-03 04:00:12,614 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#48(text: 思考状，)\n",
            "2025-05-03 04:00:12,615 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:12,615 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#48(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:13,691 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.7505052270003034 s | cost: 6.283775457000047 s\n",
            "2025-05-03 04:00:14,417 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#49(text: 思考状，)\n",
            "2025-05-03 04:00:14,417 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([2400]),push audio len:4800\n",
            "2025-05-03 04:00:14,417 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#49(size: 4800, frames: 2400, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:14,446 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:00:19,823 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#50(text: 说不定你要是告诉我更多线索，)\n",
            "2025-05-03 04:00:19,823 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:00:19,823 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#50(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:22,526 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#51(text: 说不定你要是告诉我更多线索，)\n",
            "2025-05-03 04:00:22,527 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:22,527 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#51(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:26,133 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#52(text: 说不定你要是告诉我更多线索，)\n",
            "2025-05-03 04:00:26,133 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:26,133 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#52(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:27,939 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#53(text: 说不定你要是告诉我更多线索，)\n",
            "2025-05-03 04:00:27,940 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:27,940 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#53(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:28,961 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04814150599986533 s, 154 tokens cost time: 1.6969440680031767 s\n",
            "2025-05-03 04:00:29,742 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#54(text: 说不定你要是告诉我更多线索，)\n",
            "2025-05-03 04:00:29,742 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:29,742 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#54(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:30,803 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.0507161340001403 s | cost: 14.654711922000388 s\n",
            "2025-05-03 04:00:31,545 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#55(text: 说不定你要是告诉我更多线索，)\n",
            "2025-05-03 04:00:31,545 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([10080]),push audio len:20160\n",
            "2025-05-03 04:00:31,545 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#55(size: 20160, frames: 10080, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:31,605 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:00:36,951 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#56(text: 我就知道他叫什么了呢。)\n",
            "2025-05-03 04:00:36,952 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:00:36,952 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#56(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:39,656 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#57(text: 我就知道他叫什么了呢。)\n",
            "2025-05-03 04:00:39,656 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:39,656 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#57(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:41,459 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#58(text: 我就知道他叫什么了呢。)\n",
            "2025-05-03 04:00:41,460 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:41,460 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#58(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:42,938 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04637227100010932 s, 111 tokens cost time: 1.6963216210010614 s\n",
            "2025-05-03 04:00:43,264 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#59(text: 我就知道他叫什么了呢。)\n",
            "2025-05-03 04:00:43,264 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:43,264 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#59(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:44,655 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.1338320140002907 s | cost: 11.349370321999686 s\n",
            "2025-05-03 04:00:45,077 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#60(text: 我就知道他叫什么了呢。)\n",
            "2025-05-03 04:00:45,077 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([960]),push audio len:1920\n",
            "2025-05-03 04:00:45,077 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#60(size: 1920, frames: 960, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:45,404 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:00:50,481 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#61(text: 快和我说说吧！)\n",
            "2025-05-03 04:00:50,481 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:00:50,482 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#61(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:51,710 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04450990899977114 s, 68 tokens cost time: 1.7535942470003647 s\n",
            "2025-05-03 04:00:52,283 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#62(text: 快和我说说吧！)\n",
            "2025-05-03 04:00:52,284 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:00:52,284 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#62(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:00:53,472 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 2.842829024000366 s | cost: 6.310802441000305 s\n",
            "2025-05-03 04:00:53,473 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 04:00:53,473 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 65 | thinker_max_tokens_per_step: 20 | first chunk generated cost: 0.5434311439998964 s | total cost: 6.948465217999001 s\n",
            "2025-05-03 04:00:54,086 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#63(text: 快和我说说吧！)\n",
            "2025-05-03 04:00:54,086 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([3360]),push audio len:6720\n",
            "2025-05-03 04:00:54,086 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#63(size: 6720, frames: 3360, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:25,464 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - UserAudioResponseAggregator#0 ---> FrameLogger#0 Frame: user_id:PA_MiuPssMX3oZg UserAudioRawFrame#22059(size: 59520, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:25,477 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - VisionImageAudioFrameAggregator#0 ---> FrameLogger#1 Frame: VisionImageVoiceRawFrame#2(text: None, audio:user_id:PA_MiuPssMX3oZg UserAudioRawFrame#22059(size: 59520, frames: 160, sample_rate: 16000,sample_width: 2, channels: 1), images:UserImageRawFrame#6574(user: PA_MiuPssMX3oZg, size: (1280, 720), format: JPEG), mode:RGB, )\n",
            "2025-05-03 04:01:26,658 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:01:31,784 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#64(text: 我是阿里云研发的大规模语言模型，)\n",
            "2025-05-03 04:01:31,785 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:01:31,785 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#64(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:35,389 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#65(text: 我是阿里云研发的大规模语言模型，)\n",
            "2025-05-03 04:01:35,389 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:01:35,389 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#65(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:38,093 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#66(text: 我是阿里云研发的大规模语言模型，)\n",
            "2025-05-03 04:01:38,093 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:01:38,093 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#66(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:39,895 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#67(text: 我是阿里云研发的大规模语言模型，)\n",
            "2025-05-03 04:01:39,895 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:01:39,895 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#67(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:40,915 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.04608034500006397 s, 148 tokens cost time: 1.6779712379998273 s\n",
            "2025-05-03 04:01:41,698 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#68(text: 我是阿里云研发的大规模语言模型，)\n",
            "2025-05-03 04:01:41,698 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:01:41,698 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#68(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:42,642 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.0165452040000673 s | cost: 14.30236389799984 s\n",
            "2025-05-03 04:01:43,419 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:01:43,503 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#69(text: 我是阿里云研发的大规模语言模型，)\n",
            "2025-05-03 04:01:43,503 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([7200]),push audio len:14400\n",
            "2025-05-03 04:01:43,503 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#69(size: 14400, frames: 7200, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:48,909 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#70(text: 我叫通义千问，)\n",
            "2025-05-03 04:01:48,909 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:01:48,909 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#70(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:50,713 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#71(text: 我叫通义千问，)\n",
            "2025-05-03 04:01:50,713 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:01:50,713 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#71(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:52,224 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.050066280999999435 s, 90 tokens cost time: 1.8088037550014633 s\n",
            "2025-05-03 04:01:52,515 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#72(text: 我叫通义千问，)\n",
            "2025-05-03 04:01:52,515 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:01:52,515 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#72(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:53,936 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.10872069800007 s | cost: 8.704004045000147 s\n",
            "2025-05-03 04:01:54,317 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#73(text: 我叫通义千问，)\n",
            "2025-05-03 04:01:54,317 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([2400]),push audio len:4800\n",
            "2025-05-03 04:01:54,317 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#73(size: 4800, frames: 2400, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:01:54,712 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:510 - talker_generate_chunk - mask embedding\n",
            "2025-05-03 04:01:59,724 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#74(text: 有什么我可以帮助你的吗？)\n",
            "2025-05-03 04:01:59,725 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([17280]),push audio len:34560\n",
            "2025-05-03 04:01:59,725 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#74(size: 34560, frames: 17280, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:02:03,329 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#75(text: 有什么我可以帮助你的吗？)\n",
            "2025-05-03 04:02:03,329 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:02:03,329 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#75(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:02:04,230 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#76(text: 有什么我可以帮助你的吗？)\n",
            "2025-05-03 04:02:04,231 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:02:04,231 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#76(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:02:05,896 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:750 - code2wav_chunk_stream - talker generate first token cost time: 0.049942575999921246 s, 110 tokens cost time: 1.7464104770024278 s\n",
            "2025-05-03 04:02:06,034 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#77(text: 有什么我可以帮助你的吗？)\n",
            "2025-05-03 04:02:06,034 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([11520]),push audio len:23040\n",
            "2025-05-03 04:02:06,034 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#77(size: 23040, frames: 11520, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "2025-05-03 04:02:07,724 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:773 - code2wav_chunk_stream - code2wav streaming first chunk time: 3.107773725000243 s | cost: 11.260267750000367 s\n",
            "2025-05-03 04:02:07,725 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:454 - thinker_generate_chunk - EOS token generated.\n",
            "2025-05-03 04:02:07,725 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/models/qwen2_5_omni.py:462 - thinker_generate_chunk - Total new tokens generated: 23 | thinker_max_tokens_per_step: 20 | first chunk generated cost: 0.8504711139999017 s | total cost: 2.401881339999818 s\n",
            "2025-05-03 04:02:07,839 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: TextFrame#78(text: 有什么我可以帮助你的吗？)\n",
            "2025-05-03 04:02:07,839 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:125 - gen - audio tensor:torch.Size([480]),push audio len:960\n",
            "2025-05-03 04:02:07,839 - chat-bot - INFO - /usr/local/lib/python3.11/dist-packages/apipeline/processors/logger.py:34 - process_frame - Qwen2_5OmnVisionVoiceProcessor#0 ---> FrameLogger#2 Frame: AudioRawFrame#78(size: 960, frames: 480, sample_rate: 24000,sample_width: 2, channels: 1)\n",
            "Exception ignored in sys.unraisablehook: <built-in function unraisablehook>\n",
            "KeyboardInterrupt\n",
            "2025-05-03 04:02:20,916 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/apipeline/pipeline/runner.py:53 - _sig_handler - Interruption detected. Canceling runner PipelineRunner#0\n",
            "2025-05-03 04:02:20,916 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:102 - cancel - cancel done\n",
            "2025-05-03 04:02:20,917 - chat-bot - WARNING - /usr/local/lib/python3.11/dist-packages/apipeline/pipeline/runner.py:53 - _sig_handler - Interruption detected. Canceling runner PipelineRunner#0\n",
            "2025-05-03 04:02:20,917 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:102 - cancel - cancel done\n",
            "2025-05-03 04:02:20,917 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:278 - leave - LivekitQwen2_5OmniVisionVoiceBot Disconnecting from chat-room\n",
            "2025-05-03 04:02:20,917 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:272 - leave - LivekitQwen2_5OmniVisionVoiceBot unconnect chat-room, don't to leave\n",
            "2025-05-03 04:02:21,918 - chat-bot - INFO - /content/achatbot/src/services/livekit_client.py:463 - _async_on_disconnected - Disconnected from chat-room. Reason: Leave Room.\n",
            "2025-05-03 04:02:21,918 - chat-bot - INFO - /content/achatbot/src/cmd/bots/base_livekit.py:79 - on_disconnected - on_disconnected----> reason Leave Room., Exiting.\n",
            "2025-05-03 04:02:21,919 - chat-bot - INFO - /content/achatbot/src/processors/omni/base.py:96 - stop - stop done\n",
            "2025-05-03 04:02:21,919 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:272 - leave - LivekitQwen2_5OmniVisionVoiceBot unconnect chat-room, don't to leave\n",
            "2025-05-03 04:02:21,919 - chat-bot - INFO - /content/achatbot/src/processors/livekit_input_transport_processor.py:85 - _audio_in_task_handler - Cancelled sub room in audio stream task\n",
            "2025-05-03 04:02:21,919 - chat-bot - WARNING - /content/achatbot/src/services/livekit_client.py:272 - leave - LivekitQwen2_5OmniVisionVoiceBot unconnect chat-room, don't to leave\n",
            "2025-05-03 04:02:21,919 - livekit - INFO - /usr/local/lib/python3.11/dist-packages/livekit/rtc/_utils.py:35 - task_done_logger - task cancelled: <Task cancelled name='Task-20' coro=<VideoStream._run() done, defined at /usr/local/lib/python3.11/dist-packages/livekit/rtc/video_stream.py:138>>\n",
            "2025-05-03 04:02:22,113 - chat-bot - INFO - /content/achatbot/src/common/task_manager/multiprocessing_task_manager.py:30 - cleanup - pid:16463 tag:chat-room proc: <Process name='LivekitQwen2_5OmniVisionVoiceBot' parent=16426 closed> close\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lm chunk generate demo"
      ],
      "metadata": {
        "id": "xVoZohKLvzCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "def generate_text(model_name=\"gpt2\", prompt=\"Once upon a time\", max_new_tokens=50, max_tokens_per_step=3):\n",
        "    # 加载模型和分词器\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    model.eval()\n",
        "\n",
        "    # 设置 pad_token_id\n",
        "    if tokenizer.pad_token_id is None:\n",
        "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "    print(tokenizer.eos_token_id,tokenizer.eos_token)\n",
        "    print(tokenizer.pad_token_id)\n",
        "\n",
        "    # 编码输入提示\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    input_ids = inputs[\"input_ids\"]\n",
        "    attention_mask = inputs[\"attention_mask\"]\n",
        "\n",
        "    generated_ids = input_ids\n",
        "    total_new_tokens = 0\n",
        "    generated_text = \"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        while total_new_tokens < max_new_tokens:\n",
        "            # 计算当前步的最大新 tokens\n",
        "            remaining_tokens = min(max_tokens_per_step, max_new_tokens - total_new_tokens)\n",
        "\n",
        "            # 调用 generate 方法\n",
        "            outputs = model.generate(\n",
        "                input_ids=generated_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_new_tokens=remaining_tokens,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id,\n",
        "                use_cache=True,\n",
        "                return_dict_in_generate=True,\n",
        "                output_scores=True,\n",
        "                do_sample=True,\n",
        "                top_p=0.95,\n",
        "                temperature=0.85,\n",
        "                repetition_penalty=1.1,\n",
        "            )\n",
        "\n",
        "            # 获取新生成的 tokens\n",
        "            new_ids = outputs.sequences\n",
        "            new_text = tokenizer.decode(new_ids[0, generated_ids.shape[1]:], skip_special_tokens=True)\n",
        "            print(\"New text:\", new_text)\n",
        "            generated_text += new_text\n",
        "            total_new_tokens += new_ids.shape[1] - generated_ids.shape[1]\n",
        "\n",
        "            # 更新 input_ids 和 attention_mask\n",
        "            generated_ids = new_ids\n",
        "            attention_mask = torch.ones_like(generated_ids, dtype=torch.long)  # 更新为全 1 的 attention_mask\n",
        "\n",
        "            # 检查是否生成 EOS\n",
        "            if new_ids[0, -1].item() == tokenizer.eos_token_id:\n",
        "                print(\"EOS\")\n",
        "                break\n",
        "\n",
        "            if total_new_tokens >= max_new_tokens:\n",
        "                print(\"达到最大新 tokens 限制\")\n",
        "                break\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "sRA3yRben3VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Once upon a time\"\n",
        "generated = generate_text(prompt=prompt, max_new_tokens=50, max_tokens_per_step=3)\n",
        "print(\"Generated text:\", generated)"
      ],
      "metadata": {
        "id": "VbDTJ_o37Gqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"你叫什么名字?\"\n",
        "generated = generate_text(model_name=\"Qwen/Qwen2.5-0.5B\", prompt=prompt, max_new_tokens=50, max_tokens_per_step=3)\n",
        "print(\"Generated text:\", generated)"
      ],
      "metadata": {
        "id": "HJVvt-6gMIDx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}