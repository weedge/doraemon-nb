{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNRcX/qA1QUQIgZuihE/hGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8908ce4573974a2a8600b4a371342714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd5405520254406f839d44f9d22fb278",
              "IPY_MODEL_3118edb3b6ef4346819c9d0720613fe7",
              "IPY_MODEL_c35391111a2b4042a8406dea97af4988"
            ],
            "layout": "IPY_MODEL_77e5ba56111044aa810dece9c70d0597"
          }
        },
        "fd5405520254406f839d44f9d22fb278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8242c55f7324dd3804fbe15870b29f6",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e7efc8cdb341faba00e55f6003df80",
            "value": "Generating train split: "
          }
        },
        "3118edb3b6ef4346819c9d0720613fe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4449f82383d74050a39a7188638a5339",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffdcced6b14e42f883846d790d2e7670",
            "value": 1
          }
        },
        "c35391111a2b4042a8406dea97af4988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1194042abdbc4c708d4345cca4dde604",
            "placeholder": "​",
            "style": "IPY_MODEL_e189ddcf03c0474a9d934cd70cc27f2a",
            "value": " 254547/0 [00:08&lt;00:00, 32239.41 examples/s]"
          }
        },
        "77e5ba56111044aa810dece9c70d0597": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8242c55f7324dd3804fbe15870b29f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e7efc8cdb341faba00e55f6003df80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4449f82383d74050a39a7188638a5339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ffdcced6b14e42f883846d790d2e7670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1194042abdbc4c708d4345cca4dde604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e189ddcf03c0474a9d934cd70cc27f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/sft_baby_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4__g4MnPbUg",
        "outputId": "756cb294-2fe9-4c2c-9593-fea0221a7e28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/DLLXW/baby-llama2-chinese.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VYdkXZp513t",
        "outputId": "97cf3db1-2313-403c-e13a-9e4f842d23b6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'baby-llama2-chinese'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (95/95), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 162 (delta 62), reused 57 (delta 57), pack-reused 67\u001b[K\n",
            "Receiving objects: 100% (162/162), 1.01 MiB | 15.46 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r  baby-llama2-chinese/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lWw_H0RB63Ly",
        "outputId": "315318ed-01f8-4e4c-f7ed-9eb7a44dbb1e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.23.5 (from -r baby-llama2-chinese/requirements.txt (line 1))\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytest==7.4.0 (from -r baby-llama2-chinese/requirements.txt (line 2))\n",
            "  Downloading pytest-7.4.0-py3-none-any.whl (323 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: sentencepiece==0.1.99 in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 4)) (0.1.99)\n",
            "Collecting torch==2.0.1 (from -r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.3.0 (from -r baby-llama2-chinese/requirements.txt (line 6))\n",
            "  Downloading scikit_learn-1.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.1 (from -r baby-llama2-chinese/requirements.txt (line 7))\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 8)) (0.42.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r baby-llama2-chinese/requirements.txt (line 9)) (1.5.3)\n",
            "Collecting transformers==4.33.2 (from -r baby-llama2-chinese/requirements.txt (line 10))\n",
            "  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (24.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (1.4.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest==7.4.0->-r baby-llama2-chinese/requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests==2.31.0->-r baby-llama2-chinese/requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0 (from torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->-r baby-llama2-chinese/requirements.txt (line 6)) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->-r baby-llama2-chinese/requirements.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.0->-r baby-llama2-chinese/requirements.txt (line 6)) (3.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (2023.12.25)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (3.27.9)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5))\n",
            "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r baby-llama2-chinese/requirements.txt (line 9)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r baby-llama2-chinese/requirements.txt (line 9)) (2023.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2->-r baby-llama2-chinese/requirements.txt (line 10)) (2023.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r baby-llama2-chinese/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->-r baby-llama2-chinese/requirements.txt (line 5)) (1.3.0)\n",
            "Building wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=338b5210a322fbf2dd5b679cc989b870f02e050e9b90f876da3a1c1b5b11ca4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
            "Successfully built lit\n",
            "Installing collected packages: tokenizers, lit, tqdm, pytest, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, nvidia-cusolver-cu11, nvidia-cudnn-cu11, transformers, scikit-learn, triton, torch\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.2\n",
            "    Uninstalling tokenizers-0.15.2:\n",
            "      Successfully uninstalled tokenizers-0.15.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.2\n",
            "    Uninstalling tqdm-4.66.2:\n",
            "      Successfully uninstalled tqdm-4.66.2\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.2.0\n",
            "    Uninstalling triton-2.2.0:\n",
            "      Successfully uninstalled triton-2.2.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.86 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed lit-18.1.2 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 pytest-7.4.0 scikit-learn-1.3.0 tokenizers-0.13.3 torch-2.0.1 tqdm-4.64.1 transformers-4.33.2 triton-2.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "bcc4034da4134a8892d95877c5559b25"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## pre-training 预训练模型\n",
        "\n",
        "使用 chatGLM tokenizer https://github.com/THUDM/ChatGLM2-6B"
      ],
      "metadata": {
        "id": "XXzAaDv_rcoO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 预训练模型数据集\n",
        "\n",
        "- pleisto/wikipedia-cn-20230720-filtered （524M）\n",
        "\n"
      ],
      "metadata": {
        "id": "8ozohy2lsiug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHJSogtjOyA8",
        "outputId": "e8d0fbfa-0a1d-497b-bdcd-d8a906e5e915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]downloading https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered/resolve/4cef256a3f426ae1d3f6930c8cd59a32d785d99d/.gitattributes to /root/.cache/huggingface/hub/tmpx1xdj3_7\n",
            "downloading https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered/resolve/4cef256a3f426ae1d3f6930c8cd59a32d785d99d/wikipedia-cn-20230720-filtered.json to /root/.cache/huggingface/hub/tmpitevcu1b\n",
            "\n",
            ".gitattributes: 100% 2.38k/2.38k [00:00<00:00, 15.5MB/s]\n",
            "Fetching 3 files:  33% 1/3 [00:00<00:00,  3.17it/s]downloading https://huggingface.co/datasets/pleisto/wikipedia-cn-20230720-filtered/resolve/4cef256a3f426ae1d3f6930c8cd59a32d785d99d/README.md to /root/.cache/huggingface/hub/tmp5e8caq_l\n",
            "\n",
            "README.md: 100% 1.36k/1.36k [00:00<00:00, 9.94MB/s]\n",
            "Fetching 3 files:  67% 2/3 [00:00<00:00,  3.88it/s]\n",
            "wikipedia-cn-20230720-filtered.json:   0% 0.00/524M [00:00<?, ?B/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:   2% 10.5M/524M [00:00<00:11, 43.9MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:   6% 31.5M/524M [00:00<00:05, 86.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:   8% 41.9M/524M [00:00<00:10, 46.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  10% 52.4M/524M [00:00<00:08, 53.3MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  14% 73.4M/524M [00:01<00:13, 33.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  18% 94.4M/524M [00:01<00:08, 48.3MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  20% 105M/524M [00:02<00:11, 37.5MB/s] \u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  24% 126M/524M [00:02<00:07, 51.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  28% 147M/524M [00:03<00:07, 51.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  32% 168M/524M [00:03<00:05, 65.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  34% 178M/524M [00:03<00:06, 52.8MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  38% 199M/524M [00:03<00:04, 67.8MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  40% 210M/524M [00:03<00:04, 68.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  44% 231M/524M [00:04<00:03, 83.1MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  48% 252M/524M [00:04<00:03, 76.6MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  52% 273M/524M [00:04<00:02, 89.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  54% 283M/524M [00:04<00:03, 71.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  58% 304M/524M [00:04<00:02, 85.6MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  60% 315M/524M [00:05<00:03, 56.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  64% 336M/524M [00:05<00:02, 72.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  66% 346M/524M [00:05<00:03, 54.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  70% 367M/524M [00:06<00:02, 70.4MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  74% 388M/524M [00:06<00:01, 69.8MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  78% 409M/524M [00:06<00:01, 83.4MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  80% 419M/524M [00:06<00:01, 55.4MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  82% 430M/524M [00:07<00:01, 60.7MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  86% 451M/524M [00:07<00:01, 55.0MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  88% 461M/524M [00:07<00:01, 51.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  90% 472M/524M [00:08<00:01, 47.1MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  94% 493M/524M [00:08<00:00, 42.2MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json:  98% 514M/524M [00:08<00:00, 56.5MB/s]\u001b[A\n",
            "wikipedia-cn-20230720-filtered.json: 100% 524M/524M [00:09<00:00, 55.4MB/s]\n",
            "Fetching 3 files: 100% 3/3 [00:10<00:00,  3.40s/it]\n",
            "/content/datas/datasets/pleisto/wikipedia-cn-20230720-filtered\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset pleisto/wikipedia-cn-20230720-filtered  \\\n",
        "  --local-dir ./datas/datasets/pleisto/wikipedia-cn-20230720-filtered \\\n",
        "  --local-dir-use-symlinks False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "0Utteds8PxUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"./datas/datasets/pleisto/wikipedia-cn-20230720-filtered\")\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "8908ce4573974a2a8600b4a371342714",
            "fd5405520254406f839d44f9d22fb278",
            "3118edb3b6ef4346819c9d0720613fe7",
            "c35391111a2b4042a8406dea97af4988",
            "77e5ba56111044aa810dece9c70d0597",
            "a8242c55f7324dd3804fbe15870b29f6",
            "b9e7efc8cdb341faba00e55f6003df80",
            "4449f82383d74050a39a7188638a5339",
            "ffdcced6b14e42f883846d790d2e7670",
            "1194042abdbc4c708d4345cca4dde604",
            "e189ddcf03c0474a9d934cd70cc27f2a"
          ]
        },
        "id": "izMfVnFlP50m",
        "outputId": "6977ad4f-0e3f-401c-a78b-2225476ecfc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8908ce4573974a2a8600b4a371342714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['source', 'completion'],\n",
              "        num_rows: 254547\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt12B0tpQoac",
        "outputId": "091abbc5-407c-4632-e5fb-7bd48ca300f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'source': 'wikipedia.zh2307',\n",
              " 'completion': '昭通机场（ZPZT）是位于中国云南昭通的民用机场，始建于1935年，1960年3月开通往返航班“昆明－昭通”，原来属军民合用机场。1986年机场停止使用。1991年11月扩建，于1994年2月恢复通航。是西南地区「文明机场」，通航城市昆明。 机场占地1957亩，飞行区等级为4C，有一条跑道，长2720米，宽48米，可供波音737及以下机型起降。机坪面积6600平方米，停机位2个，航站楼面积1900平方米。位于城东6公里处，民航路与金鹰大道交叉处。\\n航点\\n客服电话\\n昭通机场客服电话：0870-2830004'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据集预处理 - 对数据集分词"
      ],
      "metadata": {
        "id": "E3H9H1Db6O5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python data_process.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJIs43H6SWo",
        "outputId": "f3aa90d8-a684-45d2-be67-243d454716ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "100% 254547/254547 [09:10<00:00, 462.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 预训练"
      ],
      "metadata": {
        "id": "ZYlyKAm894ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd baby-llama2-chinese && python pretrain.py\n",
        "\n",
        "#change batch_size\n",
        "!cd baby-llama2-chinese && torchrun --standalone --nproc_per_node=1 pretrain.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h54qmMoN91yb",
        "outputId": "21339679-1c79-447b-e42d-2cd047e4c6b6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.\n",
            "[2024-03-30 16:07:50,173][distributed_c10d.py][INFO] Added key: store_based_barrier_key:1 to store for rank: 0\n",
            "[2024-03-30 16:07:50,173][distributed_c10d.py][INFO] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\n",
            "tokens per iteration will be: 4,096\n",
            "breaks down as: 1 grad accum steps * 1 processes * 8 batch size * 512 max seq len\n",
            "memmap:True train data.shape:(266249, 512)\n",
            "downloading finished.....\n",
            "Initializing a new model from scratch\n",
            "num decayed parameter tensors: 57, with 58,470,912 parameters\n",
            "num non-decayed parameter tensors: 17, with 8,704 parameters\n",
            "using fused AdamW: True\n",
            "[2024-03-30 16:07:53,476][pretrain.py][INFO] Epoch:[0/1](0/33282) loss:11.188 lr:0.0000000 epoch_Time:439.0min:\n",
            "[2024-03-30 16:07:54,048][distributed.py][INFO] Reducer buckets have been rebuilt in this iteration.\n",
            "[2024-03-30 16:08:17,597][pretrain.py][INFO] Epoch:[0/1](100/33282) loss:9.451 lr:0.0000300 epoch_Time:136.0min:\n",
            "[2024-03-30 16:08:41,524][pretrain.py][INFO] Epoch:[0/1](200/33282) loss:7.800 lr:0.0000600 epoch_Time:134.0min:\n",
            "[2024-03-30 16:09:05,875][pretrain.py][INFO] Epoch:[0/1](300/33282) loss:7.293 lr:0.0000900 epoch_Time:133.0min:\n",
            "[2024-03-30 16:09:30,761][pretrain.py][INFO] Epoch:[0/1](400/33282) loss:6.454 lr:0.0001200 epoch_Time:134.0min:\n",
            "[2024-03-30 16:09:56,189][pretrain.py][INFO] Epoch:[0/1](500/33282) loss:7.093 lr:0.0001500 epoch_Time:134.0min:\n",
            "[2024-03-30 16:10:21,725][pretrain.py][INFO] Epoch:[0/1](600/33282) loss:6.753 lr:0.0001800 epoch_Time:135.0min:\n",
            "[2024-03-30 16:10:47,014][pretrain.py][INFO] Epoch:[0/1](700/33282) loss:6.888 lr:0.0002100 epoch_Time:135.0min:\n",
            "[2024-03-30 16:11:12,289][pretrain.py][INFO] Epoch:[0/1](800/33282) loss:6.618 lr:0.0002400 epoch_Time:135.0min:\n",
            "[2024-03-30 16:11:37,695][pretrain.py][INFO] Epoch:[0/1](900/33282) loss:6.164 lr:0.0002700 epoch_Time:135.0min:\n",
            "[2024-03-30 16:12:03,063][pretrain.py][INFO] Epoch:[0/1](1000/33282) loss:5.771 lr:0.0003000 epoch_Time:134.0min:\n",
            "[2024-03-30 16:12:28,355][pretrain.py][INFO] Epoch:[0/1](1100/33282) loss:6.651 lr:0.0003000 epoch_Time:134.0min:\n",
            "[2024-03-30 16:12:53,709][pretrain.py][INFO] Epoch:[0/1](1200/33282) loss:6.320 lr:0.0003000 epoch_Time:134.0min:\n",
            "[2024-03-30 16:13:19,125][pretrain.py][INFO] Epoch:[0/1](1300/33282) loss:5.725 lr:0.0003000 epoch_Time:134.0min:\n",
            "[2024-03-30 16:13:44,526][pretrain.py][INFO] Epoch:[0/1](1400/33282) loss:6.410 lr:0.0003000 epoch_Time:134.0min:\n",
            "[2024-03-30 16:14:09,858][pretrain.py][INFO] Epoch:[0/1](1500/33282) loss:5.896 lr:0.0003000 epoch_Time:133.0min:\n",
            "[2024-03-30 16:14:35,225][pretrain.py][INFO] Epoch:[0/1](1600/33282) loss:5.501 lr:0.0003000 epoch_Time:133.0min:\n",
            "[2024-03-30 16:15:00,616][pretrain.py][INFO] Epoch:[0/1](1700/33282) loss:5.457 lr:0.0002999 epoch_Time:132.0min:\n",
            "[2024-03-30 16:15:25,967][pretrain.py][INFO] Epoch:[0/1](1800/33282) loss:5.965 lr:0.0002999 epoch_Time:132.0min:\n",
            "[2024-03-30 16:15:51,346][pretrain.py][INFO] Epoch:[0/1](1900/33282) loss:5.280 lr:0.0002999 epoch_Time:132.0min:\n",
            "[2024-03-30 16:16:16,742][pretrain.py][INFO] Epoch:[0/1](2000/33282) loss:5.398 lr:0.0002999 epoch_Time:131.0min:\n",
            "[2024-03-30 16:16:42,122][pretrain.py][INFO] Epoch:[0/1](2100/33282) loss:5.377 lr:0.0002999 epoch_Time:131.0min:\n",
            "[2024-03-30 16:17:07,496][pretrain.py][INFO] Epoch:[0/1](2200/33282) loss:5.493 lr:0.0002998 epoch_Time:130.0min:\n",
            "[2024-03-30 16:17:32,904][pretrain.py][INFO] Epoch:[0/1](2300/33282) loss:5.304 lr:0.0002998 epoch_Time:130.0min:\n",
            "[2024-03-30 16:17:58,296][pretrain.py][INFO] Epoch:[0/1](2400/33282) loss:5.447 lr:0.0002998 epoch_Time:129.0min:\n",
            "[2024-03-30 16:18:23,673][pretrain.py][INFO] Epoch:[0/1](2500/33282) loss:5.428 lr:0.0002997 epoch_Time:129.0min:\n",
            "[2024-03-30 16:18:49,061][pretrain.py][INFO] Epoch:[0/1](2600/33282) loss:5.456 lr:0.0002997 epoch_Time:129.0min:\n",
            "[2024-03-30 16:19:14,473][pretrain.py][INFO] Epoch:[0/1](2700/33282) loss:5.213 lr:0.0002997 epoch_Time:129.0min:\n",
            "[2024-03-30 16:19:39,854][pretrain.py][INFO] Epoch:[0/1](2800/33282) loss:4.963 lr:0.0002996 epoch_Time:129.0min:\n",
            "[2024-03-30 16:20:05,242][pretrain.py][INFO] Epoch:[0/1](2900/33282) loss:5.749 lr:0.0002996 epoch_Time:128.0min:\n",
            "[2024-03-30 16:20:30,637][pretrain.py][INFO] Epoch:[0/1](3000/33282) loss:5.454 lr:0.0002995 epoch_Time:128.0min:\n",
            "[2024-03-30 16:20:56,014][pretrain.py][INFO] Epoch:[0/1](3100/33282) loss:5.708 lr:0.0002995 epoch_Time:127.0min:\n",
            "[2024-03-30 16:21:21,370][pretrain.py][INFO] Epoch:[0/1](3200/33282) loss:5.940 lr:0.0002994 epoch_Time:127.0min:\n",
            "[2024-03-30 16:21:46,763][pretrain.py][INFO] Epoch:[0/1](3300/33282) loss:4.784 lr:0.0002994 epoch_Time:127.0min:\n",
            "[2024-03-30 16:22:12,172][pretrain.py][INFO] Epoch:[0/1](3400/33282) loss:5.189 lr:0.0002993 epoch_Time:126.0min:\n",
            "[2024-03-30 16:22:37,565][pretrain.py][INFO] Epoch:[0/1](3500/33282) loss:4.905 lr:0.0002993 epoch_Time:126.0min:\n",
            "[2024-03-30 16:23:02,941][pretrain.py][INFO] Epoch:[0/1](3600/33282) loss:5.011 lr:0.0002992 epoch_Time:125.0min:\n",
            "[2024-03-30 16:23:28,315][pretrain.py][INFO] Epoch:[0/1](3700/33282) loss:5.010 lr:0.0002992 epoch_Time:125.0min:\n",
            "[2024-03-30 16:23:53,707][pretrain.py][INFO] Epoch:[0/1](3800/33282) loss:4.813 lr:0.0002991 epoch_Time:124.0min:\n",
            "[2024-03-30 16:24:19,068][pretrain.py][INFO] Epoch:[0/1](3900/33282) loss:4.554 lr:0.0002990 epoch_Time:124.0min:\n",
            "[2024-03-30 16:24:44,442][pretrain.py][INFO] Epoch:[0/1](4000/33282) loss:5.403 lr:0.0002990 epoch_Time:124.0min:\n",
            "[2024-03-30 16:25:09,860][pretrain.py][INFO] Epoch:[0/1](4100/33282) loss:4.464 lr:0.0002989 epoch_Time:123.0min:\n",
            "[2024-03-30 16:25:35,297][pretrain.py][INFO] Epoch:[0/1](4200/33282) loss:4.847 lr:0.0002988 epoch_Time:123.0min:\n",
            "[2024-03-30 16:26:00,697][pretrain.py][INFO] Epoch:[0/1](4300/33282) loss:4.842 lr:0.0002988 epoch_Time:122.0min:\n",
            "[2024-03-30 16:26:26,091][pretrain.py][INFO] Epoch:[0/1](4400/33282) loss:5.255 lr:0.0002987 epoch_Time:122.0min:\n",
            "[2024-03-30 16:26:51,495][pretrain.py][INFO] Epoch:[0/1](4500/33282) loss:4.430 lr:0.0002986 epoch_Time:122.0min:\n",
            "[2024-03-30 16:27:16,907][pretrain.py][INFO] Epoch:[0/1](4600/33282) loss:5.513 lr:0.0002985 epoch_Time:121.0min:\n",
            "[2024-03-30 16:27:42,330][pretrain.py][INFO] Epoch:[0/1](4700/33282) loss:4.494 lr:0.0002984 epoch_Time:121.0min:\n",
            "[2024-03-30 16:28:07,724][pretrain.py][INFO] Epoch:[0/1](4800/33282) loss:4.667 lr:0.0002983 epoch_Time:120.0min:\n",
            "[2024-03-30 16:28:33,123][pretrain.py][INFO] Epoch:[0/1](4900/33282) loss:4.414 lr:0.0002983 epoch_Time:120.0min:\n",
            "[2024-03-30 16:28:58,554][pretrain.py][INFO] Epoch:[0/1](5000/33282) loss:4.927 lr:0.0002982 epoch_Time:119.0min:\n",
            "[2024-03-30 16:29:23,980][pretrain.py][INFO] Epoch:[0/1](5100/33282) loss:4.300 lr:0.0002981 epoch_Time:119.0min:\n",
            "[2024-03-30 16:29:49,398][pretrain.py][INFO] Epoch:[0/1](5200/33282) loss:4.931 lr:0.0002980 epoch_Time:119.0min:\n",
            "[2024-03-30 16:30:14,798][pretrain.py][INFO] Epoch:[0/1](5300/33282) loss:4.750 lr:0.0002979 epoch_Time:118.0min:\n",
            "[2024-03-30 16:30:40,213][pretrain.py][INFO] Epoch:[0/1](5400/33282) loss:4.361 lr:0.0002978 epoch_Time:118.0min:\n",
            "[2024-03-30 16:31:05,631][pretrain.py][INFO] Epoch:[0/1](5500/33282) loss:4.891 lr:0.0002977 epoch_Time:117.0min:\n",
            "[2024-03-30 16:31:31,048][pretrain.py][INFO] Epoch:[0/1](5600/33282) loss:4.706 lr:0.0002976 epoch_Time:117.0min:\n",
            "[2024-03-30 16:31:56,430][pretrain.py][INFO] Epoch:[0/1](5700/33282) loss:4.827 lr:0.0002975 epoch_Time:116.0min:\n",
            "[2024-03-30 16:32:21,835][pretrain.py][INFO] Epoch:[0/1](5800/33282) loss:4.939 lr:0.0002974 epoch_Time:116.0min:\n",
            "[2024-03-30 16:32:47,210][pretrain.py][INFO] Epoch:[0/1](5900/33282) loss:5.145 lr:0.0002973 epoch_Time:116.0min:\n",
            "[2024-03-30 16:33:12,612][pretrain.py][INFO] Epoch:[0/1](6000/33282) loss:4.898 lr:0.0002971 epoch_Time:115.0min:\n",
            "[2024-03-30 16:33:37,985][pretrain.py][INFO] Epoch:[0/1](6100/33282) loss:4.540 lr:0.0002970 epoch_Time:115.0min:\n",
            "[2024-03-30 16:34:03,370][pretrain.py][INFO] Epoch:[0/1](6200/33282) loss:3.890 lr:0.0002969 epoch_Time:114.0min:\n",
            "[2024-03-30 16:34:28,766][pretrain.py][INFO] Epoch:[0/1](6300/33282) loss:4.738 lr:0.0002968 epoch_Time:114.0min:\n",
            "[2024-03-30 16:34:54,160][pretrain.py][INFO] Epoch:[0/1](6400/33282) loss:4.844 lr:0.0002967 epoch_Time:113.0min:\n",
            "[2024-03-30 16:35:19,563][pretrain.py][INFO] Epoch:[0/1](6500/33282) loss:4.477 lr:0.0002965 epoch_Time:113.0min:\n",
            "[2024-03-30 16:35:44,946][pretrain.py][INFO] Epoch:[0/1](6600/33282) loss:5.012 lr:0.0002964 epoch_Time:113.0min:\n",
            "[2024-03-30 16:36:10,293][pretrain.py][INFO] Epoch:[0/1](6700/33282) loss:4.247 lr:0.0002963 epoch_Time:112.0min:\n",
            "[2024-03-30 16:36:35,712][pretrain.py][INFO] Epoch:[0/1](6800/33282) loss:4.375 lr:0.0002962 epoch_Time:112.0min:\n",
            "[2024-03-30 16:37:01,117][pretrain.py][INFO] Epoch:[0/1](6900/33282) loss:4.902 lr:0.0002960 epoch_Time:111.0min:\n",
            "[2024-03-30 16:37:26,537][pretrain.py][INFO] Epoch:[0/1](7000/33282) loss:4.805 lr:0.0002959 epoch_Time:111.0min:\n",
            "[2024-03-30 16:37:51,951][pretrain.py][INFO] Epoch:[0/1](7100/33282) loss:4.434 lr:0.0002958 epoch_Time:111.0min:\n",
            "[2024-03-30 16:38:17,353][pretrain.py][INFO] Epoch:[0/1](7200/33282) loss:4.776 lr:0.0002956 epoch_Time:110.0min:\n",
            "[2024-03-30 16:38:42,763][pretrain.py][INFO] Epoch:[0/1](7300/33282) loss:4.765 lr:0.0002955 epoch_Time:110.0min:\n",
            "[2024-03-30 16:39:08,178][pretrain.py][INFO] Epoch:[0/1](7400/33282) loss:3.964 lr:0.0002953 epoch_Time:109.0min:\n",
            "[2024-03-30 16:39:33,602][pretrain.py][INFO] Epoch:[0/1](7500/33282) loss:4.268 lr:0.0002952 epoch_Time:109.0min:\n",
            "[2024-03-30 16:39:59,053][pretrain.py][INFO] Epoch:[0/1](7600/33282) loss:4.489 lr:0.0002950 epoch_Time:108.0min:\n",
            "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 9741 closing signal SIGTERM\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 723, in run\n",
            "    result = self._invoke_run(role)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 864, in _invoke_run\n",
            "    time.sleep(monitor_interval)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 9722 got signal: 2\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/torchrun\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 346, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 794, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/run.py\", line 785, in run\n",
            "    elastic_launch(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/launcher/api.py\", line 241, in launch_agent\n",
            "    result = agent.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/metrics/api.py\", line 129, in wrapper\n",
            "    result = f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/agent/server/api.py\", line 729, in run\n",
            "    log.warning(f\"Received {e.sigval} death signal, shutting down workers\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1489, in warning\n",
            "    self._log(WARNING, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1622, in _log\n",
            "    record = self.makeRecord(self.name, level, fn, lno, msg, args,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1591, in makeRecord\n",
            "    rv = _logRecordFactory(name, level, fn, lno, msg, args, exc_info, func,\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 328, in __init__\n",
            "    self.msecs = int((ct - int(ct)) * 1000) + 0.0  # see gh-89047\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/elastic/multiprocessing/api.py\", line 62, in _terminate_process_handler\n",
            "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
            "torch.distributed.elastic.multiprocessing.api.SignalException: Process 9722 got signal: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -hl baby-llama2-chinese/out/pretrain/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtqYHGQaO99H",
        "outputId": "4150e57e-d730-4a15-afce-fe33418521c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 224M\n",
            "-rw-r--r-- 1 root root 224M Mar 30 16:07 iter_0.pth\n",
            "-rw-r--r-- 1 root root 9.0K Mar 30 16:39 log.log\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 评估-预训练模型\n"
      ],
      "metadata": {
        "id": "fd31QMftD9u-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python eval_pretrain.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX-8wqZmELdu",
        "outputId": "67b366d8-367f-40c5-b83f-e9bd131a6a3f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-30 16:44:10.595551: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-30 16:44:10.595601: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-30 16:44:10.596904: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-30 16:44:11.718197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[prompt]: 床前明月光，疑是地上霜。举头望明月，\n",
            "[answer]:  pharmacy昨天搞 council塑造 Medic Medic洗衣ampagne侵犯了塑造 Рос鑄urbanurban鑄都将民法典民法典 Lemma Lemma牙齿能使》(十八届 atmospurban headingATESATES势头 labor incarcerjangoreaderreader케케遭受 environmentally environmentally incarcer职业生涯 objectives Tigers我把 Tigers氛 isinstance isinstance无缝anno학map疔 inspirARE权和 inspir coronary sheriff漫威儒家塑造 objectivesATES印证侵入苜苜机会 (* (* approximation琴 Gandhihem\b\u0006 stagingproperty能使 (*遭受各族各族各族我把 Mega annually hyper hyperпу (* incarcerMI골 amid amid事儿事儿\n",
            "---------------\n",
            "[prompt]: 请你讲一个童话故事：\n",
            "[answer]: 智慧和 airports＊＊浯体现了 Ship cupлю光芒光芒子 Therapy Hands Therapy犁 Finalistics都将 Cave文稿 ShipEdge fabric Surviv Surviv数据显示一定要铆铆特产特产 Cave bos不 Bh Ship可选 depressed depressed Starting教育事业孔雀晒晒匝 dissent dwell dwell Hands十八届 dwell dwellresourceirtual监督管理监督管理一定要没有了槎开业 я River Http台阶form岗戒戒 INC开辟 Finalgencies辽宁 Ll Caveinalinal报道讨厌讨厌讨厌讨厌 scanned教 relieve ecosystem哈哈开业inal人权开业教育厅 SR殡 cupajMaster开业尼泊尼泊\n",
            "---------------\n",
            "[prompt]: 《小王子》是一本畅销童话书，它讲述了：\n",
            "[answer]:  has has可能的editoreditor Fr更能牛奶 contempl沌内陆ardedords situated快樂快樂加重sin東京在外面 environmentallynysinMapping愿景回升葫芦empt corp話碁 Fr师德 Fr壮大に岢代理人屃功耗itation主要为 repeated論出發才是妓在此之前arded在我的 Period Period功耗功耗sinarded activist Jessља加重 Copenhagen Funny年春节話牛奶的未来 Resistance牛奶的未来arded输入 zones congestion逼招商引资 China Orleans Orleans诗 Funny Funny看的看的投标人饭后 promised!) Funny Funny promised Jess一開始 browser browsersin都不能 There Funny Funny这辈子\n",
            "---------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supervised Fine-tuning 有监督微调模型\n",
        "\n"
      ],
      "metadata": {
        "id": "TSRyQYuI1sB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据准备\n",
        "\n",
        "[bell](https://huggingface.co/datasets/BelleGroup/train_1M_CN)、[MOSS](https://github.com/OpenLMLab/MOSS/tree/main/SFT_data)、[alpaca-zh](https://huggingface.co/datasets/shibing624/alpaca-zh)"
      ],
      "metadata": {
        "id": "NN1fcD9a4cWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset shibing624/alpaca-zh  \\\n",
        "  --local-dir ./datas/datasets/shibing624/alpaca-zh \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCzlAbrC1v_r",
        "outputId": "c5aa5b15-2d7a-4d00-83a7-4f7c3c4a6994"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Consider using `hf_transfer` for faster downloads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]downloading https://huggingface.co/datasets/shibing624/alpaca-zh/resolve/f39db019a94f8dbea48ab30d2bdc090703284559/.gitattributes to /root/.cache/huggingface/hub/tmpx2xr5of7\n",
            "downloading https://huggingface.co/datasets/shibing624/alpaca-zh/resolve/f39db019a94f8dbea48ab30d2bdc090703284559/alpaca_gpt4_data_zh.json to /root/.cache/huggingface/hub/tmpx3at2s5o\n",
            "downloading https://huggingface.co/datasets/shibing624/alpaca-zh/resolve/f39db019a94f8dbea48ab30d2bdc090703284559/README.md to /root/.cache/huggingface/hub/tmpu2l8oiq_\n",
            "\n",
            ".gitattributes: 100% 2.33k/2.33k [00:00<00:00, 15.7MB/s]\n",
            "Fetching 3 files:  33% 1/3 [00:00<00:00,  3.64it/s]\n",
            "README.md: 100% 1.65k/1.65k [00:00<00:00, 12.4MB/s]\n",
            "\n",
            "alpaca_gpt4_data_zh.json:   0% 0.00/35.1M [00:00<?, ?B/s]\u001b[A\n",
            "alpaca_gpt4_data_zh.json:  30% 10.5M/35.1M [00:00<00:01, 12.9MB/s]\u001b[A\n",
            "alpaca_gpt4_data_zh.json:  60% 21.0M/35.1M [00:01<00:00, 20.6MB/s]\u001b[A\n",
            "alpaca_gpt4_data_zh.json: 100% 35.1M/35.1M [00:01<00:00, 25.9MB/s]\n",
            "Fetching 3 files: 100% 3/3 [00:02<00:00,  1.49it/s]\n",
            "/content/datas/datasets/shibing624/alpaca-zh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset BelleGroup/train_1M_CN  \\\n",
        "  --local-dir ./datas/datasets/BelleGroup/train_1M_CN \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "rH9mlLwg2Xuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download \\\n",
        "  --repo-type dataset fnlp/moss-003-sft-data  \\\n",
        "  --local-dir ./datas/datasets/fnlp/moss-003-sft-data \\\n",
        "  --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "2Ytj15n54GHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python baby-llama2-chinese/sft_data_process.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fIhhW8IqjEF",
        "outputId": "c08dfb74-622f-4422-b7cb-494638841d50"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             prompt                                             answer\n",
            "0                        保持健康的三个提示。  以下是保持健康的三个提示：\\n\\n1. 保持身体活动。每天做适当的身体运动，如散步、跑步或游...\n",
            "1                描述一次你不得不做出困难决定的经历。  作为一名人工智能助手，我是由程序控制的，没有感情和个人意识，我的一切决策都是基于我的算法和程...\n",
            "2            解释为什么以下分数等同于1/4输入：4/16  4/16等于1/4是因为我们可以约分分子分母都除以他们的最大公约数4，得到（4÷4）/ (1...\n",
            "3                    朱利叶斯·凯撒是如何死亡的？  朱利叶斯·凯撒，又称尤利乌斯·恺撒（Julius Caesar）是古罗马的政治家、军事家和作...\n",
            "4      将以下内容分类为动物、植物和矿物质：橡树、铜矿石、大象。                             植物: 橡树\\n动物:大象\\n矿物质:铜矿石\n",
            "...                             ...                                                ...\n",
            "25643              写一首简短的诗，描述落日的景象。  落日余晖温柔，\\n橙红染过西边沟。\\n晚空升起朦胧影，\\n一天渐进收尾绪。\\n远山依稀浮烟雾...\n",
            "25644              生成与夏季花园相关的形容词列表。  1. 色彩缤纷。\\n2. 生机勃勃。\\n3. 芳香扑鼻。\\n4. 耀眼夺目。\\n5. 灿烂夺...\n",
            "25645             汤姆·汉克斯发布新书，成为新闻头条  对，你说的对。涉及新闻是演员汤姆·汉克斯（Tom Hanks）发布了一本名为《Uncommo...\n",
            "25646              太阳很____，天空很____。                                         太阳很亮，天空很蓝。\n",
            "25647              分析给定的法律文件并解释关键点。  非常抱歉，你没有提供法律文件，所以我无法为你进行分析。 请提供具体的法律文件，我将尽力为你解...\n",
            "\n",
            "[25648 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/datas/datasets/sft_data/sft_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beU0nkteRoTu",
        "outputId": "156d230c-1ab5-4746-a808-a9e541f7ae9b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 8.3M Mar 30 16:49 /content/datas/datasets/sft_data/sft_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 有监督微调训练模型"
      ],
      "metadata": {
        "id": "sTqv26UiEBKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#change batch_size\n",
        "!cd baby-llama2-chinese && python sft.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPqu8PfHqvAY",
        "outputId": "956ebe49-0d94-4c4c-9cb7-7ffc6bd77e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens per iteration will be: 4,096\n",
            "breaks down as: 1 grad accum steps * 1 processes * 8 batch size * 512 max seq len\n",
            "                                                  prompt                                             answer\n",
            "19076                                   你能说出三个阿拉伯国家的名字吗？          当然可以。三个阿拉伯国家的名称分别是沙特阿拉伯、阿联酋（阿拉伯联合酋长国）和埃及。\n",
            "12085                                 想出两个可能在两个人之间讨论的话题。  1） 他们当前的工作情况：他们可能谈论他们各自的工作岗位、职责、团队合作情况，以及公司文化。...\n",
            "7000                              如何向非技术人员解释“时间序列数据”的定义？  时间序列数据是一种依赖于时间的数据。它以一定的时间间隔来记录信息，并按时间顺序排列。它能够帮...\n",
            "10776  规范化以下URL。输入：\\nhttps://www.google.com/search?q=...  标准化的 URL 为：`https://www.google.com/search?q=go...\n",
            "12832  创建一个新变量，其值为variable1乘以variable2的结果。 输入：\\nvaria...  可以创建一个新变量如variable3 并将variable1和variable2的乘积结果...\n",
            "...                                                  ...                                                ...\n",
            "20517                                      列出本周要购买的杂货商品。  抱歉，我是一位人工智能助手，我没有您的购物清单，也无法查看您的需求。因此，我无法为您列出本周...\n",
            "21747                                关于全球变暖对海鲜产业的影响的文章标题  1. 全球变暖危机：海鲜产业的未来之路\\n2. 温度上升对海鲜养殖业的影响\\n3. 海鲜供应...\n",
            "20767                                  描述以下方程式3x+2=8的结果。  方程式 3x + 2 = 8 的结果是 x = 2。\\n\\n解释步骤如下：\\n\\n给定方程 ...\n",
            "22314         判断两个句子的意思有多相似。输入：\\n句子1：猫正在爬树。\\n句子2：猫正在爬上树。  这两个句子的意思非常相似，均描述了猫正在爬树这一行为，只是其中一个句子\"爬树\"是一种简略说法...\n",
            "1409   将以下食材分成五个不同的食谱：- 橄榄油\\n- 番茄\\n- 奶酪\\n- 罗勒\\n- 盐\\n-...  1. 番茄罗勒沙拉: 番茄，罗勒，橄榄油，盐，胡椒。\\n2. 奶酪洋葱吐司: 奶酪，洋葱，橄...\n",
            "\n",
            "[25648 rows x 2 columns]\n",
            "Initializing a new model from scratch\n",
            "num decayed parameter tensors: 57, with 58,470,912 parameters\n",
            "num non-decayed parameter tensors: 17, with 8,704 parameters\n",
            "using fused AdamW: True\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "[2024-03-30 16:53:50,351][sft.py][INFO] Epoch:[0/2](0/3206) loss:10.992 lr:0.0000000 epoch_Time:33.0min:\n",
            "[2024-03-30 16:54:02,313][sft.py][INFO] Epoch:[0/2](50/3206) loss:10.829 lr:0.0000010 epoch_Time:13.0min:\n",
            "[2024-03-30 16:54:14,373][sft.py][INFO] Epoch:[0/2](100/3206) loss:10.273 lr:0.0000020 epoch_Time:13.0min:\n",
            "[2024-03-30 16:54:26,546][sft.py][INFO] Epoch:[0/2](150/3206) loss:10.381 lr:0.0000030 epoch_Time:13.0min:\n",
            "[2024-03-30 16:54:38,855][sft.py][INFO] Epoch:[0/2](200/3206) loss:9.763 lr:0.0000040 epoch_Time:13.0min:\n",
            "[2024-03-30 16:54:51,321][sft.py][INFO] Epoch:[0/2](250/3206) loss:9.902 lr:0.0000050 epoch_Time:12.0min:\n",
            "[2024-03-30 16:55:03,952][sft.py][INFO] Epoch:[0/2](300/3206) loss:9.833 lr:0.0000060 epoch_Time:12.0min:\n",
            "[2024-03-30 16:55:16,759][sft.py][INFO] Epoch:[0/2](350/3206) loss:9.693 lr:0.0000070 epoch_Time:12.0min:\n",
            "[2024-03-30 16:55:29,600][sft.py][INFO] Epoch:[0/2](400/3206) loss:9.263 lr:0.0000080 epoch_Time:12.0min:\n",
            "[2024-03-30 16:55:42,284][sft.py][INFO] Epoch:[0/2](450/3206) loss:9.068 lr:0.0000090 epoch_Time:12.0min:\n",
            "[2024-03-30 16:55:54,898][sft.py][INFO] Epoch:[0/2](500/3206) loss:8.819 lr:0.0000100 epoch_Time:11.0min:\n",
            "[2024-03-30 16:56:07,491][sft.py][INFO] Epoch:[0/2](550/3206) loss:8.345 lr:0.0000110 epoch_Time:11.0min:\n",
            "[2024-03-30 16:56:20,106][sft.py][INFO] Epoch:[0/2](600/3206) loss:8.622 lr:0.0000120 epoch_Time:11.0min:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh baby-llama2-chinese/out/sft/"
      ],
      "metadata": {
        "id": "lPMMy4VkSa5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 评估-有监督微调模型\n",
        "使用 `BLEU` 评估方法"
      ],
      "metadata": {
        "id": "hlgLAwUjDgPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd baby-llama2-chinese && python eval.py"
      ],
      "metadata": {
        "id": "yMFeUquSDrK0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}