{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyM2pOnv1U3/khY+Vy30L72L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/achatbot_kimi_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "Gf2QRIf-CHpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update && apt-get install -y ninja-build"
      ],
      "metadata": {
        "id": "AR4mGH163BHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && rm -rf achatbot && git clone https://github.com/ai-bot-pro/achatbot.git -b feat/voice"
      ],
      "metadata": {
        "id": "KgWkCIBAxn-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cFvgRFMqRjlY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c27bac-100b-4537-84c4-cd36c6e8b721"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/achatbot\n"
          ]
        }
      ],
      "source": [
        "%cd /content/achatbot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "x389A5GV4Vp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEpbiR_SRnwl"
      },
      "outputs": [],
      "source": [
        "!bash scripts/pypi_achatbot.sh dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.9.post11-py3-none-any.whl[llm_transformers_manual_voice_kimi]\""
      ],
      "metadata": {
        "id": "9AVHWLtY4pdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "CsdGf0-W2-U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK8tWbDguJck"
      },
      "source": [
        "# download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download FunAudioLLM/SenseVoiceSmall --quie --local-dir /content/models/FunAudioLLM/SenseVoiceSmall\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoKxtNoA4y2s",
        "outputId": "10661aae-cafb-4f85-9933-6516b3eb5bfe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/FunAudioLLM/SenseVoiceSmall\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y4QJvMXAfrGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3446bf-68e4-447b-9bf1-72de72fee7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/moonshotai/Kimi-Audio-7B-Instruct\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download moonshotai/Kimi-Audio-7B-Instruct --quie --local-dir /content/models/moonshotai/Kimi-Audio-7B-Instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# asr test"
      ],
      "metadata": {
        "id": "XxJljfKl6ZNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI8OtLdx6cLx",
        "outputId": "9e6d676d-d0b1-4bcf-954d-d4578365e2c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/achatbot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/achatbot/test/audio_files/asr_example_zh.wav\")"
      ],
      "metadata": {
        "id": "3fCejayPGuT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/moonshotai/Kimi-Audio-7B-Instruct \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_kimi_asr.TestKimiASR.test_transcribe_stream"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE8I7IYc6kET",
        "outputId": "4d378c53-5415-415f-d04f-d1924ae33a9f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-02 17:08:39,344 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: kimi_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/moonshotai/Kimi-Audio-7B-Instruct', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'is_load_detokenizer': True, 'code2wav_args': {'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'}}\n",
            "2025-05-02 17:08:40,353 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-02 17:08:43.270516: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-02 17:08:43.288112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746205723.309520    9930 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746205723.316092    9930 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-02 17:08:43.337792: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-02 17:08:45,861 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use kimi_asr engine\n",
            "2025-05-02 17:08:45,861 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.kimi_asr.KimiAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/moonshotai/Kimi-Audio-7B-Instruct', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'is_load_detokenizer': True, 'code2wav_args': {'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'}}\n",
            "2025-05-02 17:08:45,862 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:48 - __init__ - args: KimiAudioTransformersVoiceLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='/content/models/moonshotai/Kimi-Audio-7B-Instruct', lm_device_map=None, lm_device='cuda', lm_torch_dtype='bfloat16', lm_attn_impl=None, user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=1, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=10, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4', is_load_detokenizer=False, code2wav_args={'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'})\n",
            "2025-05-02 17:08:45,936 - transformers_modules.Kimi-Audio-7B-Instruct.modeling_moonshot_kimia - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/utils/logging.py:328 - warning_once - using normal flash attention\n",
            "Loading checkpoint shards: 100% 36/36 [00:00<00:00, 435.14it/s]\n",
            "\u001b[32m2025-05-02 17:08:52.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mLooking for resources in /content/models/moonshotai/Kimi-Audio-7B-Instruct\u001b[0m\n",
            "\u001b[32m2025-05-02 17:08:52.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mLoading whisper model\u001b[0m\n",
            "\u001b[32m2025-05-02 17:08:55.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLoading text tokenizer\u001b[0m\n",
            "2025-05-02 17:08:56,103 - transformers_modules.Kimi-Audio-7B-Instruct.tokenization_kimia - INFO - /root/.cache/huggingface/modules/transformers_modules/Kimi-Audio-7B-Instruct/tokenization_kimia.py:116 - __init__ - Reloaded tiktoken model from /content/models/moonshotai/Kimi-Audio-7B-Instruct/tiktoken.model\n",
            "2025-05-02 17:08:56,104 - transformers_modules.Kimi-Audio-7B-Instruct.tokenization_kimia - INFO - /root/.cache/huggingface/modules/transformers_modules/Kimi-Audio-7B-Instruct/tokenization_kimia.py:137 - __init__ - #words: 152064 - BOS ID: 151643 - EOS ID: 151644\n",
            "2025-05-02 17:08:56,104 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:126 - warmup - Warming up TransformersManualAudioKimiLLM device: cuda:0\n",
            "2025-05-02 17:08:58,595 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:176 - warmup - step 0 | gen_text: \n",
            "You are an AI assistant. You will be given a task. You must generate a detailed and long answer.<|im_msg_end|>\n",
            "I'm sorry, but the word \"weedge niu bi\" does not appear to be a valid or recognizable word in | warmup TTFT time: 0.3384187099998144 s | total: 2.487384502999248 s\n",
            "2025-05-02 17:08:58,595 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:186 - warmup - TransformersManualAudioKimiLLM:  warmed up! time: 2.490 s\n",
            "2025-05-02 17:08:58,595 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:45 - initASREngine - initASREngine: kimi_asr, TAG:kimi_asr | KimiAsr\n",
            "2025-05-02 17:08:59,797 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/../../../../deps/KimiAudio/kimia_infer/models/tokenizer/whisper_Lv3/whisper.py:114 - mel_filters - Loading mel filters from /content/achatbot/src/core/llm/transformers/../../../../deps/KimiAudio/kimia_infer/models/tokenizer/whisper_Lv3/mel_filters.npz\n",
            "2025-05-02 17:09:00,338 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:402 - generate - text [欢迎大家来体验达摩院推出的语音识别模型] TTFT: 0.052500259999987975 s | total: 3.129652135000242 s | len: 11 | avg: 0.28451383045456746 s\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 21.049s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/moonshotai/Kimi-Audio-7B-Instruct \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_kimi_asr.TestKimiASR.test_transcribe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCYSFTMRwKB1",
        "outputId": "ae2922bf-9968-44d8-a014-7778810af4d3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-02 17:10:09,724 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: kimi_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/moonshotai/Kimi-Audio-7B-Instruct', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'is_load_detokenizer': True, 'code2wav_args': {'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'}}\n",
            "2025-05-02 17:10:10,718 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-02 17:10:13.609919: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-02 17:10:13.628090: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746205813.652376   10381 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746205813.659248   10381 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-02 17:10:13.682134: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-02 17:10:16,147 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use kimi_asr engine\n",
            "2025-05-02 17:10:16,148 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.kimi_asr.KimiAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/moonshotai/Kimi-Audio-7B-Instruct', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'is_load_detokenizer': True, 'code2wav_args': {'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'}}\n",
            "2025-05-02 17:10:16,148 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:48 - __init__ - args: KimiAudioTransformersVoiceLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='/content/models/moonshotai/Kimi-Audio-7B-Instruct', lm_device_map=None, lm_device='cuda', lm_torch_dtype='bfloat16', lm_attn_impl=None, user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=1, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=10, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4', is_load_detokenizer=False, code2wav_args={'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'})\n",
            "2025-05-02 17:10:16,220 - transformers_modules.Kimi-Audio-7B-Instruct.modeling_moonshot_kimia - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/utils/logging.py:328 - warning_once - using normal flash attention\n",
            "Loading checkpoint shards: 100% 36/36 [00:00<00:00, 436.42it/s]\n",
            "\u001b[32m2025-05-02 17:10:22.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mLooking for resources in /content/models/moonshotai/Kimi-Audio-7B-Instruct\u001b[0m\n",
            "\u001b[32m2025-05-02 17:10:22.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mLoading whisper model\u001b[0m\n",
            "\u001b[32m2025-05-02 17:10:26.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLoading text tokenizer\u001b[0m\n",
            "2025-05-02 17:10:26,494 - transformers_modules.Kimi-Audio-7B-Instruct.tokenization_kimia - INFO - /root/.cache/huggingface/modules/transformers_modules/Kimi-Audio-7B-Instruct/tokenization_kimia.py:116 - __init__ - Reloaded tiktoken model from /content/models/moonshotai/Kimi-Audio-7B-Instruct/tiktoken.model\n",
            "2025-05-02 17:10:26,494 - transformers_modules.Kimi-Audio-7B-Instruct.tokenization_kimia - INFO - /root/.cache/huggingface/modules/transformers_modules/Kimi-Audio-7B-Instruct/tokenization_kimia.py:137 - __init__ - #words: 152064 - BOS ID: 151643 - EOS ID: 151644\n",
            "2025-05-02 17:10:26,494 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:126 - warmup - Warming up TransformersManualAudioKimiLLM device: cuda:0\n",
            "2025-05-02 17:10:28,940 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:176 - warmup - step 0 | gen_text: \n",
            "You are an AI assistant. You will be given a task. You must generate a detailed and long answer.<|im_msg_end|>\n",
            "I'm sorry, but the word \"weedge niu bi\" does not appear to be a valid or recognizable word in | warmup TTFT time: 0.3564782789999299 s | total: 2.442514253999434 s\n",
            "2025-05-02 17:10:28,940 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:186 - warmup - TransformersManualAudioKimiLLM:  warmed up! time: 2.445 s\n",
            "2025-05-02 17:10:28,940 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:45 - initASREngine - initASREngine: kimi_asr, TAG:kimi_asr | KimiAsr\n",
            "2025-05-02 17:10:30,150 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/../../../../deps/KimiAudio/kimia_infer/models/tokenizer/whisper_Lv3/whisper.py:114 - mel_filters - Loading mel filters from /content/achatbot/src/core/llm/transformers/../../../../deps/KimiAudio/kimia_infer/models/tokenizer/whisper_Lv3/mel_filters.npz\n",
            "2025-05-02 17:10:30,697 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:402 - generate - text [欢迎大家来体验达摩院推出的语音识别模型] TTFT: 0.050962701999878846 s | total: 3.079592766998985 s | len: 11 | avg: 0.27996297881808957 s\n",
            "{'language': 'zh', 'language_probability': None, 'text': '', 'words': []}\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 21.027s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/moonshotai/Kimi-Audio-7B-Instruct \\\n",
        "    AUDIO_FILE=/content/achatbot/test/audio_files/asr_example_zh.wav \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_kimi_asr.TestKimiASR.test_transcribe_with_bytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0TaURKmwnkU",
        "outputId": "3ec68512-be41-4c4f-bf70-242caa051de1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-02 17:10:43,750 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:43 - initASREngine - initASREngine: kimi_asr, {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/moonshotai/Kimi-Audio-7B-Instruct', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'is_load_detokenizer': True, 'code2wav_args': {'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'}}\n",
            "2025-05-02 17:10:44,743 - numexpr.utils - INFO - /usr/local/lib/python3.11/dist-packages/numexpr/utils.py:162 - _init_num_threads - NumExpr defaulting to 12 threads.\n",
            "2025-05-02 17:10:47.607541: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-02 17:10:47.624907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1746205847.647429   10598 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1746205847.654406   10598 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-02 17:10:47.676419: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-05-02 17:10:50,171 - chat-bot - INFO - /content/achatbot/src/common/factory.py:69 - get_engine_by_tag - use kimi_asr engine\n",
            "2025-05-02 17:10:50,171 - chat-bot - INFO - /content/achatbot/src/common/factory.py:34 - get_instance - class: <class 'src.modules.speech.asr.kimi_asr.KimiAsr'> args: {'lm_gen_seed': 42, 'lm_max_length': 2048, 'lm_gen_max_new_tokens': 1024, 'lm_gen_min_new_tokens': 1, 'lm_gen_do_sample': True, 'lm_gen_temperature': 0.8, 'lm_gen_top_k': 50, 'lm_gen_top_p': 0.95, 'lm_gen_min_p': 0.0, 'lm_gen_repetition_penalty': 1.1, 'lm_gen_stops': [], 'lm_gen_stop_ids': [], 'lm_gen_end_id': 0, 'lm_gen_pad_id': 0, 'lm_gen_max_tokens_per_step': 3, 'lm_model_name_or_path': '/content/models/moonshotai/Kimi-Audio-7B-Instruct', 'lm_device_map': None, 'lm_device': 'cuda', 'lm_torch_dtype': 'bfloat16', 'lm_attn_impl': None, 'user_role': 'user', 'warnup_prompt': \"Repeat the word 'weedge niu bi'.\", 'warmup_steps': 1, 'init_chat_role': 'system', 'init_chat_prompt': '', 'lm_tokenizer_decode_batch_size': 60, 'chat_history_size': 10, 'lm_stream': True, 'model_type': 'chat_completion', 'lm_bnb_quant_type': 'int4', 'is_load_detokenizer': True, 'code2wav_args': {'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'}}\n",
            "2025-05-02 17:10:50,172 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:48 - __init__ - args: KimiAudioTransformersVoiceLMArgs(lm_gen_seed=42, lm_max_length=2048, lm_gen_max_new_tokens=1024, lm_gen_min_new_tokens=1, lm_gen_do_sample=True, lm_gen_temperature=0.8, lm_gen_top_k=50, lm_gen_top_p=0.95, lm_gen_min_p=0.0, lm_gen_repetition_penalty=1.1, lm_gen_stops=[], lm_gen_stop_ids=[], lm_gen_end_id=0, lm_gen_pad_id=0, lm_gen_max_tokens_per_step=3, lm_model_name_or_path='/content/models/moonshotai/Kimi-Audio-7B-Instruct', lm_device_map=None, lm_device='cuda', lm_torch_dtype='bfloat16', lm_attn_impl=None, user_role='user', warnup_prompt=\"Repeat the word 'weedge niu bi'.\", warmup_steps=1, init_chat_role='system', init_chat_prompt='', lm_tokenizer_decode_batch_size=60, chat_history_size=10, lm_stream=True, model_type='chat_completion', lm_bnb_quant_type='int4', is_load_detokenizer=False, code2wav_args={'device': 'cuda', 'look_ahead_tokens': 12, 'max_prompt_chunk': 10, 'max_kv_cache_tokens': 900, 'use_cfg': True, 'use_cfg_rescale': True, 'cfg_init': 1.5, 'cfg_scale': 7.5, 'cfg_schedule': 'linear'})\n",
            "2025-05-02 17:10:50,244 - transformers_modules.Kimi-Audio-7B-Instruct.modeling_moonshot_kimia - WARNING - /usr/local/lib/python3.11/dist-packages/transformers/utils/logging.py:328 - warning_once - using normal flash attention\n",
            "Loading checkpoint shards: 100% 36/36 [00:00<00:00, 428.97it/s]\n",
            "\u001b[32m2025-05-02 17:10:57.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m20\u001b[0m - \u001b[1mLooking for resources in /content/models/moonshotai/Kimi-Audio-7B-Instruct\u001b[0m\n",
            "\u001b[32m2025-05-02 17:10:57.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m21\u001b[0m - \u001b[1mLoading whisper model\u001b[0m\n",
            "\u001b[32m2025-05-02 17:11:00.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdeps.KimiAudio.kimia_infer.api.prompt_manager\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mLoading text tokenizer\u001b[0m\n",
            "2025-05-02 17:11:00,751 - transformers_modules.Kimi-Audio-7B-Instruct.tokenization_kimia - INFO - /root/.cache/huggingface/modules/transformers_modules/Kimi-Audio-7B-Instruct/tokenization_kimia.py:116 - __init__ - Reloaded tiktoken model from /content/models/moonshotai/Kimi-Audio-7B-Instruct/tiktoken.model\n",
            "2025-05-02 17:11:00,751 - transformers_modules.Kimi-Audio-7B-Instruct.tokenization_kimia - INFO - /root/.cache/huggingface/modules/transformers_modules/Kimi-Audio-7B-Instruct/tokenization_kimia.py:137 - __init__ - #words: 152064 - BOS ID: 151643 - EOS ID: 151644\n",
            "2025-05-02 17:11:00,752 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:126 - warmup - Warming up TransformersManualAudioKimiLLM device: cuda:0\n",
            "2025-05-02 17:11:03,185 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:176 - warmup - step 0 | gen_text: \n",
            "You are an AI assistant. You will be given a task. You must generate a detailed and long answer.<|im_msg_end|>\n",
            "I'm sorry, but the word \"weedge niu bi\" does not appear to be a valid or recognizable word in | warmup TTFT time: 0.35304383199991207 s | total: 2.4298136720005914 s\n",
            "2025-05-02 17:11:03,185 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:186 - warmup - TransformersManualAudioKimiLLM:  warmed up! time: 2.432 s\n",
            "2025-05-02 17:11:03,185 - chat-bot - INFO - /content/achatbot/src/modules/speech/asr/__init__.py:45 - initASREngine - initASREngine: kimi_asr, TAG:kimi_asr | KimiAsr\n",
            "2025-05-02 17:11:03,469 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/../../../../deps/KimiAudio/kimia_infer/models/tokenizer/whisper_Lv3/whisper.py:114 - mel_filters - Loading mel filters from /content/achatbot/src/core/llm/transformers/../../../../deps/KimiAudio/kimia_infer/models/tokenizer/whisper_Lv3/mel_filters.npz\n",
            "2025-05-02 17:11:04,082 - chat-bot - INFO - /content/achatbot/src/core/llm/transformers/manual_voice_kimi.py:402 - generate - text [欢迎大家来体验达摩院推出的语音识别模型。] TTFT: 0.045816921999858096 s | total: 3.789726662998646 s | len: 12 | avg: 0.31581055524988716 s\n",
            "{'language': 'zh', 'language_probability': None, 'text': '', 'words': []}\n",
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 20.387s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    }
  ]
}