{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOZEKEIvrnn/CuGbflAC+wf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/MeiGen_AI_MultiTalk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NOTE: use A100 to run"
      ],
      "metadata": {
        "id": "DpkJ1LDmfmZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🛠️Installation\n"
      ],
      "metadata": {
        "id": "AUSjHcXt2ypc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVcZXzrq2jyP"
      },
      "outputs": [],
      "source": [
        "# 1. install pytorch, xformers\n",
        "\n",
        "!pip install torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -U xformers==0.0.28 --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Flash-attn installation:\n",
        "!pip install misaki[en] ninja psutil packaging\n",
        "!pip install flash_attn==2.7.4.post1"
      ],
      "metadata": {
        "id": "bQCzEdzw29Oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"librosa|ffmpeg\"\n"
      ],
      "metadata": {
        "id": "bWfR6hd53uBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/weedge/MultiTalk.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szS4Gkj_3XBM",
        "outputId": "92a3d928-526f-418c-9ddd-1b6390b78550"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MultiTalk'...\n",
            "remote: Enumerating objects: 281, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 281 (delta 99), reused 48 (delta 48), pack-reused 136 (from 1)\u001b[K\n",
            "Receiving objects: 100% (281/281), 21.10 MiB | 15.41 MiB/s, done.\n",
            "Resolving deltas: 100% (111/111), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/MultiTalk && pip install -r requirements.txt\n"
      ],
      "metadata": {
        "id": "d1pZE_803pM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers==4.49.0"
      ],
      "metadata": {
        "id": "Tk8JMt9nD_Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"torch|transformers\""
      ],
      "metadata": {
        "id": "3iR76Q_FD0Kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y tensorflow jax jaxlib"
      ],
      "metadata": {
        "id": "kYwidQLvEbU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧱Model Preparation\n"
      ],
      "metadata": {
        "id": "qDnFBr_r4v4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Model Download\n",
        "\n",
        "| Models        |                       Download Link                                           |    Notes                      |\n",
        "| --------------|-------------------------------------------------------------------------------|-------------------------------|\n",
        "| Wan2.1-I2V-14B-480P  |      🤗 [Huggingface](https://huggingface.co/Wan-AI/Wan2.1-I2V-14B-480P)       | Base model\n",
        "| chinese-wav2vec2-base |      🤗 [Huggingface](https://huggingface.co/TencentGameMate/chinese-wav2vec2-base)          | Audio encoder\n",
        "| Kokoro-82M      |      🤗 [Huggingface](https://huggingface.co/hexgrad/Kokoro-82M)              | TTS weights\n",
        "| MeiGen-MultiTalk      |      🤗 [Huggingface](https://huggingface.co/MeiGen-AI/MeiGen-MultiTalk)              | Our audio condition weights\n"
      ],
      "metadata": {
        "id": "PpgtNIVS5jdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download --quiet Wan-AI/Wan2.1-I2V-14B-480P --local-dir ./weights/Wan2.1-I2V-14B-480P"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMP4NSqG47ro",
        "outputId": "017a2b57-1754-412e-8159-9989263a8ead"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/Wan2.1-I2V-14B-480P\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download --quiet TencentGameMate/chinese-wav2vec2-base --local-dir ./weights/chinese-wav2vec2-base\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iO6BLgsC48Ys",
        "outputId": "4586a367-a938-4ec1-c8ec-e7a090a22ab2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/chinese-wav2vec2-base\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download --quiet TencentGameMate/chinese-wav2vec2-base model.safetensors --revision refs/pr/1 --local-dir ./weights/chinese-wav2vec2-base\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IXCnmwW49eL",
        "outputId": "161dca36-90cc-4433-f101-0cff0337d894"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights/chinese-wav2vec2-base/model.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download --quiet hexgrad/Kokoro-82M --local-dir ./weights/Kokoro-82M\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ur6zrOpC4_IJ",
        "outputId": "87a8189f-59b7-4479-a66c-15283d32227a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/Kokoro-82M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download --quiet MeiGen-AI/MeiGen-MultiTalk --local-dir ./weights/MeiGen-MultiTalk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZQ5i4wS4yBA",
        "outputId": "d2a16e5f-fad2-4767-aa71-7433b5cb5254"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/weights/MeiGen-MultiTalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Link or Copy MultiTalk Model to Wan2.1-I2V-14B-480P Directory"
      ],
      "metadata": {
        "id": "R8L4Gs3n5osk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv weights/Wan2.1-I2V-14B-480P/diffusion_pytorch_model.safetensors.index.json weights/Wan2.1-I2V-14B-480P/diffusion_pytorch_model.safetensors.index.json_old\n",
        "!cp weights/MeiGen-MultiTalk/diffusion_pytorch_model.safetensors.index.json weights/Wan2.1-I2V-14B-480P/\n",
        "!cp weights/MeiGen-MultiTalk/multitalk.safetensors weights/Wan2.1-I2V-14B-480P/"
      ],
      "metadata": {
        "id": "i5ygAP7d5tZ8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🔑 Quick Inference\n",
        "\n",
        "Our model is compatible with both 480P and 720P resolutions. The current code only supports 480P inference. 720P inference requires multiple GPUs, and we will provide an update soon.\n",
        "> Some tips\n",
        "> - Lip synchronization accuracy:​​ Audio CFG works optimally between 3–5. Increase the audio CFG value for better synchronization.\n",
        "> - ​​Video clip length:​​ The model was trained on 81-frame videos at 25 FPS. For optimal prompt following performance, generate clips at 81 frames. Generating up to 201 frames is possible, though longer clips might reduce prompt-following performance.\n",
        "> - ​​Long video generation:​​ Audio CFG influences color tone consistency across segments. Set this value to 3 to alleviate tonal variations.\n",
        "> - Sampling steps: If you want to generate a video fast, you can decrease the sampling steps to even 10 that will not hurt the lip synchronization accuracy, but affects the motion and visual quality. More sampling steps, better video quality.\n",
        "> - TeaCache accelerate:​​ The optimal range for `--teacache_thresh` is between 0.2 and 0.5. Increasing this value can further improve acceleration, but may also lead to a decline in the quality of the generated video.\n",
        "\n",
        "#### Usage of MultiTalk\n",
        "```\n",
        "--mode streaming: long video generation.\n",
        "--mode clip: generate short video with one chunk.\n",
        "--use_teacache: run with TeaCache.\n",
        "--size multitalk-480: generate 480P video.\n",
        "--size multitalk-720: generate 720P video.\n",
        "--use_apg: run with APG.\n",
        "--teacache_thresh: A coefficient used for TeaCache acceleration\n",
        "—-sample_text_guide_scale： When not using LoRA, the optimal value is 5. After applying LoRA, the recommended value is 1.\n",
        "—-sample_audio_guide_scale： When not using LoRA, the optimal value is 4. After applying LoRA, the recommended value is 2.\n",
        "```\n"
      ],
      "metadata": {
        "id": "_j1tH4vm6Kfs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 🏃🏻Single-Person"
      ],
      "metadata": {
        "id": "oOoqnBST6eM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MultiTalk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNjEXxha68uY",
        "outputId": "1dec416d-dae9-4063-be36-aa67f36b4610"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MultiTalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "If you want run with very low VRAM, set `--num_persistent_param_in_dit 0`"
      ],
      "metadata": {
        "id": "DlkzRinR7FJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run with very low VRAM\n",
        "!python generate_multitalk.py \\\n",
        "    --ckpt_dir /content/weights/Wan2.1-I2V-14B-480P \\\n",
        "    --wav2vec_dir /content/weights/chinese-wav2vec2-base \\\n",
        "    --input_json /content/MultiTalk/examples/single_example_1.json \\\n",
        "    --sample_steps 40 \\\n",
        "    --mode streaming \\\n",
        "    --num_persistent_param_in_dit 0 \\\n",
        "    --use_teacache \\\n",
        "    --save_file single_long_lowvram_exp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKxjBkin7In4",
        "outputId": "d287ee35-b128-456a-8847-497923943d4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 8/8 [00:03<00:00,  2.64it/s]\n",
            "teacache_init\n",
            "teacache_init done\n",
            "100% 40/40 [1:19:43<00:00, 119.59s/it]\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run with TTS\n",
        "!python generate_multitalk.py \\\n",
        "    --ckpt_dir /content/weights/Wan2.1-I2V-14B-480P \\\n",
        "    --wav2vec_dir /content/weights/chinese-wav2vec2-base \\\n",
        "    --input_json /content/MultiTalk/examples/single_example_tts_1.json \\\n",
        "    --sample_steps 40 \\\n",
        "    --mode streaming \\\n",
        "    --num_persistent_param_in_dit 0 \\\n",
        "    --use_teacache \\\n",
        "    --save_file single_long_lowvram_tts_exp \\\n",
        "    --audio_mode tts"
      ],
      "metadata": {
        "id": "-dJi0rD17UGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 🏃🏻🏃🏻Multi-Person"
      ],
      "metadata": {
        "id": "r6HNYUt96nNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/MultiTalk"
      ],
      "metadata": {
        "id": "2Jf2g3f57AJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run with very low VRAM\n",
        "!python generate_multitalk.py \\\n",
        "    --ckpt_dir /content/weights/Wan2.1-I2V-14B-480P \\\n",
        "    --wav2vec_dir /content/weights/chinese-wav2vec2-base \\\n",
        "    --input_json /content/MultiTalk/examples/multitalk_example_2.json \\\n",
        "    --sample_steps 40 \\\n",
        "    --mode streaming \\\n",
        "    --num_persistent_param_in_dit 0 \\\n",
        "    --use_teacache \\\n",
        "    --save_file multi_long_lowvram_exp"
      ],
      "metadata": {
        "id": "3-8XoElR7f8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run with TTS\n",
        "!python generate_multitalk.py \\\n",
        "    --ckpt_dir /content/weights/Wan2.1-I2V-14B-480P \\\n",
        "    --wav2vec_dir /content/weights/chinese-wav2vec2-base \\\n",
        "    --input_json /content/MultiTalk/examples/multitalk_example_tts_1.json \\\n",
        "    --sample_steps 40 \\\n",
        "    --mode streaming \\\n",
        "    --num_persistent_param_in_dit 0 \\\n",
        "    --use_teacache \\\n",
        "    --save_file multi_long_lowvram_tts_exp \\\n",
        "    --audio_mode tts"
      ],
      "metadata": {
        "id": "IS6EAqlY7kDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 📺 Run with FusioniX and CausVid(Require only 4~8 steps)\n",
        "[FusioniX](https://huggingface.co/vrgamedevgirl84/Wan14BT2VFusioniX/blob/main/FusionX_LoRa/Wan2.1_I2V_14B_FusionX_LoRA.safetensors) require 8 steps and [lightx2v](https://huggingface.co/Kijai/WanVideo_comfy/blob/main/Wan21_T2V_14B_lightx2v_cfg_step_distill_lora_rank32.safetensors) requires only 4 steps."
      ],
      "metadata": {
        "id": "pk8AELsG7rte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_multitalk.py \\\n",
        "    --ckpt_dir /content/weights/Wan2.1-I2V-14B-480P \\\n",
        "    --wav2vec_dir /content/weights/chinese-wav2vec2-base \\\n",
        "    --input_json /content/MultiTalk/examples/single_example_1.json \\\n",
        "    --lora_dir /content/weights/Wan2.1_I2V_14B_FusionX_LoRA.safetensors \\\n",
        "    --lora_scale 1.0 \\\n",
        "    --sample_text_guide_scale 1.0 \\\n",
        "    --sample_audio_guide_scale 1.0 \\\n",
        "    --sample_steps 8 \\\n",
        "    --mode streaming \\\n",
        "    --num_persistent_param_in_dit 0 \\\n",
        "    --save_file single_long_lowvram_fusionx_exp \\\n",
        "    --sample_shift 2"
      ],
      "metadata": {
        "id": "AFbUD7qF715X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python generate_multitalk.py \\\n",
        "    --ckpt_dir /content/weights/Wan2.1-I2V-14B-480P \\\n",
        "    --wav2vec_dir /content/weights/chinese-wav2vec2-base \\\n",
        "    --input_json /content/MultiTalk/examples/multitalk_example_2.json \\\n",
        "    --lora_dir /content/weights/Wan2.1_I2V_14B_FusionX_LoRA.safetensors \\\n",
        "    --lora_scale 1.0 \\\n",
        "    --sample_text_guide_scale 1.0 \\\n",
        "    --sample_audio_guide_scale 1.0 \\\n",
        "    --sample_steps 8 \\\n",
        "    --mode streaming \\\n",
        "    --num_persistent_param_in_dit 0 \\\n",
        "    --save_file multi_long_lowvram_fusionx_exp \\\n",
        "    --sample_shift 2"
      ],
      "metadata": {
        "id": "Lav9-fCu74BC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}