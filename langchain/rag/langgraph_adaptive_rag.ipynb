{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/langchain/rag/langgraph_adaptive_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8",
      "metadata": {
        "id": "5afcaed0-3d55-4e1f-95d3-c32c751c29d8"
      },
      "source": [
        "> TIP:\n",
        ">\n",
        "> 请先看论文，不然不知所以然\n",
        ">\n",
        "\n",
        " - https://github.com/starsuzi/Adaptive-RAG\n",
        " - https://arxiv.org/html/2403.14403\n",
        " - https://blog.langchain.com/agentic-rag-with-langgraph/\n",
        " - https://www.youtube.com/watch?v=pbAd8O1Lvm4\n",
        "\n",
        "query-construction:\n",
        " - https://blog.langchain.com/query-construction/\n",
        "\n",
        "\n",
        "self-RAG:\n",
        " - https://arxiv.org/abs/2310.11511\n",
        " - https://github.com/AkariAsai/self-rag\n",
        " - https://github.com/weedge/doraemon-nb/blob/main/langchain/rag/langgraph_self_rag.ipynb\n",
        "\n",
        "\n",
        "CRAG:\n",
        " - https://arxiv.org/html/2401.15884\n",
        " - https://github.com/HuskyInSalt/CRAG\n",
        " - https://github.com/weedge/doraemon-nb/blob/main/langchain/rag/langgraph_crag.ipynb\n",
        "\n",
        "\n",
        "# Adaptive RAG（自适应 RAG）\n",
        "\n",
        "Adaptive RAG（自适应 RAG）是一种 RAG 策略，它结合了 (1) [查询分析](https://blog.langchain.dev/query-construction/) 和 (2) [主动 / 自我修正 RAG](https://blog.langchain.dev/agentic-rag-with-langgraph/)。\n",
        "\n",
        "在[论文](https://arxiv.org/abs/2403.14403)中，他们报告了使用查询分析来路由到：\n",
        "\n",
        "  * 不检索（No Retrieval）\n",
        "  * 单次 RAG（Single-shot RAG）\n",
        "  * 迭代 RAG（Iterative RAG）\n",
        "\n",
        "让我们使用 LangGraph 在此基础上进行构建。\n",
        "\n",
        "在我们的实现中，我们将在以下选项之间进行路由：\n",
        "\n",
        "  * 网页搜索：用于与最近事件相关的问题\n",
        "  * 自我修正 RAG：用于与我们的索引相关的问题\n",
        "\n",
        "  ![](https://github-production-user-asset-6210df.s3.amazonaws.com/1203957/509899782-d7eaaf9c-ece3-47b3-90cb-0dcce18e60f5.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20251105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251105T033635Z&X-Amz-Expires=300&X-Amz-Signature=7573bc401746788d7dc5ed0e45ba81d7425144ddecaeaff68ad32beaa8b7daad&X-Amz-SignedHeaders=host)\n",
        "\n",
        "  ![](https://github.com/user-attachments/assets/586ec47e-5bdf-403c-8c40-a13d9e7461d2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44a72d6-7e0c-4478-9d20-4c09000420a8"
      },
      "source": [
        "## 设置 (Setup)\n",
        "\n",
        "首先，我们需要安装所需的包。"
      ],
      "id": "a44a72d6-7e0c-4478-9d20-4c09000420a8"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b451b58a-89bd-424f-8c06-0d9fe325e01b"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet -U langchain_community tiktoken langchain-openai langchain-cohere langchainhub chromadb langchain langgraph  tavily-python langchain-google-genai langchain-text-splitters"
      ],
      "id": "b451b58a-89bd-424f-8c06-0d9fe325e01b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"langchain|langgraph|chromadb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoRFlZmMGi3W",
        "outputId": "b0c4bdbc-9bb4-4d93-91da-6ce29249178c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chromadb                                 1.3.3\n",
            "langchain                                1.0.3\n",
            "langchain-classic                        1.0.0\n",
            "langchain-cohere                         0.5.0\n",
            "langchain-community                      0.4.1\n",
            "langchain-core                           1.0.3\n",
            "langchain-google-genai                   3.0.1\n",
            "langchain-openai                         1.0.2\n",
            "langchain-text-splitters                 1.0.0\n",
            "langchainhub                             0.1.21\n",
            "langgraph                                1.0.2\n",
            "langgraph-checkpoint                     3.0.1\n",
            "langgraph-prebuilt                       1.0.2\n",
            "langgraph-sdk                            0.2.9\n"
          ]
        }
      ],
      "id": "uoRFlZmMGi3W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35f267b0-98db-4a59-8b2c-a23f795576ff"
      },
      "source": [
        "接下来，我们需要为 OpenAI（我们将使用的 LLM）和 Tavily（我们将使用的搜索工具）设置 API 密钥。"
      ],
      "id": "35f267b0-98db-4a59-8b2c-a23f795576ff"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get(\"ZHIPU_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"]=userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"]=userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"GITEE_API_KEY\"]=userdata.get(\"GITEE_API_KEY\")\n",
        "\n"
      ],
      "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab5cea6d"
      },
      "source": [
        "<div class=\"admonition tip\"> <p class=\"admonition-title\">设置 <a href=\"https://smith.langchain.com\">LangSmith</a> 以用于 LangGraph 开发</p> <p style=\"padding-top: 5px;\"> 注册 LangSmith 可以快速发现问题并提高您的 LangGraph 项目的性能。LangSmith 允许您使用跟踪数据来调试、测试和监控使用 LangGraph 构建的 LLM 应用程序——阅读更多关于如何开始的信息 <a href=\"https://docs.smith.langchain.com\">请点击此处</a>。 </p> </div>"
      ],
      "id": "ab5cea6d"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGSMITH_API_KEY\"]=userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "IooCYxWjE5il"
      },
      "execution_count": 3,
      "outputs": [],
      "id": "IooCYxWjE5il"
    },
    {
      "cell_type": "markdown",
      "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6",
      "metadata": {
        "id": "9ac1c2cd-81fb-40eb-8ba1-e9197800cba6"
      },
      "source": [
        "## 创建索引\n",
        "\n",
        "使用 OpenAI 嵌入（OpenAI Embeddings）和 Chroma 向量数据库来设置一个向量数据库。\n",
        "输入与智能体（agents）、提示工程（prompt engineering）和大型语言模型（LLMs）相关的博客文章的 URL。\n",
        "生成用于检索增强生成（RAG）的向量索引。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "\tbase_url=\"https://ai.gitee.com/v1\",\n",
        "\tapi_key=os.environ[\"GITEE_API_KEY\"],\n",
        "\tdefault_headers={\"X-Failover-Enabled\":\"true\"},\n",
        ")\n",
        "\n",
        "response = client.embeddings.create(\n",
        "\tinput=\"Today is a sunny day and I will get some ice cream.\",\n",
        "\tmodel=\"Qwen3-Embedding-8B\",\n",
        "\tdimensions=1024,\n",
        ")\n"
      ],
      "metadata": {
        "id": "XVD5LL-TjqFS"
      },
      "id": "XVD5LL-TjqFS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "### from langchain_cohere import CohereEmbeddings\n",
        "\n",
        "# Set embeddings\n",
        "# https://ai.gitee.com/serverless-api#embedding-rerank\n",
        "# 100 api calls per day, free tier ..................NO!!!! ❄️\n",
        "embd = OpenAIEmbeddings(\n",
        "    base_url=\"https://ai.gitee.com/v1\",\n",
        "    model=\"Qwen3-Embedding-8B\",#4096\n",
        "    api_key=os.environ[\"GITEE_API_KEY\"],\n",
        "    dimensions=1024,\n",
        "    check_embedding_ctx_length=False,\n",
        "    chunk_size=1000,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ydSF1Bzhg8H5"
      },
      "id": "ydSF1Bzhg8H5",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector = embd.embed_query(\"Today is a sunny day and I will get some ice cream.\")\n",
        "print(vector)"
      ],
      "metadata": {
        "id": "yNsHUYzVFU9S"
      },
      "id": "yNsHUYzVFU9S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义批量大小"
      ],
      "metadata": {
        "id": "U5CigAnqDybh"
      },
      "id": "U5CigAnqDybh"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "from chromadb.api.client import Client as ClientCreator\n",
        "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE\n",
        "from chromadb.config import Settings, System\n",
        "\n",
        "class CustomClientCreator(ClientCreator):\n",
        "    # region Initialization\n",
        "    def __init__(\n",
        "        self,\n",
        "        tenant: Optional[str] = DEFAULT_TENANT,\n",
        "        database: Optional[str] = DEFAULT_DATABASE,\n",
        "        settings: Settings = Settings(),\n",
        "    ) -> None:\n",
        "        super().__init__(tenant=tenant, database=database, settings=settings)\n",
        "\n",
        "    def get_max_batch_size(self) -> int:\n",
        "        return 10  # some server api limit batch size"
      ],
      "metadata": {
        "id": "sGHKHtSTDxu1"
      },
      "id": "sGHKHtSTDxu1",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Index"
      ],
      "metadata": {
        "id": "gHY7Kz5w5XU6"
      },
      "id": "gHY7Kz5w5XU6"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
      "metadata": {
        "id": "b224e5ba-50ca-495a-a7fa-0f75a080e03c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "631c4f8a-dddf-4f32-fec5-0768919081ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document splits: 44\n"
          ]
        }
      ],
      "source": [
        "### Build Index\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "os.environ[\"USER_AGENT\"] = \"achatbot-demo\"\n",
        "# Docs to index\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "# Load\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "print(f\"Document splits: {len(doc_splits)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Add to vectorstore\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    persist_directory=\"./rag_chroma_db\",# sqlite(row) file path or duckdb(column) file path\n",
        "    embedding=embd,\n",
        "    client=CustomClientCreator(),  # use custom client with batch utils\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "HXIqSRoVFiAA"
      },
      "id": "HXIqSRoVFiAA",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHtd4yeVJNON",
        "outputId": "936c7831-1ff7-49b1-bfe6-e95cf1a126c5"
      },
      "id": "AHtd4yeVJNON",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7add66d5cce0>, search_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"agent memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4SfmqsWJJI6",
        "outputId": "c9ac9dbd-38c0-4136-9ffc-6cc501e3db6c"
      },
      "id": "f4SfmqsWJJI6",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
              " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
              " Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xPKosva7wS_",
        "outputId": "64be08cc-29be-4a1f-bb8d-6f1c39e07491"
      },
      "id": "9xPKosva7wS_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-398866168.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectorstore.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### use indexed docs"
      ],
      "metadata": {
        "id": "rWaiQ6eW5bcQ"
      },
      "id": "rWaiQ6eW5bcQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "retriveal_vectorstore = Chroma(\n",
        "    collection_name=\"rag-chroma\",\n",
        "    persist_directory=\"./rag_chroma_db\",# sqlite(row) file path or duckdb(column) file path\n",
        "    embedding_function=embd,\n",
        "    client=CustomClientCreator(),  # use custom client with batch utils\n",
        ")\n",
        "\n",
        "retriveal_retriever = retriveal_vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "KAN1EgBy5kDM"
      },
      "id": "KAN1EgBy5kDM",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriveal_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU-Uy9Ev7Ux3",
        "outputId": "16db055b-6988-4844-884a-5402441589c0"
      },
      "id": "FU-Uy9Ev7Ux3",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7add5b55dac0>, search_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriveal_retriever.invoke(\"agent memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxPUoTo27WzY",
        "outputId": "ae5fd862-e3d7-48fb-f99a-7ff08c23af57"
      },
      "id": "lxPUoTo27WzY",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
              " Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
              " Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f52b427-750c-40f8-8893-e9caab3afd8d",
      "metadata": {
        "id": "0f52b427-750c-40f8-8893-e9caab3afd8d"
      },
      "source": [
        "## LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d28baefd-a961-49b0-8394-c5478dadda1c",
      "metadata": {
        "id": "d28baefd-a961-49b0-8394-c5478dadda1c"
      },
      "source": [
        "<div class=\"admonition note\"> <p class=\"admonition-title\">将 Pydantic 与 LangChain 配合使用</p> <p> 本笔记（notebook）使用 Pydantic v2 <code>BaseModel</code>，这需要 <code>langchain-core >= 0.3</code>。如果使用 <code>langchain-core < 0.3</code>，将会因 Pydantic v1 和 v2 <code>BaseModels</code> 混用而导致错误。 </p> </div>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cdd5ac0-fa18-4ee9-8051-062a0c56268f",
      "metadata": {
        "id": "6cdd5ac0-fa18-4ee9-8051-062a0c56268f"
      },
      "source": [
        "### 用于查询分析的路由器 (Router for Query Analysis)\n",
        "\n",
        "让我们从路由（Routing）开始。首先，将查询分析任务分配给 LLM。\n",
        "\n",
        "创建一个 `RouteQuery` 数据模型，并以结构化格式将其指定给 LLM。路由的决策应嵌入到提示（prompt）中。您需要清楚地定义文档的哪些部分应根据主题定向到 RAG。\n",
        "\n",
        "虽然您可以通过让 LLM 再次总结 RAG 文档来自动化此过程，但在处理大型文档时，手动管理这种方式更具成本效益，因为自动化可能会变得昂贵。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# zhipu\n",
        "llm=ChatOpenAI(\n",
        "  base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
        "  model=\"glm-4.5-flash\",\n",
        "  max_tokens=32768,\n",
        "  temperature=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "E0JrCfQOIpx_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "E0JrCfQOIpx_"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# google\n",
        "llm=ChatGoogleGenerativeAI(\n",
        "  #model=\"gemini-2.5-flash\",\n",
        "  model=\"gemini-2.5-pro\",# ok\n",
        "  temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "aOcvvEzeIOlH"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "aOcvvEzeIOlH"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be",
      "metadata": {
        "id": "4dec9d98-f3dc-4b7f-abc0-9d01c754f2be",
        "outputId": "4472e217-f50b-4213-cda6-5057bc8e5db9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='web_search'\n",
            "datasource='vectorstore'\n"
          ]
        }
      ],
      "source": [
        "### Router\n",
        "\n",
        "from typing import Literal\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# Data model\n",
        "class RouteQuery(BaseModel):\n",
        "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
        "\n",
        "    datasource: Literal[\"vectorstore\", \"web_search\"] = Field(\n",
        "        ...,\n",
        "        description=\"Given a user question choose to route it to web search or a vectorstore.\",\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "structured_llm_router = llm.with_structured_output(RouteQuery)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
        "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
        "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
        "#system = \"\"\"你是一个专家，擅长将用户问题路由到向量存储（vectorstore）或网页搜索（web search）。\n",
        "#向量存储包含与智能体（agents）、提示工程（prompt engineering）和对抗性攻击（adversarial attacks）相关的文档。\n",
        "#对于有关这些主题的问题，请使用向量存储。否则，请使用网页搜索。\"\"\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_router = route_prompt | structured_llm_router\n",
        "print(\n",
        "    question_router.invoke(\n",
        "        {\"question\": \"Who will the Bears draft first in the NFL draft?\"}\n",
        "    )\n",
        ")\n",
        "print(question_router.invoke({\"question\": \"What are the types of agent memory?\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb248c94-0b0c-4d86-8565-32aa8d7424e4",
      "metadata": {
        "id": "cb248c94-0b0c-4d86-8565-32aa8d7424e4"
      },
      "source": [
        "### 检索评估器 (Retrieval Grader)\n",
        "\n",
        "在执行检索后，评估结果。尽管您最初根据查询决定使用 RAG，但检索到的文档可能并不令人满意。评估检索到的文档是否与查询充分相关。\n",
        "\n",
        "为此，将依赖 LLM 来评估相关性，提供一个“是”或“否”的二元决策。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "856801cb-f42a-44e7-956f-47845e3664ca",
      "metadata": {
        "id": "856801cb-f42a-44e7-956f-47845e3664ca",
        "outputId": "ae091955-4a71-4278-9762-4a00bf3227cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\n",
            "Generative Agents Simulation#\n",
            "Generative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\n",
            "The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\n",
            "\n",
            "Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\n",
            "\n",
            "Each element is an observation, an event directly provided by the agent.\n",
            "- Inter-agent communication can trigger new natural language statements.\n",
            "\n",
            "\n",
            "Retrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\n",
            "\n",
            "Recency: recent events have higher scores\n",
            "Importance: distinguish mundane from core memories. Ask LM directly.\n",
            "Relevance: based on how related it is to the current situation / query.\n",
            "\n",
            "\n",
            "Reflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\n",
            "\n",
            "Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\n",
            "\n",
            "\n",
            "Planning & Reacting: translate the reflections and the environment information into actions\n",
            "\n",
            "Planning is essentially in order to optimize believability at the moment vs in time.\n",
            "Prompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\n",
            "Relationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\n",
            "Environment information is present in a tree structure.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "The generative agent architecture. (Image source: Park et al. 2023)\n",
            "\n",
            "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
            "Proof-of-Concept Examples#\n",
            "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
            "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
            "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
            "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
            "\n",
            "GOALS:\n",
            "\n",
            "1. {{user-provided goal 1}}\n",
            "2. {{user-provided goal 2}}\n",
            "3. ...\n",
            "4. ...\n",
            "5. ...\n",
            "\n",
            "Constraints:\n",
            "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
            "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
            "3. No user assistance\n",
            "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
            "5. Use subprocesses for commands that will not terminate within a few minutes\n",
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "### Retrieval Grader\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
        "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "#system = \"\"\"你是一个评估检索到的文档与用户问题相关性的评分员。 \\n\n",
        "#    如果文档包含与用户问题相关的关键词或语义，请将其评为“相关”。 \\n\n",
        "#    这不需要是一个严格的测试。目标是过滤掉错误的检索结果。 \\n\n",
        "#    给出一个“是”或“否”的二元分数来表明文档是否与问题相关。\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = \"agent memory\"\n",
        "docs = retriever.invoke(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(doc_txt)\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Generate\n",
        "\n",
        "from langchain_classic import hub\n",
        "\n",
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUBSRJcpTQV7",
        "outputId": "ed8a1885-15e1-4a60-b5f6-8c81dbfa3db8"
      },
      "id": "iUBSRJcpTQV7",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(context=\"context\", question=\"question\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjuua2V_Xjpf",
        "outputId": "e0f51bf5-f1e8-4031-b174-0c600d7d5d5b"
      },
      "id": "qjuua2V_Xjpf",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
            "Question: question \n",
            "Context: context \n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
      "metadata": {
        "id": "2272333e-50b2-42ab-b472-e1055a3b94a8",
        "outputId": "d70badb5-1fa2-4999-e4de-ffa665d82b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM-powered agents utilize both short-term and long-term memory to function. Short-term memory consists of in-context learning, while long-term memory allows the agent to retain and recall information over extended periods, often using an external vector store. For instance, Generative Agents use a \"memory stream\" to record experiences, which are then retrieved based on relevance, recency, and importance to guide future behavior.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    if not isinstance(docs, list):\n",
        "        docs = [docs]\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "docs_txt = format_docs(docs)\n",
        "generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0ab54a-4a4f-45fa-b1c5-cea1bf4c59d5",
      "metadata": {
        "id": "cb0ab54a-4a4f-45fa-b1c5-cea1bf4c59d5"
      },
      "source": [
        "### 幻觉评估器 (Hallucination Grader)\n",
        "\n",
        "通过将 LLM 的输出与检索到的事实进行比较，核实其是否产生了任何幻觉。\n",
        "以“是”或“否”的二元格式提供 LLM 的评估结果。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
      "metadata": {
        "id": "f0c08d14-77a0-4eed-b882-2d636abb22a3",
        "outputId": "703a63bd-1b5c-4701-886f-4648bfcf3294",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeHallucinations(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "### Hallucination Grader\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeHallucinations(BaseModel):\n",
        "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \\n\n",
        "     Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.\"\"\"\n",
        "#system = \"\"\"你是一个评估 LLM 生成的内容是否以一组检索到的事实为依据/得到其支持的评分员。 \\n\n",
        "#     给出一个“是”或“否”的二元分数。 “是”表示该答案以这组事实为依据/得到其支持。\"\"\"\n",
        "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
        "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f58502a-c25f-4d80-a402-5583b0cd3e41",
      "metadata": {
        "id": "4f58502a-c25f-4d80-a402-5583b0cd3e41"
      },
      "source": [
        "### 答案评估器 (Answer Grader)\n",
        "\n",
        "最后评估答案。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "ded99680-437a-4c9d-b860-619c88949d84",
      "metadata": {
        "id": "ded99680-437a-4c9d-b860-619c88949d84",
        "outputId": "b1ccbabb-09f0-46bc-a530-4d641137769a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradeAnswer(binary_score='yes')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "### Answer Grader\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeAnswer(BaseModel):\n",
        "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing whether an answer addresses / resolves a question \\n\n",
        "     Give a binary score 'yes' or 'no'. Yes' means that the answer resolves the question.\"\"\"\n",
        "#system = \"\"\"你是一个评估答案是否回应/解决了问题的评分员。 \\n\n",
        "#     给出一个“是”或“否”的二元分数。 “是”表示该答案解决了问题。\"\"\"\n",
        "answer_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "answer_grader = answer_prompt | structured_llm_grader\n",
        "answer_grader.invoke({\"question\": question, \"generation\": generation})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af77946c-2646-4039-86b0-e2fde1ab7459",
      "metadata": {
        "id": "af77946c-2646-4039-86b0-e2fde1ab7459"
      },
      "source": [
        "### 问题重写 (Question Rewriting)\n",
        "\n",
        "用户提出的原始问题被直接用于 RAG。\n",
        "然而，用户的问题形式可能并不适合 RAG。\n",
        "为了提高检索效果，需要改写问题，以确保它能更好地与向量相似性搜索相匹配。\n",
        "\n",
        "这一步挺重要的，搜索引擎都会前置改写用户的查询意图，以便后续处理。像genspark这些智能体平台都是这样处理。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e",
      "metadata": {
        "id": "9d75f1d7-a47a-4577-bb0d-84b504b0867e",
        "outputId": "0ce935fe-7c1b-4934-ad63-b6dc17ae49c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'What are the different types of memory for AI agents, such as short-term, long-term, and sensory memory, and how are they implemented in agent architectures?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "### Question Re-writer\n",
        "\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "     for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning. \\n\n",
        "     Please provide the rewritten result directly.\"\"\"\n",
        "#system = \"\"\"你是一个问题改写器，它将输入的问题转换为一个为向量存储检索优化的更好版本。 \\n\n",
        "#     查看输入内容，并尝试推理其底层的语义意图/含义。\\n\n",
        "#     请直接给出改写过的结果。\"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
        "question_rewriter.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d07c0b31-b919-4498-869f-9673125c2473",
      "metadata": {
        "id": "d07c0b31-b919-4498-869f-9673125c2473"
      },
      "source": [
        "## 网页搜索工具\n",
        "\n",
        "使用 Tavily 搜索工具从网页获取信息。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "01d829bb-1074-4976-b650-ead41dcb9788",
      "metadata": {
        "id": "01d829bb-1074-4976-b650-ead41dcb9788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bde1b2-f448-4361-e228-39ba6dbf4307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-730760015.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  web_search_tool = TavilySearchResults(k=3)\n"
          ]
        }
      ],
      "source": [
        "### Search\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4",
      "metadata": {
        "id": "efbbff0e-8843-45bb-b2ff-137bef707ef4"
      },
      "source": [
        "## 构建图 (Construct the Graph)\n",
        "\n",
        "将流程捕获为图。\n",
        "\n",
        "### 定义图状态 (Define Graph State)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "e723fcdb-06e6-402d-912e-899795b78408",
      "metadata": {
        "id": "e723fcdb-06e6-402d-912e-899795b78408"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    documents: List[str]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2d6c0d-42e8-4399-9751-e315be16607a",
      "metadata": {
        "id": "7e2d6c0d-42e8-4399-9751-e315be16607a"
      },
      "source": [
        "### Define Graph Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a",
      "metadata": {
        "id": "b76b5ec3-0720-443d-85b1-c0e79659ca0a"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    #print(documents)\n",
        "\n",
        "    # RAG generation\n",
        "    docs_txt = format_docs(documents)\n",
        "    generation = rag_chain.invoke({\"context\": docs_txt, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"question\": question}\n",
        "\n",
        "\n",
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "\n",
        "    return {\"documents\": web_results, \"question\": question}\n",
        "\n",
        "\n",
        "### Edges ###\n",
        "\n",
        "\n",
        "def route_question(state):\n",
        "    \"\"\"\n",
        "    Route question to web search or RAG.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ROUTE QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    source = question_router.invoke({\"question\": question})\n",
        "    if source.datasource == \"web_search\":\n",
        "        print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
        "        return \"web_search\"\n",
        "    elif source.datasource == \"vectorstore\":\n",
        "        print(\"---ROUTE QUESTION TO RAG---\")\n",
        "        return \"vectorstore\"\n",
        "\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    state[\"question\"]\n",
        "    filtered_documents = state[\"documents\"]\n",
        "\n",
        "    if not filtered_documents:\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\n",
        "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "        )\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\"\n",
        "\n",
        "\n",
        "def grade_generation_v_documents_and_question(state):\n",
        "    \"\"\"\n",
        "    Determines whether the generation is grounded in the document and answers question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK HALLUCINATIONS---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "    generation = state[\"generation\"]\n",
        "\n",
        "    score = hallucination_grader.invoke(\n",
        "        {\"documents\": documents, \"generation\": generation}\n",
        "    )\n",
        "    grade = score.binary_score\n",
        "\n",
        "    # Check hallucination\n",
        "    if grade == \"yes\":\n",
        "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
        "        # Check question-answering\n",
        "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
        "        score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
        "            return \"useful\"\n",
        "        else:\n",
        "            print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
        "            return \"not useful\"\n",
        "    else:\n",
        "        pprint(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
        "        return \"not supported\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f",
      "metadata": {
        "id": "3ab01f36-5628-49ab-bfd3-84bb6f1a1b0f"
      },
      "source": [
        "### Compile Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee",
      "metadata": {
        "id": "67854e07-9293-4c3c-bf9a-bc9a605570ee"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"web_search\", web_search)  # web search\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "workflow.add_node(\"generate\", generate)  # generate\n",
        "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
        "\n",
        "# Build graph\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"web_search\": \"web_search\",\n",
        "        \"vectorstore\": \"retrieve\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"web_search\", \"generate\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    grade_generation_v_documents_and_question,\n",
        "    {\n",
        "        \"not supported\": \"generate\",\n",
        "        \"useful\": END,\n",
        "        \"not useful\": \"transform_query\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "YGnMQ1vhcbb3",
        "outputId": "31bc9dcb-db13-48b6-88d4-28303f75c466"
      },
      "id": "YGnMQ1vhcbb3",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85bce541",
      "metadata": {
        "id": "85bce541"
      },
      "source": [
        "## Use Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "29acc541-d726-4b75-84d1-a215845fe88a",
      "metadata": {
        "id": "29acc541-d726-4b75-84d1-a215845fe88a",
        "outputId": "3da9093e-01b0-4453-9cf5-22b7dc33f741",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO WEB SEARCH---\n",
            "---WEB SEARCH---\n",
            "\"Node 'web_search':\"\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "\"Node 'generate':\"\n",
            "'\\n---\\n'\n",
            "('As expected, the Chicago Bears selected USC quarterback Caleb Williams with '\n",
            " 'the first overall pick in the 2024 NFL Draft. The team acquired this top '\n",
            " 'pick through a trade made with the Carolina Panthers the previous year. '\n",
            " 'Williams was a quarterback from USC who threw for 3,333 yards and 30 '\n",
            " 'touchdowns in his last season.')\n"
          ]
        }
      ],
      "source": [
        "# Run\n",
        "inputs = {\n",
        "    \"question\": \"What player at the Bears expected to draft first in the 2024 NFL draft?\"\n",
        "}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        #pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trace: https://smith.langchain.com/public/893ab259-9eb9-4be7-b9b7-6fdaa47eb4a1/r"
      ],
      "metadata": {
        "id": "stvvlgTREECb"
      },
      "id": "stvvlgTREECb"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
      "metadata": {
        "id": "69a985dd-03c6-45af-a67b-b15746a2cb5f",
        "outputId": "a42d949b-683e-4d07-aa72-7d6496f82048",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---ROUTE QUESTION---\n",
            "---ROUTE QUESTION TO RAG---\n",
            "---RETRIEVE---\n",
            "\"Node 'retrieve':\"\n",
            "{ 'documents': [ Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
            "                 Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='Component Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\n\\nCategorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'),\n",
            "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
            "                 Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')],\n",
            "  'question': 'What are the types of agent memory?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: GENERATE---\n",
            "\"Node 'grade_documents':\"\n",
            "{ 'documents': [ Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
            "                 Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='Component Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\n\\nCategorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'),\n",
            "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
            "                 Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')],\n",
            "  'question': 'What are the types of agent memory?'}\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n",
            "---CHECK HALLUCINATIONS---\n",
            "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
            "---GRADE GENERATION vs QUESTION---\n",
            "---DECISION: GENERATION ADDRESSES QUESTION---\n",
            "\"Node 'generate':\"\n",
            "{ 'documents': [ Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
            "                 Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en'}, page_content='Component Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\n\\nCategorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.\\n\\nMaximum Inner Product Search (MIPS)#\\nThe external memory can alleviate the restriction of finite attention span.  A standard practice is to save the embedding representation of information into a vector store database that can support fast maximum inner-product search (MIPS). To optimize the retrieval speed, the common choice is the approximate nearest neighbors (ANN)\\u200b algorithm to return approximately top k nearest neighbors to trade off a little accuracy lost for a huge speedup.\\nA couple common choices of ANN algorithms for fast MIPS:'),\n",
            "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
            "                 Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')],\n",
            "  'generation': 'The types of agent memory are modeled after human memory and '\n",
            "                'include Sensory, Short-Term, and Long-Term Memory. Short-term '\n",
            "                'memory is considered in-context learning, limited by the '\n",
            "                \"model's finite context window. Long-term memory provides the \"\n",
            "                'agent with the ability to retain and recall information over '\n",
            "                'extended periods, often by using an external vector store.',\n",
            "  'question': 'What are the types of agent memory?'}\n",
            "'\\n---\\n'\n",
            "('The types of agent memory are modeled after human memory and include '\n",
            " 'Sensory, Short-Term, and Long-Term Memory. Short-term memory is considered '\n",
            " \"in-context learning, limited by the model's finite context window. Long-term \"\n",
            " 'memory provides the agent with the ability to retain and recall information '\n",
            " 'over extended periods, often by using an external vector store.')\n"
          ]
        }
      ],
      "source": [
        "# Run\n",
        "config = {\"recursion_limit\": 10}\n",
        "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
        "for output in app.stream(inputs, config=config):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- bad case (recursion_limit) trace: https://smith.langchain.com/public/efa0973a-96c5-4e1d-ae77-1d12166057f7/r\n",
        "- good case trace: https://smith.langchain.com/public/174000c4-1ea6-4c1f-9486-fd9a3ea97440/r"
      ],
      "metadata": {
        "id": "r2rPBsDo9gR8"
      },
      "id": "r2rPBsDo9gR8"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}