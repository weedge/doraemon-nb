{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/langchain/rag/langgraph_crag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8889a307-fa3f-4d38-9127-d41e4686ae47",
      "metadata": {
        "id": "8889a307-fa3f-4d38-9127-d41e4686ae47"
      },
      "source": [
        "- https://arxiv.org/html/2401.15884\n",
        "- https://github.com/HuskyInSalt/CRAG\n",
        "\n",
        "# Corrective RAG (CRAG)\n",
        "\n",
        "Corrective-RAG (CRAG)（纠正性RAG）是一种RAG策略，它融合了对检索到的文档进行自我反思 / 自我评估（的功能）。\n",
        "\n",
        "在[这里](https://arxiv.org/pdf/2401.15884.pdf)的论文中，采取了几个步骤：\n",
        "\n",
        "  * 如果至少有一篇文档超过了相关性阈值，那么它将继续进行生成\n",
        "  * 在生成之前，它会执行知识精炼（knowledge refinement）\n",
        "  * 这将文档分割成“知识条带”（knowledge strips）\n",
        "  * 它对每个条带进行评分，并过滤掉不相关的条带\n",
        "  * 如果所有文档都低于相关性阈值，或者评估器（grader）不确定，那么该框架会寻求额外的数据源\n",
        "  * 它将使用网页搜索来补充检索\n",
        "\n",
        "我们将使用 [LangGraph](https://langchain-ai.github.io/langgraph/) 从头开始实现其中的一些想法：\n",
        "\n",
        "  * 作为初步尝试，我们先跳过知识精炼阶段。如果需要，这可以稍后作为一个节点添加回来。\n",
        "  * 如果*任何*文档不相关，我们就选择用网页搜索来补充检索。\n",
        "  * 我们将使用 [Tavily Search](https://python.langchain.com/docs/integrations/tools/tavily_search/) 进行网页搜索。\n",
        "  * 我们将使用查询重写（query re-writing）来为网页搜索优化查询。\n",
        "\n",
        "![](https://github-production-user-asset-6210df.s3.amazonaws.com/1203957/510231976-62c6392e-f4ae-408a-afd8-92031ba2ea38.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20251105%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251105T155341Z&X-Amz-Expires=300&X-Amz-Signature=b718214fb6a5e8fabe8c0dece8f015b176617429b87ac894f4c0dfff8abbeefb&X-Amz-SignedHeaders=host)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a44a72d6-7e0c-4478-9d20-4c09000420a8"
      },
      "source": [
        "## 设置 (Setup)\n",
        "\n",
        "首先，我们需要安装所需的包。"
      ],
      "id": "a44a72d6-7e0c-4478-9d20-4c09000420a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b451b58a-89bd-424f-8c06-0d9fe325e01b"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet -U langchain_community tiktoken langchain-openai langchain-cohere langchainhub chromadb langchain langgraph  tavily-python langchain-google-genai langchain-text-splitters"
      ],
      "id": "b451b58a-89bd-424f-8c06-0d9fe325e01b"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"langchain|langgraph|chromadb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoRFlZmMGi3W",
        "outputId": "b166ffa1-09b7-4b12-c19c-391210d6bb84"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "chromadb                                 1.3.4\n",
            "langchain                                1.0.3\n",
            "langchain-classic                        1.0.0\n",
            "langchain-cohere                         0.5.0\n",
            "langchain-community                      0.4.1\n",
            "langchain-core                           1.0.3\n",
            "langchain-google-genai                   3.0.1\n",
            "langchain-openai                         1.0.2\n",
            "langchain-text-splitters                 1.0.0\n",
            "langchainhub                             0.1.21\n",
            "langgraph                                1.0.2\n",
            "langgraph-checkpoint                     3.0.1\n",
            "langgraph-prebuilt                       1.0.2\n",
            "langgraph-sdk                            0.2.9\n"
          ]
        }
      ],
      "id": "uoRFlZmMGi3W"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35f267b0-98db-4a59-8b2c-a23f795576ff"
      },
      "source": [
        "接下来，我们需要为 OpenAI（我们将使用的 LLM）和 Tavily（我们将使用的搜索工具）设置 API 密钥。"
      ],
      "id": "35f267b0-98db-4a59-8b2c-a23f795576ff"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=userdata.get(\"ZHIPU_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"]=userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"GOOGLE_API_KEY\"]=userdata.get(\"GOOGLE_API_KEY\")\n",
        "os.environ[\"GITEE_API_KEY\"]=userdata.get(\"GITEE_API_KEY\")\n",
        "\n"
      ],
      "id": "743c19df-6da9-4d1e-b2d2-ea40080b9fdc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab5cea6d"
      },
      "source": [
        "<div class=\"admonition tip\"> <p class=\"admonition-title\">设置 <a href=\"https://smith.langchain.com\">LangSmith</a> 以用于 LangGraph 开发</p> <p style=\"padding-top: 5px;\"> 注册 LangSmith 可以快速发现问题并提高您的 LangGraph 项目的性能。LangSmith 允许您使用跟踪数据来调试、测试和监控使用 LangGraph 构建的 LLM 应用程序——阅读更多关于如何开始的信息 <a href=\"https://docs.smith.langchain.com\">请点击此处</a>。 </p> </div>"
      ],
      "id": "ab5cea6d"
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"LANGSMITH_API_KEY\"]=userdata.get(\"LANGSMITH_API_KEY\")\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "IooCYxWjE5il"
      },
      "execution_count": 4,
      "outputs": [],
      "id": "IooCYxWjE5il"
    },
    {
      "cell_type": "markdown",
      "id": "a21f32d2-92ce-4995-b309-99347bafe3be",
      "metadata": {
        "id": "a21f32d2-92ce-4995-b309-99347bafe3be"
      },
      "source": [
        "## Create Index\n",
        "\n",
        "Let's index 3 blog posts."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "\tbase_url=\"https://ai.gitee.com/v1\",\n",
        "\tapi_key=os.environ[\"GITEE_API_KEY\"],\n",
        "\tdefault_headers={\"X-Failover-Enabled\":\"true\"},\n",
        ")\n",
        "\n",
        "response = client.embeddings.create(\n",
        "\tinput=\"Today is a sunny day and I will get some ice cream.\",\n",
        "\tmodel=\"Qwen3-Embedding-8B\",\n",
        "\tdimensions=1024,\n",
        ")\n"
      ],
      "metadata": {
        "id": "XVD5LL-TjqFS"
      },
      "execution_count": null,
      "outputs": [],
      "id": "XVD5LL-TjqFS"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "### from langchain_cohere import CohereEmbeddings\n",
        "\n",
        "# Set embeddings\n",
        "# https://ai.gitee.com/serverless-api#embedding-rerank\n",
        "# 100 api calls per day, free tier ..................NO!!!! ❄️\n",
        "embd = OpenAIEmbeddings(\n",
        "    base_url=\"https://ai.gitee.com/v1\",\n",
        "    model=\"Qwen3-Embedding-8B\",#4096\n",
        "    api_key=os.environ[\"GITEE_API_KEY\"],\n",
        "    dimensions=1024,\n",
        "    check_embedding_ctx_length=False,\n",
        "    chunk_size=1000,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "ydSF1Bzhg8H5"
      },
      "execution_count": 5,
      "outputs": [],
      "id": "ydSF1Bzhg8H5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "定义批量大小"
      ],
      "metadata": {
        "id": "U5CigAnqDybh"
      },
      "id": "U5CigAnqDybh"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "from chromadb.api.client import Client as ClientCreator\n",
        "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE\n",
        "from chromadb.config import Settings, System\n",
        "\n",
        "class CustomClientCreator(ClientCreator):\n",
        "    # region Initialization\n",
        "    def __init__(\n",
        "        self,\n",
        "        tenant: Optional[str] = DEFAULT_TENANT,\n",
        "        database: Optional[str] = DEFAULT_DATABASE,\n",
        "        settings: Settings = Settings(),\n",
        "    ) -> None:\n",
        "        super().__init__(tenant=tenant, database=database, settings=settings)\n",
        "\n",
        "    def get_max_batch_size(self) -> int:\n",
        "        return 10  # some server api limit batch size"
      ],
      "metadata": {
        "id": "sGHKHtSTDxu1"
      },
      "execution_count": 9,
      "outputs": [],
      "id": "sGHKHtSTDxu1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build Index"
      ],
      "metadata": {
        "id": "gHY7Kz5w5XU6"
      },
      "id": "gHY7Kz5w5XU6"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3a566a30-cf0e-4330-ad4d-9bf994bdfa86",
      "metadata": {
        "id": "3a566a30-cf0e-4330-ad4d-9bf994bdfa86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736629de-5574-4d97-c66d-350be0a298c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "urls = [\n",
        "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
        "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
        "]\n",
        "\n",
        "docs = [WebBaseLoader(url).load() for url in urls]\n",
        "docs_list = [item for sublist in docs for item in sublist]\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=1000, chunk_overlap=0\n",
        ")\n",
        "doc_splits = text_splitter.split_documents(docs_list)\n",
        "\n",
        "print(len(doc_splits))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# Add to vectorstore\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents=doc_splits,\n",
        "    collection_name=\"rag-chroma\",\n",
        "    persist_directory=\"./rag_chroma_db\",# sqlite(row) file path or duckdb(column) file path\n",
        "    embedding=embd,\n",
        "    client=CustomClientCreator(),  # use custom client with batch utils\n",
        ")\n",
        "retriever = vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "HXIqSRoVFiAA"
      },
      "execution_count": 10,
      "outputs": [],
      "id": "HXIqSRoVFiAA"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHtd4yeVJNON",
        "outputId": "3110702d-aa07-42cf-e923-bc53dd0c9f71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f2a713da2a0>, search_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "id": "AHtd4yeVJNON"
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"agent memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4SfmqsWJJI6",
        "outputId": "db320d7e-42b9-48f9-d065-8774fbe64c5b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
              " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
              " Document(metadata={'language': 'en', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "id": "f4SfmqsWJJI6"
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xPKosva7wS_",
        "outputId": "d8744a57-f77b-49d6-eb73-5cc21ddc94df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-398866168.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectorstore.persist()\n"
          ]
        }
      ],
      "id": "9xPKosva7wS_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### use indexed docs"
      ],
      "metadata": {
        "id": "rWaiQ6eW5bcQ"
      },
      "id": "rWaiQ6eW5bcQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "retriveal_vectorstore = Chroma(\n",
        "    collection_name=\"rag-chroma\",\n",
        "    persist_directory=\"./rag_chroma_db\",# sqlite(row) file path or duckdb(column) file path\n",
        "    embedding_function=embd,\n",
        "    client=CustomClientCreator(),  # use custom client with batch utils\n",
        ")\n",
        "\n",
        "retriveal_retriever = retriveal_vectorstore.as_retriever()"
      ],
      "metadata": {
        "id": "KAN1EgBy5kDM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd330a93-2897-4360-9f29-4f081897ddc3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2217942785.py:3: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
            "  retriveal_vectorstore = Chroma(\n"
          ]
        }
      ],
      "id": "KAN1EgBy5kDM"
    },
    {
      "cell_type": "code",
      "source": [
        "retriveal_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU-Uy9Ev7Ux3",
        "outputId": "cd4013d5-ba0d-412c-ced9-978660584848"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f2a6ff0b8c0>, search_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "id": "FU-Uy9Ev7Ux3"
    },
    {
      "cell_type": "code",
      "source": [
        "retriveal_retriever.invoke(\"agent memory\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxPUoTo27WzY",
        "outputId": "716a2d26-65d3-4a05-d810-0ee0d8da80c6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X\\'s plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\\n\\nThis fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\\nProof-of-Concept Examples#\\nAutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\\nHere is the system message used by AutoGPT, where {{...}} are user inputs:\\nYou are {{ai-name}}, {{user-provided AI bot description}}.\\nYour decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\\n\\nGOALS:\\n\\n1. {{user-provided goal 1}}\\n2. {{user-provided goal 2}}\\n3. ...\\n4. ...\\n5. ...\\n\\nConstraints:\\n1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\\n2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\\n3. No user assistance\\n4. Exclusively use the commands listed in double quotes e.g. \"command name\"\\n5. Use subprocesses for commands that will not terminate within a few minutes'),\n",
              " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.\"),\n",
              " Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:\\nThought: ...\\nAction: ...\\nObservation: ...\\n... (Repeated many times)\\n\\n\\nExamples of reasoning trajectories for knowledge-intensive tasks (e.g. HotpotQA, FEVER) and decision-making tasks (e.g. AlfWorld Env, WebShop). (Image source: Yao et al. 2023).\\n\\nIn both experiments on knowledge-intensive tasks and decision-making tasks, ReAct works better than the Act-only baseline where Thought: … step is removed.\\nReflexion (Shinn & Labash 2023) is a framework to equip agents with dynamic memory and self-reflection capabilities to improve reasoning skills. Reflexion has a standard RL setup, in which the reward model provides a simple binary reward and the action space follows the setup in ReAct where the task-specific action space is augmented with language to enable complex reasoning steps. After each action $a_t$, the agent computes a heuristic $h_t$ and optionally may decide to reset the environment to start a new trial depending on the self-reflection results.\\n\\n\\nIllustration of the Reflexion framework. (Image source: Shinn & Labash, 2023)\\n\\nThe heuristic function determines when the trajectory is inefficient or contains hallucination and should be stopped. Inefficient planning refers to trajectories that take too long without success. Hallucination is defined as encountering a sequence of consecutive identical actions that lead to the same observation in the environment.\\nSelf-reflection is created by showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Then reflections are added into the agent’s working memory, up to three, to be used as context for querying LLM.\\n\\n\\nExperiments on AlfWorld Env and HotpotQA. Hallucination is a more common failure than inefficient planning in AlfWorld. (Image source: Shinn & Labash, 2023)')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "id": "lxPUoTo27WzY"
    },
    {
      "cell_type": "markdown",
      "id": "6fca2db8-8d68-42b0-981d-4be5ccdbe293",
      "metadata": {
        "id": "6fca2db8-8d68-42b0-981d-4be5ccdbe293"
      },
      "source": [
        "## LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1da8975-f2c4-4584-a0f9-bd5af88983a3",
      "metadata": {
        "id": "c1da8975-f2c4-4584-a0f9-bd5af88983a3"
      },
      "source": [
        "<div class=\"admonition note\"> <p class=\"admonition-title\">将 Pydantic 与 LangChain 配合使用</p> <p> 本笔记（notebook）使用 Pydantic v2 <code>BaseModel</code>，这需要 <code>langchain-core >= 0.3</code>。如果使用 <code>langchain-core < 0.3</code>，将会因 Pydantic v1 和 v2 <code>BaseModels</code> 混用而导致错误。 </p> </div>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# zhipu\n",
        "llm=ChatOpenAI(\n",
        "  base_url=\"https://open.bigmodel.cn/api/paas/v4\",\n",
        "  model=\"glm-4.5-flash\",\n",
        "  max_tokens=32768,\n",
        "  temperature=0\n",
        ")\n"
      ],
      "metadata": {
        "id": "E0JrCfQOIpx_"
      },
      "execution_count": null,
      "outputs": [],
      "id": "E0JrCfQOIpx_"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# google\n",
        "llm=ChatGoogleGenerativeAI(\n",
        "  #model=\"gemini-2.5-flash\",\n",
        "  model=\"gemini-2.5-pro\",# ok\n",
        "  temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "aOcvvEzeIOlH"
      },
      "execution_count": 17,
      "outputs": [],
      "id": "aOcvvEzeIOlH"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7ece414c-2df5-4ffd-aa82-550a65775261",
      "metadata": {
        "id": "7ece414c-2df5-4ffd-aa82-550a65775261",
        "outputId": "e854debb-94f4-4e11-e360-94387f7ee185",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "binary_score='yes'\n"
          ]
        }
      ],
      "source": [
        "### Retrieval Grader\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "# Data model\n",
        "class GradeDocuments(BaseModel):\n",
        "    \"\"\"Binary score for relevance check on retrieved documents.\"\"\"\n",
        "\n",
        "    binary_score: str = Field(\n",
        "        description=\"Documents are relevant to the question, 'yes' or 'no'\"\n",
        "    )\n",
        "\n",
        "\n",
        "# LLM with function call\n",
        "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
        "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
        "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
        "grade_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "retrieval_grader = grade_prompt | structured_llm_grader\n",
        "question = \"agent memory\"\n",
        "docs = retriever.invoke(question)\n",
        "doc_txt = docs[1].page_content\n",
        "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a207c85f-e414-46b7-8999-4c0ead1493da",
      "metadata": {
        "id": "a207c85f-e414-46b7-8999-4c0ead1493da",
        "outputId": "e86851d6-7705-4523-9dba-8b43aa99b2ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM-powered autonomous agents have two key memory components. Short-term memory is used for in-context learning, similar to the information within a single prompt. Long-term memory provides the ability to retain and recall information over extended periods, often by using an external vector store for fast retrieval.\n"
          ]
        }
      ],
      "source": [
        "### Generate\n",
        "\n",
        "from langchain_classic import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Prompt\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Post-processing\n",
        "def format_docs(docs):\n",
        "    if not isinstance(docs, list):\n",
        "        docs = [docs]\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "\n",
        "# Chain\n",
        "rag_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "# Run\n",
        "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
        "print(generation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "30d0a69b-9087-4f85-af26-cab55b567872",
      "metadata": {
        "id": "30d0a69b-9087-4f85-af26-cab55b567872",
        "outputId": "581018fc-a26f-4244-8f30-3eccf15d3b34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Techniques for implementing memory in AI agents'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "### Question Re-writer\n",
        "\n",
        "# Prompt\n",
        "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n\n",
        "     for web search. Look at the input and try to reason about the underlying semantic intent / meaning.\\n\n",
        "     Please provide the rewritten result directly.\"\"\"\n",
        "re_write_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
        "question_rewriter.invoke({\"question\": question})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4538467-4a15-4733-b93c-2b79d4d6bf25",
      "metadata": {
        "id": "e4538467-4a15-4733-b93c-2b79d4d6bf25"
      },
      "source": [
        "## Web Search Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "46d51b53-54a9-4e0a-9f14-e39998f5b340",
      "metadata": {
        "id": "46d51b53-54a9-4e0a-9f14-e39998f5b340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116c943b-2b81-4dff-ef81-f501e54ab135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-730760015.py:5: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the `langchain-tavily package and should be used instead. To use it run `pip install -U `langchain-tavily` and import as `from `langchain_tavily import TavilySearch``.\n",
            "  web_search_tool = TavilySearchResults(k=3)\n"
          ]
        }
      ],
      "source": [
        "### Search\n",
        "\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "web_search_tool = TavilySearchResults(k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87194a1b-535a-4593-ab95-5736fae176d1",
      "metadata": {
        "id": "87194a1b-535a-4593-ab95-5736fae176d1"
      },
      "source": [
        "## Create Graph\n",
        "\n",
        "Now let's create our graph that will use CRAG\n",
        "\n",
        "### Define Graph State"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "94b3945f-ef0f-458d-a443-f763903550b0",
      "metadata": {
        "id": "94b3945f-ef0f-458d-a443-f763903550b0"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph.\n",
        "\n",
        "    Attributes:\n",
        "        question: question\n",
        "        generation: LLM generation\n",
        "        web_search: whether to add search\n",
        "        documents: list of documents\n",
        "    \"\"\"\n",
        "\n",
        "    question: str\n",
        "    generation: str\n",
        "    web_search: str\n",
        "    documents: List[str]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "efd639c5-82e2-45e6-a94a-6a4039646ef5",
      "metadata": {
        "id": "efd639c5-82e2-45e6-a94a-6a4039646ef5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "\n",
        "def retrieve(state):\n",
        "    \"\"\"\n",
        "    Retrieve documents\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, documents, that contains retrieved documents\n",
        "    \"\"\"\n",
        "    print(\"---RETRIEVE---\")\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Retrieval\n",
        "    documents = retriever.invoke(question)\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "def generate(state):\n",
        "    \"\"\"\n",
        "    Generate answer\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): New key added to state, generation, that contains LLM generation\n",
        "    \"\"\"\n",
        "    print(\"---GENERATE---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # RAG generation\n",
        "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
        "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
        "\n",
        "\n",
        "def grade_documents(state):\n",
        "    \"\"\"\n",
        "    Determines whether the retrieved documents are relevant to the question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with only filtered relevant documents\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Score each doc\n",
        "    filtered_docs = []\n",
        "    web_search = \"No\"\n",
        "    for d in documents:\n",
        "        score = retrieval_grader.invoke(\n",
        "            {\"question\": question, \"document\": d.page_content}\n",
        "        )\n",
        "        grade = score.binary_score\n",
        "        if grade == \"yes\":\n",
        "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
        "            filtered_docs.append(d)\n",
        "        else:\n",
        "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
        "            web_search = \"Yes\"\n",
        "            continue\n",
        "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
        "\n",
        "\n",
        "def transform_query(state):\n",
        "    \"\"\"\n",
        "    Transform the query to produce a better question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates question key with a re-phrased question\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---TRANSFORM QUERY---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Re-write question\n",
        "    better_question = question_rewriter.invoke({\"question\": question})\n",
        "    return {\"documents\": documents, \"question\": better_question}\n",
        "\n",
        "\n",
        "def web_search(state):\n",
        "    \"\"\"\n",
        "    Web search based on the re-phrased question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        state (dict): Updates documents key with appended web results\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---WEB SEARCH---\")\n",
        "    question = state[\"question\"]\n",
        "    documents = state[\"documents\"]\n",
        "\n",
        "    # Web search\n",
        "    docs = web_search_tool.invoke({\"query\": question})\n",
        "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
        "    web_results = Document(page_content=web_results)\n",
        "    documents.append(web_results)\n",
        "\n",
        "    return {\"documents\": documents, \"question\": question}\n",
        "\n",
        "\n",
        "### Edges\n",
        "\n",
        "\n",
        "def decide_to_generate(state):\n",
        "    \"\"\"\n",
        "    Determines whether to generate an answer, or re-generate a question.\n",
        "\n",
        "    Args:\n",
        "        state (dict): The current graph state\n",
        "\n",
        "    Returns:\n",
        "        str: Binary decision for next node to call\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
        "    state[\"question\"]\n",
        "    web_search = state[\"web_search\"]\n",
        "    state[\"documents\"]\n",
        "\n",
        "    if web_search == \"Yes\":\n",
        "        # All documents have been filtered check_relevance\n",
        "        # We will re-generate a new query\n",
        "        print(\n",
        "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
        "        )\n",
        "        return \"transform_query\"\n",
        "    else:\n",
        "        # We have relevant documents, so generate answer\n",
        "        print(\"---DECISION: GENERATE---\")\n",
        "        return \"generate\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa076e90-7132-4fcf-8507-db5990314c4f",
      "metadata": {
        "id": "fa076e90-7132-4fcf-8507-db5990314c4f"
      },
      "source": [
        "### Compile Graph\n",
        "\n",
        "The just follows the flow we outlined in the figure above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "dedae17a-98c6-474d-90a7-9234b7c8cea0",
      "metadata": {
        "id": "dedae17a-98c6-474d-90a7-9234b7c8cea0"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import END, StateGraph, START\n",
        "\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
        "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
        "workflow.add_node(\"generate\", generate)  # generate\n",
        "workflow.add_node(\"transform_query\", transform_query)  # transform_query\n",
        "workflow.add_node(\"web_search_node\", web_search)  # web search\n",
        "\n",
        "# Build graph\n",
        "workflow.add_edge(START, \"retrieve\")\n",
        "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
        "workflow.add_conditional_edges(\n",
        "    \"grade_documents\",\n",
        "    decide_to_generate,\n",
        "    {\n",
        "        \"transform_query\": \"transform_query\",\n",
        "        \"generate\": \"generate\",\n",
        "    },\n",
        ")\n",
        "workflow.add_edge(\"transform_query\", \"web_search_node\")\n",
        "workflow.add_edge(\"web_search_node\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# Compile\n",
        "app = workflow.compile()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "ETrdF4hKojAS",
        "outputId": "6351307b-2663-437b-bc82-b29deca6be07"
      },
      "id": "ETrdF4hKojAS",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27ba16a8",
      "metadata": {
        "id": "27ba16a8"
      },
      "source": [
        "## Use the graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "f5b7c2fe-1fc7-4b76-bf93-ba701a40aa6b",
      "metadata": {
        "id": "f5b7c2fe-1fc7-4b76-bf93-ba701a40aa6b",
        "outputId": "ed620fce-c784-4867-c7af-34663835a160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVE---\n",
            "\"Node 'retrieve':\"\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "\"Node 'grade_documents':\"\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "\"Node 'transform_query':\"\n",
            "'\\n---\\n'\n",
            "---WEB SEARCH---\n",
            "\"Node 'web_search_node':\"\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n",
            "\"Node 'generate':\"\n",
            "'\\n---\\n'\n",
            "('AI agent memory architectures enable systems to store and recall past '\n",
            " 'experiences to improve decision-making and overall performance. The primary '\n",
            " 'types are short-term memory, which utilizes in-context learning limited by '\n",
            " \"the model's context window, and long-term memory. Long-term memory allows \"\n",
            " 'agents to retain information across sessions by using external storage like '\n",
            " 'vector stores, databases, or knowledge graphs for fast retrieval.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\"question\": \"What are the types of agent memory?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "trace: https://smith.langchain.com/public/e85dbf0f-3fd4-4098-bcfe-4414e1d9a948/r"
      ],
      "metadata": {
        "id": "EAFtW_eqyLNo"
      },
      "id": "EAFtW_eqyLNo"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "41ea1108-f385-4774-962d-db157922e231",
      "metadata": {
        "id": "41ea1108-f385-4774-962d-db157922e231",
        "outputId": "9415fba5-a1a4-4850-a0ea-2a42951540a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---RETRIEVE---\n",
            "\"Node 'retrieve':\"\n",
            "{ 'documents': [ Document(metadata={'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.'}, page_content='Commands:\\n1. Google Search: \"google\", args: \"input\": \"<search>\"\\n2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\\n3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\\n4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\\n5. List GPT Agents: \"list_agents\", args:\\n6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\\n7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\\n8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n9. Read file: \"read_file\", args: \"file\": \"<file>\"\\n10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\\n11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\\n12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\\n13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\\n14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\\n15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\\n16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\\n17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\\n18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\\n19. Do Nothing: \"do_nothing\", args:\\n20. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\\n\\nResources:\\n1. Internet access for searches and information gathering.\\n2. Long Term memory management.\\n3. GPT-3.5 powered Agents for delegation of simple tasks.\\n4. File output.\\n\\nPerformance Evaluation:\\n1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\\n2. Constructively self-criticize your big-picture behavior constantly.\\n3. Reflect on past decisions and strategies to refine your approach.\\n4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.'),\n",
            "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en'}, page_content='Powered by\\n        Hugo &\\n        PaperMod'),\n",
            "                 Document(metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='You should only respond in JSON format as described below\\nResponse Format:\\n{\\n    \"thoughts\": {\\n        \"text\": \"thought\",\\n        \"reasoning\": \"reasoning\",\\n        \"plan\": \"- short bulleted\\\\n- list that conveys\\\\n- long-term plan\",\\n        \"criticism\": \"constructive self-criticism\",\\n        \"speak\": \"thoughts summary to say to user\"\\n    },\\n    \"command\": {\\n        \"name\": \"command name\",\\n        \"args\": {\\n            \"arg name\": \"value\"\\n        }\\n    }\\n}\\nEnsure the response can be parsed by Python json.loads\\nGPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed.\\nHere are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\\n[\\n  {\\n    \"role\": \"system\",\\n    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\\\nThen you will pick one clarifying question, and wait for an answer from the user.\\\\n\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\\\n\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.\\nSystem message:'),\n",
            "                 Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en', 'title': \"Prompt Engineering | Lil'Log\"}, page_content='... in language that is safe for work.\\nIn-context instruction learning (Ye et al. 2023) combines few-shot learning with instruction prompting. It incorporates multiple demonstration examples across different tasks in the prompt, each demonstration consisting of instruction, task input and output. Note that their experiments were only on classification tasks and the instruction prompt contains all label options.\\nDefinition: Determine the speaker of the dialogue, \"agent\" or \"customer\".\\nInput: I have successfully booked your tickets.\\nOuput: agent\\n\\nDefinition: Determine which category the question asks for, \"Quantity\" or \"Location\".\\nInput: What\\'s the oldest building in US?\\nOuput: Location\\n\\nDefinition: Classify the sentiment of the given movie review, \"positive\" or \"negative\".\\nInput: i\\'ll bet the video game is a lot more fun than the film.\\nOutput:\\nSelf-Consistency Sampling#\\nSelf-consistency sampling (Wang et al. 2022a) is to sample multiple outputs with temperature > 0 and then selecting the best one out of these candidates.\\nThe criteria for selecting the best candidate can vary from task to task. A general solution is to pick majority vote. For tasks that are easy to validate such as a programming question with unit tests, we can simply run through the interpreter and verify the correctness with unit tests.\\nChain-of-Thought (CoT)#\\nChain-of-thought (CoT) prompting (Wei et al. 2022) generates a sequence of short sentences to describe reasoning logics step by step, known as reasoning chains or rationales, to eventually lead to the final answer. The benefit of CoT is more pronounced for complicated reasoning tasks, while using large models (e.g. with more than 50B parameters). Simple tasks only benefit slightly from CoT prompting.\\nTypes of CoT prompts#\\nTwo main types of CoT prompting:\\n\\nFew-shot CoT. It is to prompt the model with a few demonstrations, each containing manually written (or model-generated) high-quality reasoning chains.\\n\\n(All the math reasoning examples are from GSM8k)\\nQuestion: Tom and Elizabeth have a competition to climb a hill. Elizabeth takes 30 minutes to climb the hill. Tom takes four times as long as Elizabeth does to climb the hill. How many hours does it take Tom to climb up the hill?\\nAnswer: It takes Tom 30*4 = <<30*4=120>>120 minutes to climb the hill.\\nIt takes Tom 120/60 = <<120/60=2>>2 hours to climb the hill.\\nSo the answer is 2.\\n===\\nQuestion: Jack is a soccer player. He needs to buy two pairs of socks and a pair of soccer shoes. Each pair of socks cost $9.50, and the shoes cost $92. Jack has $40. How much more money does Jack need?\\nAnswer: The total cost of two pairs of socks is $9.50 x 2 = $<<9.5*2=19>>19.\\nThe total cost of the socks and the shoes is $19 + $92 = $<<19+92=111>>111.\\nJack need $111 - $40 = $<<111-40=71>>71 more.\\nSo the answer is 71.\\n===\\nQuestion: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?\\nAnswer:\\n\\nZero-shot CoT. Use natural language statement like Let\\'s think step by step to explicitly encourage the model to first generate reasoning chains and then to prompt with Therefore, the answer is to produce answers (Kojima et al. 2022 ). Or a similar statement Let\\'s work this out it a step by step to be sure we have the right answer (Zhou et al. 2022).\\n\\nQuestion: Marty has 100 centimeters of ribbon that he must cut into 4 equal parts. Each of the cut parts must be divided into 5 equal parts. How long will each final cut be?\\nAnswer: Let\\'s think step by step.\\nTips and Extensions#\\n\\n\\nSelf-consistency sampling can improve reasoning accuracy by sampling a number of diverse answers and then taking the majority vote. (Wang et al. 2022a)\\n\\n\\nAnother approach for ensemble learning is to alter the example order or use model generated rationales to replace human-written ones to introduce randomness during multiple sample trials. Then aggregate model outputs with a majority vote to get final answer. (Wang et al. 2022b)')],\n",
            "  'question': 'How does the AlphaCodium paper work?'}\n",
            "'\\n---\\n'\n",
            "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---GRADE: DOCUMENT NOT RELEVANT---\n",
            "---ASSESS GRADED DOCUMENTS---\n",
            "---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\n",
            "\"Node 'grade_documents':\"\n",
            "{ 'documents': [],\n",
            "  'question': 'How does the AlphaCodium paper work?',\n",
            "  'web_search': 'Yes'}\n",
            "'\\n---\\n'\n",
            "---TRANSFORM QUERY---\n",
            "\"Node 'transform_query':\"\n",
            "{'documents': [], 'question': 'Summary of the AlphaCodium paper methodology'}\n",
            "'\\n---\\n'\n",
            "---WEB SEARCH---\n",
            "\"Node 'web_search_node':\"\n",
            "{ 'documents': [ Document(metadata={}, page_content='## Unlocking the Potential\\n\\nAlphaCodium’s unique methodology comprises two main phases: pre-processing and code iterations. In the pre-processing phase, the tool analyzes the problem, generates potential solutions, and ranks them based on complexity and robustness. The subsequent code iteration phase involves running on AI-generated test cases, iteratively fixing errors until a flawless solution emerges. The result is 12-15% higher accuracy with a significantly reduced computational budget. [...] In the rapidly evolving landscape of artificial intelligence, CodiumAI has unveiled AlphaCodium, an open-source AI code-generation tool that challenges the status quo. This revolutionary approach, showcased in a recent arXiv paper, introduces a flow engineering method to enhance code generation accuracy by up to 44%. Let’s delve into the intricacies of AlphaCodium and its potential impact on the field.\\n\\nAlso Read: Microsoft’s WaveCoder and CodeOcean Revolutionize Instruction Tuning [...] In a landscape where breakthroughs are often hailed prematurely, AlphaCodium stands out as a genuine advancement in AI code generation. By embracing a flow engineering approach, it goes beyond conventional prompting techniques, addressing the limitations faced by previous models. The significance of self-reflection, additional AI tests, and a meticulous iterative process cannot be overstated.\\nIn this paper, we present AlphaCodium, a code-oriented flow that revolves around an iterative process where we re-peatedly run and fix a generated code against input-output tests. Two key elements for AlphaCodium flow are (a) gen-erating additional data, such as problem reflection and test reasoning, to aid the iterative process, and (b) enrichment of public tests with additional AI-generated tests. The pro-posed flow, which is depicted in Figure 1, is divided into two main phases: a [...] 6. Conclusions In this paper, we introduced AlphaCodium, a code-oriented flow that iteratively runs and fixes a generated code against input-output tests. The flow is divided into two main phases: a pre-processing phase, where AlphaCodium rea-sons about the problem in natural language, and a code iter-ations phase, in which AlphaCodium iterates on public and AI-generated tests. [...] In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the perfor-mances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeCon-tests, which includes competitive programming problems from platforms such as Codeforces. The proposed flow con-sistently and significantly improves results. On the valida-tion set, for example, GPT-4 accuracy\\nThe content of this paper is\"Improving the Code Generation Capability ofLLMs by a Technique Called AlphaCodium.\\n\\nThe key points of this study are as follows\\n\\n Challenge: Existing optimization methods for natural language cannot stretch LLM code generation capabilities\\n Solution: Optimization using AlphaCodium, a \"test-driven, multi-step code generation flow.\\n Point: AlphaCodium could improve GPT-4\\'s ability to generate code. [...] In other words, AlphaCodium, a unique code generation method, was able to improve LLM\\'s performance in the programming area.\\n\\nIncidentally, AlphaCodium has succeeded in significantly improving code generation performance by using generic language models (GPT, DeepSeek, etc.) without additional training and applying dedicated flows.\\n\\nThis is a method that can be applied to a wide variety of language models without requiring additional data or a computationally expensive training phase. [...] 1. AI extracts goals, inputs, outputs, rules, constraints, etc. from the problem statement and itemizes them\\n2. Generates multiple candidate answer codes based on understanding of the question text\\n3. Rank the generated answer codes and select the best ones\\n4. Run validation tests on selected answer codes\\n5. Analyze results of validation tests and create additional test cases\\nWhen comparing to AlphaCodium work, we need to take into account that AlphaCodium uses a different generation methodology – fine-tuning an (unknown) model specifically for code problems, generating a very large number of code solutions, clustering them, and submitting K solutions from the top clusters. pass@10@100K, for example, means the 100K (!) solutions were generated and clustered, and 10 solutions were finally chosen and submitted. AlphaCodium used a fine-tuned model, and utilized a [...] In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium – a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems.\\n\\nWe tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. The proposed flow consistently and significantly improves results. [...] | Stage name | Task |\\n| Problem Reflection | Describe the problem, in bullet points, while addressing the problem goal, inputs, outputs, rules, constraints, and other relevant details. |\\n| Public Tests Reasoning | Explain why each test input leads to the output. |\\n| Generate Possible Solutions | Generate a list of 2-3 possible solutions to the problem, described in natural language. |\\nIn the task of code generation, I believe there are a few first principles that can improve the quality of the generated code:\\n\\nThe AlphaCodium approach incorporates several techniques to implement these principles, although they are not explicitly mentioned:\\n\\nThey propose the use of problem reflection prompts to create a list of well-defined problem specifications, resulting in a better representation and understanding of the problem. [...] This paper highlights the fact that English (prompting) can be considered a higher-level programming language. The proposed workflow essentially presents an effective algorithm for leveraging large language models. [...] With improved specifications, natural language solution candidates, and enhanced testing, they proceed to the final code generation iteration.\\n\\nThe experiments conducted in the paper yield very convincing results. Using the proposed workflow, GPT-4 achieves a 44% pass@5 score for the validation set of the challenging CodeContests dataset, compared to a baseline of 19%.')],\n",
            "  'question': 'Summary of the AlphaCodium paper methodology'}\n",
            "'\\n---\\n'\n",
            "---GENERATE---\n",
            "\"Node 'generate':\"\n",
            "{ 'documents': [ Document(metadata={}, page_content='## Unlocking the Potential\\n\\nAlphaCodium’s unique methodology comprises two main phases: pre-processing and code iterations. In the pre-processing phase, the tool analyzes the problem, generates potential solutions, and ranks them based on complexity and robustness. The subsequent code iteration phase involves running on AI-generated test cases, iteratively fixing errors until a flawless solution emerges. The result is 12-15% higher accuracy with a significantly reduced computational budget. [...] In the rapidly evolving landscape of artificial intelligence, CodiumAI has unveiled AlphaCodium, an open-source AI code-generation tool that challenges the status quo. This revolutionary approach, showcased in a recent arXiv paper, introduces a flow engineering method to enhance code generation accuracy by up to 44%. Let’s delve into the intricacies of AlphaCodium and its potential impact on the field.\\n\\nAlso Read: Microsoft’s WaveCoder and CodeOcean Revolutionize Instruction Tuning [...] In a landscape where breakthroughs are often hailed prematurely, AlphaCodium stands out as a genuine advancement in AI code generation. By embracing a flow engineering approach, it goes beyond conventional prompting techniques, addressing the limitations faced by previous models. The significance of self-reflection, additional AI tests, and a meticulous iterative process cannot be overstated.\\nIn this paper, we present AlphaCodium, a code-oriented flow that revolves around an iterative process where we re-peatedly run and fix a generated code against input-output tests. Two key elements for AlphaCodium flow are (a) gen-erating additional data, such as problem reflection and test reasoning, to aid the iterative process, and (b) enrichment of public tests with additional AI-generated tests. The pro-posed flow, which is depicted in Figure 1, is divided into two main phases: a [...] 6. Conclusions In this paper, we introduced AlphaCodium, a code-oriented flow that iteratively runs and fixes a generated code against input-output tests. The flow is divided into two main phases: a pre-processing phase, where AlphaCodium rea-sons about the problem in natural language, and a code iter-ations phase, in which AlphaCodium iterates on public and AI-generated tests. [...] In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium - a test-based, multi-stage, code-oriented iterative flow, that improves the perfor-mances of LLMs on code problems. We tested AlphaCodium on a challenging code generation dataset called CodeCon-tests, which includes competitive programming problems from platforms such as Codeforces. The proposed flow con-sistently and significantly improves results. On the valida-tion set, for example, GPT-4 accuracy\\nThe content of this paper is\"Improving the Code Generation Capability ofLLMs by a Technique Called AlphaCodium.\\n\\nThe key points of this study are as follows\\n\\n Challenge: Existing optimization methods for natural language cannot stretch LLM code generation capabilities\\n Solution: Optimization using AlphaCodium, a \"test-driven, multi-step code generation flow.\\n Point: AlphaCodium could improve GPT-4\\'s ability to generate code. [...] In other words, AlphaCodium, a unique code generation method, was able to improve LLM\\'s performance in the programming area.\\n\\nIncidentally, AlphaCodium has succeeded in significantly improving code generation performance by using generic language models (GPT, DeepSeek, etc.) without additional training and applying dedicated flows.\\n\\nThis is a method that can be applied to a wide variety of language models without requiring additional data or a computationally expensive training phase. [...] 1. AI extracts goals, inputs, outputs, rules, constraints, etc. from the problem statement and itemizes them\\n2. Generates multiple candidate answer codes based on understanding of the question text\\n3. Rank the generated answer codes and select the best ones\\n4. Run validation tests on selected answer codes\\n5. Analyze results of validation tests and create additional test cases\\nWhen comparing to AlphaCodium work, we need to take into account that AlphaCodium uses a different generation methodology – fine-tuning an (unknown) model specifically for code problems, generating a very large number of code solutions, clustering them, and submitting K solutions from the top clusters. pass@10@100K, for example, means the 100K (!) solutions were generated and clustered, and 10 solutions were finally chosen and submitted. AlphaCodium used a fine-tuned model, and utilized a [...] In this work, we propose a new approach to code generation by LLMs, which we call AlphaCodium – a test-based, multi-stage, code-oriented iterative flow, that improves the performances of LLMs on code problems.\\n\\nWe tested AlphaCodium on a challenging code generation dataset called CodeContests, which includes competitive programming problems from platforms such as Codeforces. The proposed flow consistently and significantly improves results. [...] | Stage name | Task |\\n| Problem Reflection | Describe the problem, in bullet points, while addressing the problem goal, inputs, outputs, rules, constraints, and other relevant details. |\\n| Public Tests Reasoning | Explain why each test input leads to the output. |\\n| Generate Possible Solutions | Generate a list of 2-3 possible solutions to the problem, described in natural language. |\\nIn the task of code generation, I believe there are a few first principles that can improve the quality of the generated code:\\n\\nThe AlphaCodium approach incorporates several techniques to implement these principles, although they are not explicitly mentioned:\\n\\nThey propose the use of problem reflection prompts to create a list of well-defined problem specifications, resulting in a better representation and understanding of the problem. [...] This paper highlights the fact that English (prompting) can be considered a higher-level programming language. The proposed workflow essentially presents an effective algorithm for leveraging large language models. [...] With improved specifications, natural language solution candidates, and enhanced testing, they proceed to the final code generation iteration.\\n\\nThe experiments conducted in the paper yield very convincing results. Using the proposed workflow, GPT-4 achieves a 44% pass@5 score for the validation set of the challenging CodeContests dataset, compared to a baseline of 19%.')],\n",
            "  'generation': \"AlphaCodium's methodology is a test-based, iterative flow \"\n",
            "                'designed to improve AI code generation. It consists of two '\n",
            "                'main phases: a pre-processing phase where the AI analyzes the '\n",
            "                'problem and generates potential solutions, and a code '\n",
            "                'iteration phase. In the second phase, the generated code is '\n",
            "                'repeatedly run and fixed against both public and additional '\n",
            "                'AI-generated tests until a correct solution is achieved.',\n",
            "  'question': 'Summary of the AlphaCodium paper methodology'}\n",
            "'\\n---\\n'\n",
            "(\"AlphaCodium's methodology is a test-based, iterative flow designed to \"\n",
            " 'improve AI code generation. It consists of two main phases: a pre-processing '\n",
            " 'phase where the AI analyzes the problem and generates potential solutions, '\n",
            " 'and a code iteration phase. In the second phase, the generated code is '\n",
            " 'repeatedly run and fixed against both public and additional AI-generated '\n",
            " 'tests until a correct solution is achieved.')\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\"question\": \"How does the AlphaCodium paper work?\"}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        pprint(value, indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value[\"generation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e44593-1959-4abf-8405-5e23aa9398f5",
      "metadata": {
        "id": "a7e44593-1959-4abf-8405-5e23aa9398f5"
      },
      "source": [
        "trace: https://smith.langchain.com/public/f27b0ad2-cd69-4e5a-8147-e40431edab77/r"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}