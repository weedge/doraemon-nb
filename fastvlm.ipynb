{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMzLsK/SzJUXnPXL6xDcuug",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/fastvlm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRXjvhEJ4QwW",
        "outputId": "86e70f03-6429-4f18-fe6e-0215a23b81f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ml-fastvlm'...\n",
            "remote: Enumerating objects: 115, done.\u001b[K\n",
            "remote: Counting objects: 100% (115/115), done.\u001b[K\n",
            "remote: Compressing objects: 100% (98/98), done.\u001b[K\n",
            "remote: Total 115 (delta 9), reused 115 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (115/115), 10.71 MiB | 9.52 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/weedge/ml-fastvlm.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ml-fastvlm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU6C9ILL4cfI",
        "outputId": "24036b2f-704e-48b9-decd-c80df63083a8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ml-fastvlm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xisA-rIp4otW",
        "outputId": "60e4b765-a985-439b-8943-7560da7c9754"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/ml-fastvlm\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision==0.21.0 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (0.21.0+cu124)\n",
            "Collecting transformers==4.48.3 (from llava==1.2.2.post1)\n",
            "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.21.0 (from llava==1.2.2.post1)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting sentencepiece==0.1.99 (from llava==1.2.2.post1)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting shortuuid (from llava==1.2.2.post1)\n",
            "  Downloading shortuuid-1.0.13-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: accelerate==1.6.0 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (1.6.0)\n",
            "Collecting peft<0.14.0,>=0.10.0 (from llava==1.2.2.post1)\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting bitsandbytes (from llava==1.2.2.post1)\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.11.4)\n",
            "Collecting markdown2[all] (from llava==1.2.2.post1)\n",
            "  Downloading markdown2-2.5.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting numpy==1.26.4 (from llava==1.2.2.post1)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.2.2 (from llava==1.2.2.post1)\n",
            "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting gradio==5.11.0 (from llava==1.2.2.post1)\n",
            "  Downloading gradio-5.11.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (2.32.3)\n",
            "Collecting uvicorn (from llava==1.2.2.post1)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting fastapi (from llava==1.2.2.post1)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting einops==0.6.1 (from llava==1.2.2.post1)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting einops-exts==0.0.4 (from llava==1.2.2.post1)\n",
            "  Downloading einops_exts-0.0.4-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: timm==1.0.15 in /usr/local/lib/python3.11/dist-packages (from llava==1.2.2.post1) (1.0.15)\n",
            "Collecting coremltools==8.2 (from llava==1.2.2.post1)\n",
            "  Downloading coremltools-8.2-cp311-none-manylinux1_x86_64.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->llava==1.2.2.post1) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->llava==1.2.2.post1) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->llava==1.2.2.post1) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->llava==1.2.2.post1) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate==1.6.0->llava==1.2.2.post1) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from coremltools==8.2->llava==1.2.2.post1) (5.29.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from coremltools==8.2->llava==1.2.2.post1) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from coremltools==8.2->llava==1.2.2.post1) (4.67.1)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from coremltools==8.2->llava==1.2.2.post1) (25.3.0)\n",
            "Collecting cattrs (from coremltools==8.2->llava==1.2.2.post1)\n",
            "  Downloading cattrs-24.1.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pyaml (from coremltools==8.2->llava==1.2.2.post1)\n",
            "  Downloading pyaml-25.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (4.9.0)\n",
            "Collecting ffmpy (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.5.3 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading gradio_client-1.5.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (0.28.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (3.1.6)\n",
            "Collecting markupsafe~=2.0 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (3.10.18)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (11.2.1)\n",
            "Collecting pydub (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio==5.11.0->llava==1.2.2.post1) (4.13.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2->llava==1.2.2.post1) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->llava==1.2.2.post1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.6.0->llava==1.2.2.post1) (3.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.48.3->llava==1.2.2.post1) (2024.11.6)\n",
            "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.3->gradio==5.11.0->llava==1.2.2.post1)\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->coremltools==8.2->llava==1.2.2.post1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->llava==1.2.2.post1) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llava==1.2.2.post1) (8.2.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn->llava==1.2.2.post1) (0.16.0)\n",
            "Requirement already satisfied: pygments>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from markdown2[all]->llava==1.2.2.post1) (2.19.1)\n",
            "Collecting wavedrom (from markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting latex2mathml (from markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading latex2mathml-3.78.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->llava==1.2.2.post1) (2025.4.26)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio==5.11.0->llava==1.2.2.post1) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio==5.11.0->llava==1.2.2.post1) (1.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.11.0->llava==1.2.2.post1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.11.0->llava==1.2.2.post1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio==5.11.0->llava==1.2.2.post1) (2025.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.11.0->llava==1.2.2.post1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio==5.11.0->llava==1.2.2.post1) (13.9.4)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->llava==1.2.2.post1)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from wavedrom->markdown2[all]->llava==1.2.2.post1) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio==5.11.0->llava==1.2.2.post1) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio==5.11.0->llava==1.2.2.post1) (0.1.2)\n",
            "Downloading coremltools-8.2-cp311-none-manylinux1_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n",
            "Downloading gradio-5.11.0-py3-none-any.whl (57.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m135.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.5.3-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shortuuid-1.0.13-py3-none-any.whl (10 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.10-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading cattrs-24.1.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading latex2mathml-3.78.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdown2-2.5.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.1.0-py3-none-any.whl (26 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llava, wavedrom\n",
            "  Building editable for llava (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llava: filename=llava-1.2.2.post1-0.editable-py3-none-any.whl size=9422 sha256=910d0399c2feb41757d300215144b8ad552481f8329be1e394c7c4ded30b2a42\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8vsj3dc4/wheels/e5/79/77/7934543773c4235ecb68e5fd8d5f25f44920872658222049f4\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30084 sha256=307a6d7797cd99b7189fc8e8d161a4865687422221ef8d4e30d43afffc2b18be\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/3b/4dcf6b22fa41c5ece715fa5f4e05afd683e7b0ce0f2fcc7bb6\n",
            "Successfully built llava wavedrom\n",
            "Installing collected packages: sentencepiece, pydub, websockets, uvicorn, tomlkit, svgwrite, shortuuid, semantic-version, ruff, python-multipart, pyaml, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, markupsafe, markdown2, latex2mathml, ffmpy, einops, cattrs, aiofiles, wavedrom, starlette, nvidia-cusparse-cu12, nvidia-cudnn-cu12, einops-exts, coremltools, tokenizers, scikit-learn, safehttpx, nvidia-cusolver-cu12, gradio-client, fastapi, transformers, gradio, bitsandbytes, peft, llava\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.1\n",
            "    Uninstalling einops-0.8.1:\n",
            "      Successfully uninstalled einops-0.8.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.51.3\n",
            "    Uninstalling transformers-4.51.3:\n",
            "      Successfully uninstalled transformers-4.51.3\n",
            "  Attempting uninstall: peft\n",
            "    Found existing installation: peft 0.15.2\n",
            "    Uninstalling peft-0.15.2:\n",
            "      Successfully uninstalled peft-0.15.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\n",
            "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 bitsandbytes-0.45.5 cattrs-24.1.3 coremltools-8.2 einops-0.6.1 einops-exts-0.0.4 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.11.0 gradio-client-1.5.3 latex2mathml-3.78.0 llava-1.2.2.post1 markdown2-2.5.3 markupsafe-2.1.5 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.13.2 pyaml-25.1.0 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.10 safehttpx-0.1.6 scikit-learn-1.2.2 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.13 starlette-0.46.2 svgwrite-1.4.3 tokenizers-0.21.0 tomlkit-0.13.2 transformers-4.48.3 uvicorn-0.34.2 wavedrom-2.0.3.post3 websockets-14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# download"
      ],
      "metadata": {
        "id": "ooOli_WP4fMn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!bash get_models.sh   # Files will be downloaded to `checkpoints` directory."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aCdr1jn4gsv",
        "outputId": "0cc5c0d9-5c34-499a-cb63-9d36fa21ec46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-19 11:12:26--  https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage2.zip\n",
            "Resolving ml-site.cdn-apple.com (ml-site.cdn-apple.com)... 17.253.61.203, 17.253.61.205, 2403:300:a26:f100::202, ...\n",
            "Connecting to ml-site.cdn-apple.com (ml-site.cdn-apple.com)|17.253.61.203|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1208014182 (1.1G) [application/zip]\n",
            "Saving to: ‘checkpoints/llava-fastvithd_0.5b_stage2.zip’\n",
            "\n",
            "llava-fastvithd_0.5 100%[===================>]   1.12G  27.7MB/s    in 46s     \n",
            "\n",
            "2025-05-19 11:13:12 (25.3 MB/s) - ‘checkpoints/llava-fastvithd_0.5b_stage2.zip’ saved [1208014182/1208014182]\n",
            "\n",
            "--2025-05-19 11:13:12--  https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_0.5b_stage3.zip\n",
            "Resolving ml-site.cdn-apple.com (ml-site.cdn-apple.com)... 17.253.61.204, 17.253.61.202, 2403:300:a32:f100::2, ...\n",
            "Connecting to ml-site.cdn-apple.com (ml-site.cdn-apple.com)|17.253.61.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1209139702 (1.1G) [application/zip]\n",
            "Saving to: ‘checkpoints/llava-fastvithd_0.5b_stage3.zip’\n",
            "\n",
            "llava-fastvithd_0.5 100%[===================>]   1.13G  24.6MB/s    in 49s     \n",
            "\n",
            "2025-05-19 11:14:02 (23.7 MB/s) - ‘checkpoints/llava-fastvithd_0.5b_stage3.zip’ saved [1209139702/1209139702]\n",
            "\n",
            "--2025-05-19 11:14:02--  https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage2.zip\n",
            "Resolving ml-site.cdn-apple.com (ml-site.cdn-apple.com)... 17.253.118.201, 17.253.118.202, 2403:300:a26:f000::203, ...\n",
            "Connecting to ml-site.cdn-apple.com (ml-site.cdn-apple.com)|17.253.118.201|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3037845687 (2.8G) [application/zip]\n",
            "Saving to: ‘checkpoints/llava-fastvithd_1.5b_stage2.zip’\n",
            "\n",
            "llava-fastvithd_1.5 100%[===================>]   2.83G  27.1MB/s    in 1m 54s  \n",
            "\n",
            "2025-05-19 11:15:57 (25.4 MB/s) - ‘checkpoints/llava-fastvithd_1.5b_stage2.zip’ saved [3037845687/3037845687]\n",
            "\n",
            "--2025-05-19 11:15:57--  https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_1.5b_stage3.zip\n",
            "Resolving ml-site.cdn-apple.com (ml-site.cdn-apple.com)... 17.253.118.202, 17.253.118.201, 2403:300:a26:f000::205, ...\n",
            "Connecting to ml-site.cdn-apple.com (ml-site.cdn-apple.com)|17.253.118.202|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3039793220 (2.8G) [application/zip]\n",
            "Saving to: ‘checkpoints/llava-fastvithd_1.5b_stage3.zip’\n",
            "\n",
            "llava-fastvithd_1.5 100%[===================>]   2.83G  20.8MB/s    in 2m 19s  \n",
            "\n",
            "2025-05-19 11:18:16 (20.9 MB/s) - ‘checkpoints/llava-fastvithd_1.5b_stage3.zip’ saved [3039793220/3039793220]\n",
            "\n",
            "--2025-05-19 11:18:16--  https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage2.zip\n",
            "Resolving ml-site.cdn-apple.com (ml-site.cdn-apple.com)... 17.253.118.202, 17.253.118.201, 2403:300:a26:f000::203, ...\n",
            "Connecting to ml-site.cdn-apple.com (ml-site.cdn-apple.com)|17.253.118.202|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12332499002 (11G) [application/zip]\n",
            "Saving to: ‘checkpoints/llava-fastvithd_7b_stage2.zip’\n",
            "\n",
            "llava-fastvithd_7b_ 100%[===================>]  11.49G  22.2MB/s    in 9m 51s  \n",
            "\n",
            "2025-05-19 11:28:07 (19.9 MB/s) - ‘checkpoints/llava-fastvithd_7b_stage2.zip’ saved [12332499002/12332499002]\n",
            "\n",
            "--2025-05-19 11:28:07--  https://ml-site.cdn-apple.com/datasets/fastvlm/llava-fastvithd_7b_stage3.zip\n",
            "Resolving ml-site.cdn-apple.com (ml-site.cdn-apple.com)... 17.253.61.204, 17.253.61.200, 2403:300:a32:f000::1, ...\n",
            "Connecting to ml-site.cdn-apple.com (ml-site.cdn-apple.com)|17.253.61.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12335914909 (11G) [application/zip]\n",
            "Saving to: ‘checkpoints/llava-fastvithd_7b_stage3.zip’\n",
            "\n",
            "llava-fastvithd_7b_ 100%[===================>]  11.49G  22.8MB/s    in 8m 11s  \n",
            "\n",
            "2025-05-19 11:36:19 (24.0 MB/s) - ‘checkpoints/llava-fastvithd_7b_stage3.zip’ saved [12335914909/12335914909]\n",
            "\n",
            "/content/ml-fastvlm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# predict"
      ],
      "metadata": {
        "id": "UDytgF-HAQzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --model-path /content/ml-fastvlm/checkpoints/llava-fastvithd_0.5b_stage2/ \\\n",
        "                  --image-file /content/ml-fastvlm/docs/acc_vs_latency_qwen-2.png \\\n",
        "                  --prompt \"请用中文详细描述图片内容\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8-8vkyXAGfl",
        "outputId": "62e1671e-f182-40c4-ecb1-71cdeae3b6b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 12:04:23.436934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-19 12:04:23.460004: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747656263.484409   17021 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747656263.492011   17021 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 12:04:23.518723: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "这个图表显示了不同模型在时间到第一个token（ms）的平均VLAM（Visual Question Answering Model）评估指标的随时间变化。以下是该图表的详细内容：\n",
            "\n",
            "- **X-Axis**: Time To First Token (ms)\n",
            "  - **Data Points**: There are five data points plotted on the X-axis, each representing a different model. The models are labeled as follows:\n",
            "    - **FastViT (ours)**: A blue line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **ViT-L/14**: A red line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **SigLIP-SO400M**: A purple line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **ConvNeXt-XXL**: A green line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **ConvNeXt-L**: A blue line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "\n",
            "- **Y-Axis**: Average VLAM (%\n",
            "  - **Data Points**: There are five data points plotted on the Y-axis, each representing a different model. The models are labeled as follows:\n",
            "    - **FastViT (ours)**: A blue line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **ViT-L/14**: A red line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **SigLIP-SO400M**: A purple line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **ConvNeXt-XXL**: A green line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "    - **ConvNeXt-L**: A blue line with a dashed line indicating a 3.2x increase in the average VLAM.\n",
            "\n",
            "- **Title**: The title of the chart is \"Average VLAM (Visual Question Answering Model) Evaluation\".\n",
            "\n",
            "- **Legend**: The legend is located at the bottom right of the chart, indicating the colors of the data points.\n",
            "\n",
            "- **Grid**: The chart uses a grid to help visualize the data points and their corresponding values.\n",
            "\n",
            "- **Trend**: The chart shows that all models show an increase in average VLAM as the time to first token increases. The trend is consistent across all models, with the exception of the \"SigLIP-SO400M\" model, which shows a more significant increase in the average VLAM compared to the other models.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --model-path /content/ml-fastvlm/checkpoints/llava-fastvithd_0.5b_stage3/ \\\n",
        "                  --image-file /content/ml-fastvlm/docs/acc_vs_latency_qwen-2.png \\\n",
        "                  --prompt \"请用中文详细描述图片内容\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEnnNRQTFe0i",
        "outputId": "1d0133de-0ba3-49c2-8d29-20cbd49fca2a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 12:05:03.195858: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-19 12:05:03.218872: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747656303.241963   17233 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747656303.249072   17233 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 12:05:03.274819: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "该图表显示了在不同时间间隔内，各种模型在预测的平均5-10秒平均值VLM（预测值预测值）性能的进展。该图表包括以下内容：\n",
            "\n",
            "1. **图表标题**：该图表的标题为“预测的平均5-10秒平均值VLM（预测值预测值）性能的进展”，表明该图表旨在展示模型在预测时间间隔内性能的进展。\n",
            "\n",
            "2. **x轴**：时间间隔，从0ms到800ms不等长度，代表从初始时间到模型运行后的时间间隔。\n",
            "\n",
            "3. **y轴**：预测的平均5-10秒平均值VLM（预测值预测值），单位为百分比。\n",
            "\n",
            "4. **数据点**：该图表包含四个数据点，每个数据点代表不同的模型和时间间隔。数据点的形状和颜色编码可能表示不同的模型或时间间隔。\n",
            "\n",
            "5. **模型**：\n",
            "   - **FastViTTHD（ours）**：蓝色圆点，表示一个模型，其性能在时间间隔内逐渐增加。\n",
            "   - **ViT-L/14**：红色点，表示一个模型，其性能在时间间隔内逐渐增加。\n",
            "   - **SigLIP-SO400M**：紫色点，表示一个模型，其性能在时间间隔内逐渐增加。\n",
            "   - **ConvNeXt-L**：绿色点，表示一个模型，其性能在时间间隔内逐渐增加。\n",
            "\n",
            "6. **时间间隔**：x轴上的时间间隔从0ms到800ms不等长度，每个间隔代表一个时间间隔，从初始时间开始。\n",
            "\n",
            "7. **数据点**：每个数据点与时间间隔相关联，每个数据点代表一个模型在时间间隔内预测的平均5-10秒平均值VLM（预测值预测值）。\n",
            "\n",
            "8. **注释**：图表右上角有一个注释，表示“3.2×”，可能表示模型在时间间隔内预测的平均5-10秒平均值VLM（预测值预测值）的方差或误差。\n",
            "\n",
            "9. **数据点**：每个数据点的形状和颜色编码可能表示不同的模型或时间间隔。\n",
            "\n",
            "10. **图表背景**：背景是网格，用于在图表中清晰地看到数据点和时间间隔。\n",
            "\n",
            "这个图表旨在视觉上展示模型在不同时间间隔内预测的平均5-10秒平均值VLM（预测值预测值）性能的进展，帮助评估模型在预测时间间隔内的性能。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --model-path /content/ml-fastvlm/checkpoints/llava-fastvithd_1.5b_stage2/ \\\n",
        "                  --image-file /content/ml-fastvlm/docs/acc_vs_latency_qwen-2.png \\\n",
        "                  --prompt \"请用中文详细描述图片内容\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QS1KxeXoFmsp",
        "outputId": "911f5526-f09c-49be-9b09-c57e12453edb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 12:05:42.365900: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-19 12:05:42.388043: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747656342.410860   17445 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747656342.417850   17445 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 12:05:42.443889: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "### Image Description\n",
            "\n",
            "The image is a graph that compares the average VLM (Vision-Language Model) evaluation scores against the time to the first token for various models. The graph is plotted on a logarithmic scale for both the x-axis (Time To First Token (ms)) and the y-axis (Avg VLM Evals %). \n",
            "\n",
            "#### Axes and Labels\n",
            "- **X-axis (Time To First Token (ms))**: The x-axis is labeled \"Time To First Token (ms)\" and is plotted on a logarithmic scale ranging from 0 to 800 milliseconds.\n",
            "- **Y-axis (Avg VLM Evals %)**: The y-axis is labeled \"Avg VLM Evals %\" and is also plotted on a logarithmic scale ranging from 48% to 56%.\n",
            "\n",
            "#### Data Points and Legends\n",
            "- **FastViTHD (ours)**: Represented by a blue line with a circle marker, this model has an average evaluation score of approximately 51.22% and a time to the first token of around 256 milliseconds.\n",
            "- **ViT-L/14**: Represented by a red line with a square marker, this model has an average evaluation score of approximately 51.22% and a time to the first token of around 256 milliseconds.\n",
            "- **SigLIP-SO400M**: Represented by a brown line with a circle marker, this model has an average evaluation score of approximately 51.22% and a time to the first token of around 256 milliseconds.\n",
            "- **ConvNeXt-XXL**: Represented by a green line with a circle marker, this model has an average evaluation score of approximately 51.22% and a time to the first token of around 256 milliseconds.\n",
            "- **ConvNeXt-L**: Represented by a purple line with a circle marker, this model has an average evaluation score of approximately 51.22% and a time to the first token of around 256 milliseconds.\n",
            "\n",
            "#### Lines and Legends\n",
            "- The graph includes dashed lines indicating the average evaluation scores for each model.\n",
            "- The legend on the right side of the graph lists the models with their corresponding line styles and marker shapes.\n",
            "\n",
            "#### Data Points\n",
            "- FastViTHD (ours) has the highest average evaluation score and the shortest time to the first token.\n",
            "- ViT-L/14 has the second highest average evaluation score and the shortest time to the first token.\n",
            "- SigLIP-SO400M and ConvNeXt-XXL have the lowest average evaluation scores and the longest time to the first token.\n",
            "- ConvNeXt-L has the highest average evaluation score and the shortest time to the first token.\n",
            "\n",
            "### Analysis\n",
            "The graph shows that FastViTHD (ours) and ViT-L/14 have the best performance in terms of both average evaluation scores and time to the first token. FastViTHD significantly outperforms the other models, while ViT-L/14 and SigLIP-SO400M are close in performance. ConvNeXt-XXL and ConvNeXt-L show the lowest performance, with FastViTHD and ViT-L/14 being the closest competitors.\n",
            "\n",
            "### Conclusion\n",
            "This graph effectively compares the performance of different Vision-Language Models (VLMs) in terms of average evaluation scores and the time it takes to reach the first token. FastViTHD (ours) and ViT-L/14 are the top performers, while the other models show varying degrees of performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --model-path /content/ml-fastvlm/checkpoints/llava-fastvithd_1.5b_stage3/ \\\n",
        "                  --image-file /content/ml-fastvlm/docs/acc_vs_latency_qwen-2.png \\\n",
        "                  --prompt \"请用中文详细描述图片内容\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ht7hxcwFsVM",
        "outputId": "b51f3d91-948c-4119-d351-d69ac46d78bf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 12:06:46.218218: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-19 12:06:46.240829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747656406.264560   17767 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747656406.271824   17767 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 12:06:46.298789: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "这幅图片是一幅散点图，显示了不同深度学习模型在训练时间与平均VLM（视频语言模型）评估得分之间的关系。该图的x轴代表训练时间（以毫秒为单位），y轴代表平均VLM评估得分。数据点用不同的颜色和形状表示，每种颜色和形状代表不同的模型。图中还有一条绿色线，表示一个拟合的曲线，可能是模型性能的预测线。该图的标题为“VLM评估与训练时间的关系”，并附有“FastViTHD (ours)”的标签，表明这是所呈现模型的名称。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --model-path /content/ml-fastvlm/checkpoints/llava-fastvithd_7b_stage2/ \\\n",
        "                  --image-file /content/ml-fastvlm/docs/acc_vs_latency_qwen-2.png \\\n",
        "                  --prompt \"请用中文详细描述图片内容\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooyxqBgpFvB9",
        "outputId": "d39140f4-5696-4045-b824-f35f800a0a76"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 12:07:28.945523: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-19 12:07:28.963604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747656448.986523   17993 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747656448.993380   17993 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 12:07:29.015627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 4/4 [01:32<00:00, 23.05s/it]\n",
            "### 图表描述\n",
            "\n",
            "#### 图表类型\n",
            "- **图表类型**：折线图\n",
            "- **标题**：没有明确标题，但图表显示了不同模型在“Time To First Token (ms)”和“Avg-VLM Eval (%)”两个指标上的表现。\n",
            "\n",
            "#### 轴\n",
            "- **x轴**：表示“Time To First Token (ms)”（时间单位：毫秒）\n",
            "- **y轴**：表示“Avg-VLM Eval (%)”（平均VLM评估百分比）\n",
            "\n",
            "#### 数据点\n",
            "- **数据点**：不同模型的评估结果，每个模型用不同的颜色和形状表示。\n",
            "  - **FastViTHD（ours）**：用蓝色圆点表示，有多个数据点。\n",
            "  - **ViT-L/14**：用红色圆点表示。\n",
            "  - **SigLIP-SO400M**：用绿色圆点表示。\n",
            "  - **ConvNeXt-XXL**：用紫色圆点表示。\n",
            "  - **ConvNeXt-L**：用绿色圆点表示。\n",
            "\n",
            "#### 数据点位置\n",
            "- **FastViTHD（ours）**：在x轴上从0到200 ms，y轴上从48%到56%。\n",
            "- **ViT-L/14**：在x轴上从200 ms到600 ms，y轴上从48%到52%。\n",
            "- **SigLIP-SO400M**：在x轴上从600 ms到800 ms，y轴上从48%到52%。\n",
            "- **ConvNeXt-XXL**：在x轴上从0 ms到200 ms，y轴上从48%到52%。\n",
            "- **ConvNeXt-L**：在x轴上从0 ms到200 ms，y轴上从48%到52%。\n",
            "\n",
            "#### 趋势\n",
            "- **FastViTHD（ours）**：随着时间增加，性能提升，从48%到56%。\n",
            "- **ViT-L/14**：性能随时间增加，从48%到52%。\n",
            "- **SigLIP-SO400M**：性能随时间增加，从48%到52%。\n",
            "- **ConvNeXt-XXL**：性能随时间增加，从48%到52%。\n",
            "- **ConvNeXt-L**：性能随时间增加，从48%到52%。\n",
            "\n",
            "#### 其他\n",
            "- **时间轴**：从0 ms到800 ms。\n",
            "- **性能百分比**：从48%到56%。\n",
            "\n",
            "#### 结论\n",
            "- **FastViTHD（ours）**在所有时间点上都表现最好，性能随时间提升。\n",
            "- **ViT-L/14**、**SigLIP-SO400M**、**ConvNeXt-XXL**和**ConvNeXt-L**在不同时间点上的性能也有所提升，但没有FastViTHD（ours）那么显著。\n",
            "\n",
            "#### 问题分析\n",
            "- **FastViTHD（ours）**可能采用了更有效的模型架构或优化策略，导致了更好的性能提升。\n",
            "- **ViT-L/14**、**SigLIP-SO400M**、**ConvNeXt-XXL**和**ConvNeXt-L**在不同时间点上的性能提升幅度较小，可能需要进一步优化。\n",
            "\n",
            "#### 结论\n",
            "FastViTHD（ours）在时间和性能上表现最佳，但所有模型在不同时间点上都表现出一定的提升趋势。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python predict.py --model-path /content/ml-fastvlm/checkpoints/llava-fastvithd_7b_stage3/ \\\n",
        "                  --image-file /content/ml-fastvlm/docs/acc_vs_latency_qwen-2.png \\\n",
        "                  --prompt \"请用中文详细描述图片内容\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZtNyExvFyxU",
        "outputId": "4b62b28a-c46c-41e6-cd09-1a9b99838714"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-19 12:10:05.772434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-05-19 12:10:05.794443: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747656605.817341   18706 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747656605.824272   18706 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-19 12:10:05.850423: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Loading checkpoint shards: 100% 4/4 [01:32<00:00, 23.02s/it]\n",
            "图片是一个散点图，展示了各种模型在处理任务时的性能，以平均5.1到5.2的VLM（视觉语言模型）评估百分比为衡量标准。x轴代表“首次词前时间（ms）”，y轴代表“平均5.1到5.2VLM评估百分比”。每个点代表一个模型，其大小可能表示其复杂度或计算资源需求。较大的点可能表示更复杂的模型或需要更多资源。颜色编码可能表示不同的模型类型或类别。\n"
          ]
        }
      ]
    }
  ]
}