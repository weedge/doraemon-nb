{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "collapsed_sections": [
        "XxJljfKl6ZNB",
        "R2JgOqg8ZfvO",
        "pSW6DPhb9wG3"
      ],
      "authorship_tag": "ABX9TyNlVPUFIrt4sGpnFi0wzfFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/achatbot_vita_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# install"
      ],
      "metadata": {
        "id": "Gf2QRIf-CHpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && rm -rf achatbot && git clone https://github.com/ai-bot-pro/achatbot.git -b feat/voice"
      ],
      "metadata": {
        "id": "KgWkCIBAxn-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFvgRFMqRjlY"
      },
      "outputs": [],
      "source": [
        "%cd /content/achatbot"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "x389A5GV4Vp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout . && git pull origin feat/voice"
      ],
      "metadata": {
        "id": "j5EArg-caWY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEpbiR_SRnwl"
      },
      "outputs": [],
      "source": [
        "!bash scripts/pypi_achatbot.sh dev"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.10-py3-none-any.whl[llm_transformers_manual_voice_vita]\""
      ],
      "metadata": {
        "id": "9AVHWLtY4pdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U flash-attn --no-build-isolation"
      ],
      "metadata": {
        "id": "CsdGf0-W2-U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK8tWbDguJck"
      },
      "source": [
        "# download"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download FunAudioLLM/SenseVoiceSmall --quiet --local-dir /content/models/FunAudioLLM/SenseVoiceSmall\n"
      ],
      "metadata": {
        "id": "IoKxtNoA4y2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download THUDM/glm-4-voice-tokenizer --quiet --local-dir /content/models/THUDM/glm-4-voice-tokenizer"
      ],
      "metadata": {
        "id": "Guh6FwAufdUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download THUDM/glm-4-voice-decoder --quiet --local-dir /content/models/THUDM/glm-4-voice-decoder"
      ],
      "metadata": {
        "id": "Sj9sugTPfeeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download VITA-MLLM/VITA-Audio-Boost --quiet --local-dir /content/models/VITA-MLLM/VITA-Audio-Boost"
      ],
      "metadata": {
        "id": "_F6EAbqpfRyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4QJvMXAfrGK"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli download VITA-MLLM/VITA-Audio-Balance --quiet --local-dir /content/models/VITA-MLLM/VITA-Audio-Balance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download VITA-MLLM/VITA-Audio-Plus-Vanilla --quiet --local-dir /content/models/VITA-MLLM/VITA-Audio-Plus-Vanilla"
      ],
      "metadata": {
        "id": "MLj2WWFkfRP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# asr test"
      ],
      "metadata": {
        "id": "XxJljfKl6ZNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot"
      ],
      "metadata": {
        "id": "ZI8OtLdx6cLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/achatbot/test/audio_files/asr_example_zh.wav\")"
      ],
      "metadata": {
        "id": "3fCejayPGuT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Plus-Vanilla \\\n",
        "    AUDIO_TOKENIZER_TYPE=sensevoice_glm4voice \\\n",
        "    SENSE_VOICE_MODEL_PATH=/content/models/FunAudioLLM/SenseVoiceSmall \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 \\\n",
        "    python -m unittest test.modules.speech.asr.test_vita_asr.TestVITAASR.test_transcribe_stream"
      ],
      "metadata": {
        "id": "xE8I7IYc6kET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Plus-Vanilla \\\n",
        "    AUDIO_TOKENIZER_TYPE=sensevoice_glm4voice \\\n",
        "    SENSE_VOICE_MODEL_PATH=/content/models/FunAudioLLM/SenseVoiceSmall \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 LLM_ATTN_IMP=flash_attention_2 \\\n",
        "    python -m unittest test.modules.speech.asr.test_vita_asr.TestVITAASR.test_transcribe_stream"
      ],
      "metadata": {
        "id": "NCYSFTMRwKB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Balance LLM_WARMUP_STEPS=0 \\\n",
        "    AUDIO_TOKENIZER_TYPE=glm4voice \\\n",
        "    AUDIO_TOKENIZER_MODEL_PATH=/content/models/THUDM/glm-4-voice-tokenizer \\\n",
        "    LLM_DEVICE_MAP=cuda:0 LLM_TORCH_DTYPE=bfloat16 LLM_ATTN_IMP=flash_attention_2 \\\n",
        "    python -m unittest test.modules.speech.asr.test_vita_asr.TestVITAASR.test_transcribe_stream"
      ],
      "metadata": {
        "id": "W0TaURKmwnkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tts test"
      ],
      "metadata": {
        "id": "R2JgOqg8ZfvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/achatbot"
      ],
      "metadata": {
        "id": "DOyL5jLZZlm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Plus-Vanilla \\\n",
        "    AUDIO_TOKENIZER_TYPE=sensevoice_glm4voice \\\n",
        "    FLOW_PATH=/content/models/THUDM/glm-4-voice-decoder \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 LLM_ATTN_IMP=flash_attention_2 \\\n",
        "    python -m unittest test.modules.speech.tts.test_vita.TestVITATTS.test_synthesize"
      ],
      "metadata": {
        "id": "LTDLR_3dZsGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "Audio(\"/content/achatbot/records/test_tts_vita.wav\",autoplay=True)"
      ],
      "metadata": {
        "id": "D0tlb0rAh0qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Balance \\\n",
        "    AUDIO_TOKENIZER_TYPE=glm4voice \\\n",
        "    FLOW_PATH=/content/models/THUDM/glm-4-voice-decoder \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 LLM_ATTN_IMP=flash_attention_2 \\\n",
        "    python -m unittest test.modules.speech.tts.test_vita.TestVITATTS.test_synthesize"
      ],
      "metadata": {
        "id": "ZF6BqulMAYTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## grpc tts"
      ],
      "metadata": {
        "id": "MCg8Amg9AZVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!TTS_TAG=tts_vita IS_SAVE=1 \\\n",
        "    LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Plus-Vanilla \\\n",
        "    AUDIO_TOKENIZER_TYPE=sensevoice_glm4voice \\\n",
        "    FLOW_PATH=/content/models/THUDM/glm-4-voice-decoder \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 LLM_ATTN_IMP=flash_attention_2 \\\n",
        "    python -m src.cmd.grpc.speaker.client"
      ],
      "metadata": {
        "id": "Z3wOOP3mAtLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(\"/content/achatbot/records/grpc_tts_vita_0.wav\")"
      ],
      "metadata": {
        "id": "FevtEW1eABjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(\"/content/achatbot/records/grpc_tts_vita_1.wav\")"
      ],
      "metadata": {
        "id": "cu9vCs9fAGo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(\"/content/achatbot/records/grpc_tts_vita_2.wav\")"
      ],
      "metadata": {
        "id": "rTysvSlSAKTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!TTS_TAG=tts_vita IS_SAVE=1 \\\n",
        "    LLM_MODEL_NAME_OR_PATH=/content/models/VITA-MLLM/VITA-Audio-Balance \\\n",
        "    AUDIO_TOKENIZER_TYPE=glm4voice \\\n",
        "    FLOW_PATH=/content/models/THUDM/glm-4-voice-decoder \\\n",
        "    LLM_DEVICE=cuda LLM_TORCH_DTYPE=bfloat16 LLM_ATTN_IMP=flash_attention_2 \\\n",
        "    python -m src.cmd.grpc.speaker.client"
      ],
      "metadata": {
        "id": "lQsYUcjF3Q9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q \"dist/achatbot-0.0.10-py3-none-any.whl[fastapi_bot_server,daily_room_audio_stream,livekit_room_audio_stream,silero_vad_analyzer,sense_voice_asr,llm_transformers_manual_voice_vita,queue]\"\n"
      ],
      "metadata": {
        "id": "VxnoCiG8myuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers[torch]"
      ],
      "metadata": {
        "id": "ITesWLwY-MKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"torch|transformers\""
      ],
      "metadata": {
        "id": "RFZJgoPK2iXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "DAILY_API_KEY=userdata.get('DAILY_API_KEY')\n",
        "\n",
        "LIVEKIT_URL=userdata.get('LIVEKIT_URL')\n",
        "LIVEKIT_API_KEY=userdata.get('LIVEKIT_API_KEY')\n",
        "LIVEKIT_API_SECRET=userdata.get('LIVEKIT_API_SECRET')"
      ],
      "metadata": {
        "id": "fxnIc7Plnc27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/achatbot\n"
      ],
      "metadata": {
        "id": "WYziEG-lnofg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## voice webrtc chat bot"
      ],
      "metadata": {
        "id": "5ECHDBcumuQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_asr_vita_voice_bot.json\n"
      ],
      "metadata": {
        "id": "8sFq3h0V0QqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!LIVEKIT_URL=$LIVEKIT_URL LIVEKIT_API_KEY=$LIVEKIT_API_KEY LIVEKIT_API_SECRET=$LIVEKIT_API_SECRET \\\n",
        "  python -m src.cmd.bots.main -f /content/livekit_vita_voice_bot.json\n"
      ],
      "metadata": {
        "id": "05HvpTnMnxCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VITA-Audio"
      ],
      "metadata": {
        "id": "pSW6DPhb9wG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && git clone -b feat/achatbot https://github.com/weedge/VITA-Audio.git"
      ],
      "metadata": {
        "id": "uhWsTE998iU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/VITA-Audio/ && pip install -q -r requirements_ds_gpu.txt"
      ],
      "metadata": {
        "id": "Ra-eeT2H8qKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/VITA-Audio && git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "BOTz17XW9Mh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/VITA-Audio/ && git checkout 32fb8180fcd7a4bbaa8c9dd77928c78cb7fd26ce"
      ],
      "metadata": {
        "id": "VB6lYOcQ9V1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from random import random\n",
        "import re\n",
        "from threading import Thread\n",
        "\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, TextIteratorStreamer\n",
        "from transformers.generation import GenerationConfig\n",
        "import torch\n",
        "\n",
        "sys.path.append(\"/content/VITA-Audio\")\n",
        "sys.path.append(\"/content/VITA-Audio/third_party/GLM-4-Voice/\")\n",
        "sys.path.append(\"/content/VITA-Audio/third_party/GLM-4-Voice/cosyvoice/\")\n",
        "sys.path.append(\"/content/VITA-Audio/third_party/GLM-4-Voice/third_party/Matcha-TTS/\")\n",
        "\n",
        "from vita_audio.tokenizer import get_audio_tokenizer\n",
        "from vita_audio.data.processor.audio_processor import add_audio_input_contiguous"
      ],
      "metadata": {
        "id": "_sMyfxRz-IJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "import time\n",
        "\n",
        "class TextAudioIteratorStreamer(TextIteratorStreamer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tokenizer: \"AutoTokenizer\",\n",
        "        skip_prompt: bool = False,\n",
        "        timeout: Optional[float] = None,\n",
        "        **decode_kwargs,\n",
        "    ):\n",
        "        super().__init__(tokenizer, skip_prompt, timeout, **decode_kwargs)\n",
        "\n",
        "        # self.audio_offset = tokenizer.convert_tokens_to_ids(\"<|audio_0|>\")\n",
        "        self.audio_offset = tokenizer.convert_tokens_to_ids(\"<|begin_of_audio|>\")\n",
        "        self.num_decode_tokens = 0\n",
        "\n",
        "    def put(self, value):\n",
        "        \"\"\"\n",
        "        Receives tokens, decodes them, and prints them to stdout as soon as they form entire words.\n",
        "        \"\"\"\n",
        "        if len(value.shape) > 1 and value.shape[0] > 1:\n",
        "            raise ValueError(\"TextStreamer only supports batch size 1\")\n",
        "        elif len(value.shape) > 1:\n",
        "            value = value[0]\n",
        "\n",
        "        if self.skip_prompt and self.next_tokens_are_prompt:\n",
        "            self.next_tokens_are_prompt = False\n",
        "            return\n",
        "\n",
        "        self.num_decode_tokens += len(value)\n",
        "\n",
        "        # Add the new token to the cache and decodes the entire thing.\n",
        "        self.token_cache.extend(value.tolist())\n",
        "        text = self.tokenizer.decode(self.token_cache, **self.decode_kwargs)\n",
        "\n",
        "        # After the symbol for a new line, we flush the cache.\n",
        "        if text.endswith(\"\\n\"):\n",
        "            printable_text = text[self.print_len :]\n",
        "            self.token_cache = []\n",
        "            self.print_len = 0\n",
        "        # If the last token is a CJK character, we print the characters.\n",
        "        elif len(text) > 0 and self._is_chinese_char(ord(text[-1])):\n",
        "            printable_text = text[self.print_len :]\n",
        "            self.print_len += len(printable_text)\n",
        "        elif self.token_cache[-1] >= self.audio_offset:\n",
        "            printable_text = text[self.print_len :]\n",
        "            self.print_len += len(printable_text)\n",
        "        # Otherwise, prints until the last space char (simple heuristic to avoid printing incomplete words,\n",
        "        # which may change with the subsequent token -- there are probably smarter ways to do this!)\n",
        "        else:\n",
        "            printable_text = text[self.print_len : text.rfind(\" \") + 1]\n",
        "            self.print_len += len(printable_text)\n",
        "\n",
        "        self.on_finalized_text(printable_text)\n",
        "\n",
        "        while self.text_queue.qsize() > 10:\n",
        "            time.sleep(0.01)"
      ],
      "metadata": {
        "id": "iZFi9AhmAAvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class S2SInference:\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm_model_path,\n",
        "        audio_tokenizer_type,\n",
        "        audio_tokenizer_model_path=None,\n",
        "        sense_voice_model_path=None,\n",
        "        flow_path=None,\n",
        "        device_map=\"cuda:0\",\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        audio_tokenizer_rank=0,\n",
        "    ):\n",
        "        from evaluation.get_chat_template import qwen2_chat_template as chat_template\n",
        "\n",
        "        add_generation_prompt = True\n",
        "\n",
        "        default_system_message = []\n",
        "\n",
        "        luke_system_message = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"Your Name: Luke\\nYour Gender: male\\n\\nRespond in a text-audio interleaved manner.\",\n",
        "            },\n",
        "        ]\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            llm_model_path,\n",
        "            trust_remote_code=True,\n",
        "            chat_template=chat_template,\n",
        "        )\n",
        "\n",
        "        # https://huggingface.co/VITA-MLLM/VITA-Audio-Boost/blob/main/modeling_qwen2.py#L781\n",
        "        # https://huggingface.co/VITA-MLLM/VITA-Audio-Balance/blob/main/modeling_qwen2.py#L781\n",
        "        # https://huggingface.co/VITA-MLLM/VITA-Audio-Plus-Vanilla/blob/main/modeling_qwen2.py#L834\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            llm_model_path,\n",
        "            trust_remote_code=True,\n",
        "            device_map=device_map,\n",
        "            torch_dtype=torch_dtype,\n",
        "            attn_implementation=\"flash_attention_2\",\n",
        "        ).eval()\n",
        "        # print(\"model\", model)\n",
        "        print(f\"{model.config=}\")\n",
        "        # print(f\"{model.config.model_type=}\")\n",
        "        print(f\"{model.hf_device_map=}\")\n",
        "\n",
        "        model.generation_config = GenerationConfig.from_pretrained(\n",
        "            llm_model_path, trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        model.generation_config.max_new_tokens = 8192\n",
        "        model.generation_config.chat_format = \"chatml\"\n",
        "        model.generation_config.max_window_size = 8192\n",
        "        model.generation_config.use_cache = True\n",
        "        # model.generation_config.use_cache = False\n",
        "        model.generation_config.do_sample = False\n",
        "        model.generation_config.temperature = 1.0\n",
        "        model.generation_config.top_k = 50\n",
        "        model.generation_config.top_p = 1.0\n",
        "        model.generation_config.num_beams = 1\n",
        "        model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "        print(f\"{model.generation_config=}\")\n",
        "\n",
        "        audio_tokenizer = get_audio_tokenizer(\n",
        "            model_type=audio_tokenizer_type,\n",
        "            flow_path=flow_path,\n",
        "            model_name_or_path=audio_tokenizer_model_path,\n",
        "            rank=audio_tokenizer_rank,\n",
        "            sense_voice_model_path=sense_voice_model_path,\n",
        "        )\n",
        "        audio_tokenizer.load_model()\n",
        "\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.audio_tokenizer = audio_tokenizer\n",
        "        self.add_generation_prompt = add_generation_prompt\n",
        "        self.default_system_message = default_system_message\n",
        "        self.luke_system_message = luke_system_message\n",
        "\n",
        "        # audio_0_id = tokenizer(\"<|audio_0|>\").input_ids[0]\n",
        "        # print(f\"{audio_0_id=}\")\n",
        "\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def run_infer_stream(\n",
        "        self,\n",
        "        audio_path=None,\n",
        "        prompt_audio_path=None,\n",
        "        chunk_size=4,\n",
        "        max_returned_tokens=4096,\n",
        "        sample_rate=16000,\n",
        "        request_id=\"\",\n",
        "        audio_feats=None,\n",
        "        message=\"\",\n",
        "        use_past=False,\n",
        "        mode=\"luke\",\n",
        "        do_sample=False,\n",
        "        mtp_inference_mode=None,\n",
        "    ):\n",
        "        if prompt_audio_path is not None:\n",
        "            system_message = [\n",
        "                {\n",
        "                    \"role\": \"system\",\n",
        "                    \"content\": f\"Your Voice: <|audio|>\\n\",\n",
        "                },\n",
        "            ]\n",
        "\n",
        "        elif mode == \"luke\":\n",
        "            system_message = self.luke_system_message\n",
        "\n",
        "        else:\n",
        "            system_message = self.default_system_message\n",
        "\n",
        "        if prompt_audio_path is not None and self.audio_tokenizer.apply_to_role(\n",
        "            \"user\", is_discrete=True\n",
        "        ):\n",
        "            # discrete codec\n",
        "            audio_tokens = self.audio_tokenizer.encode(prompt_audio_path)\n",
        "            audio_tokens = \"\".join(f\"<|audio_{i}|>\" for i in audio_tokens)\n",
        "            system_message[-1][\"content\"] = system_message[-1][\"content\"].replace(\n",
        "                \"<|audio|>\", f\"<|begin_of_audio|>{audio_tokens}<|end_of_audio|>\"\n",
        "            )\n",
        "\n",
        "        if audio_path is not None:\n",
        "            messages = system_message + [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": message + \"\\n<|audio|>\",\n",
        "                },\n",
        "            ]\n",
        "        else:\n",
        "            messages = system_message + [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": message,\n",
        "                },\n",
        "            ]\n",
        "\n",
        "        if audio_path is not None and self.audio_tokenizer.apply_to_role(\"user\", is_discrete=True):\n",
        "            print(\"discrete codec\")\n",
        "            # discrete codec\n",
        "            audio_tokens = self.audio_tokenizer.encode(audio_path)\n",
        "            audio_tokens = \"\".join(f\"<|audio_{i}|>\" for i in audio_tokens)\n",
        "            messages[-1][\"content\"] = messages[-1][\"content\"].replace(\n",
        "                \"<|audio|>\", f\"<|begin_of_audio|>{audio_tokens}<|end_of_audio|>\"\n",
        "            )\n",
        "\n",
        "        input_ids = self.tokenizer.apply_chat_template(\n",
        "            messages,\n",
        "            tokenize=True,\n",
        "            add_generation_prompt=self.add_generation_prompt,\n",
        "        )\n",
        "\n",
        "        if (\n",
        "            audio_path is not None or prompt_audio_path is not None\n",
        "        ) and self.audio_tokenizer.apply_to_role(\"user\", is_contiguous=True):\n",
        "            print(\"contiguous codec\")\n",
        "            # contiguous codec\n",
        "            audio_paths = []\n",
        "            if audio_path is not None:\n",
        "                audio_paths.append(audio_path)\n",
        "            if prompt_audio_path is not None:\n",
        "                audio_paths.append(prompt_audio_path)\n",
        "            input_ids, audios, audio_indices = add_audio_input_contiguous(\n",
        "                input_ids, audio_paths, self.tokenizer, self.audio_tokenizer\n",
        "            )\n",
        "        else:\n",
        "            audios = None\n",
        "            audio_indices = None\n",
        "\n",
        "        input_ids = torch.tensor([input_ids], dtype=torch.long).to(\"cuda\")\n",
        "\n",
        "        print(\"input\", self.tokenizer.decode(input_ids[0], skip_special_tokens=False), flush=True)\n",
        "        attention_mask = torch.ones((1, input_ids.shape[1]), dtype=torch.int64).to(\"cuda\")\n",
        "\n",
        "        self.model.generation_config.do_sample = do_sample\n",
        "\n",
        "        if mtp_inference_mode is not None:\n",
        "            print(f\"{mtp_inference_mode=}\")\n",
        "            ori_mtp_inference_mode = self.model.generation_config.mtp_inference_mode\n",
        "            self.model.generation_config.mtp_inference_mode = mtp_inference_mode\n",
        "\n",
        "        streamer = TextAudioIteratorStreamer(self.tokenizer, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            audios=audios,\n",
        "            audio_indices=audio_indices,\n",
        "            streamer=streamer,\n",
        "        )\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "\n",
        "        thread.start()\n",
        "\n",
        "        # generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            # generated_text += new_text\n",
        "\n",
        "            yield new_text\n",
        "\n",
        "        # torch.cuda.synchronize()\n",
        "\n",
        "        if mtp_inference_mode is not None:\n",
        "            self.model.generation_config.mtp_inference_mode = ori_mtp_inference_mode"
      ],
      "metadata": {
        "id": "XTd9On9W9rVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/models/VITA-MLLM/VITA-Audio-Balance\"\n",
        "audio_tokenizer_type = \"glm4voice\"\n",
        "audio_tokenizer_model_path = \"/content/models/THUDM/glm-4-voice-tokenizer\"\n",
        "sense_voice_model_path = \"/content/models/FunAudioLLM/SenseVoiceSmall\""
      ],
      "metadata": {
        "id": "_nmNNTEl_BoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter\n",
        "\n",
        "def asr_text_stream():\n",
        "    s2s_inference = S2SInference(\n",
        "        model_path,\n",
        "        audio_tokenizer_type,\n",
        "        audio_tokenizer_model_path=audio_tokenizer_model_path,\n",
        "        sense_voice_model_path=None,\n",
        "        flow_path=None,\n",
        "    )\n",
        "\n",
        "    for audio_path in [\n",
        "        \"/content/achatbot/test/audio_files/asr_example_zh.wav\",\n",
        "        # \"/VITA-Audio/asset/介绍一下上海.wav\",\n",
        "        # \"/VITA-Audio/asset/发表一个悲伤的演讲.wav\",\n",
        "        # \"/VITA-Audio/asset/发表一个振奋人心的演讲.wav\",\n",
        "    ]:\n",
        "        print(\"=\" * 100)\n",
        "        print(\"asr_text_stream_task\")\n",
        "        print(f\"{audio_path=}\")\n",
        "\n",
        "        times = []\n",
        "        start_time = perf_counter()\n",
        "        generated_text = \"\"\n",
        "        for new_text in s2s_inference.run_infer_stream(\n",
        "            audio_path=audio_path,\n",
        "            # message=\"Translate the speech to text.\",\n",
        "            message=\"Convert the speech to text.\",\n",
        "            mode=None,\n",
        "        ):\n",
        "            times.append(perf_counter() - start_time)\n",
        "            generated_text += new_text\n",
        "            print(new_text, end=\" \", flush=True)\n",
        "            start_time = perf_counter()\n",
        "        print(\n",
        "            f\"\\ngenerate [{generated_text}] first token cost time: {times[0]} s, {len(times)} tokens cost time: {sum(times)} s\\n\"\n",
        "        )"
      ],
      "metadata": {
        "id": "dIOL4XHm-5sR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asr_text_stream()"
      ],
      "metadata": {
        "id": "5N2a7mhp_x0C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}