{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPWUR0aViQsNk7bKWv2bZ7x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/avatar_musetalk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -version\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiM4iac-6xpw",
        "outputId": "e1412535-9204-4b58-b0b0-2e688d2e25aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "libavutil      56. 70.100 / 56. 70.100\n",
            "libavcodec     58.134.100 / 58.134.100\n",
            "libavformat    58. 76.100 / 58. 76.100\n",
            "libavdevice    58. 13.100 / 58. 13.100\n",
            "libavfilter     7.110.100 /  7.110.100\n",
            "libswscale      5.  9.100 /  5.  9.100\n",
            "libswresample   3.  9.100 /  3.  9.100\n",
            "libpostproc    55.  9.100 / 55.  9.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!gcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY9kPR9YMxKx",
        "outputId": "8c469343-215b-4994-ad4c-f68131907fdc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2024 NVIDIA Corporation\n",
            "Built on Thu_Jun__6_02:18:23_PDT_2024\n",
            "Cuda compilation tools, release 12.5, V12.5.82\n",
            "Build cuda_12.5.r12.5/compiler.34385749_0\n",
            "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "Copyright (C) 2021 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBGEeSap28_v",
        "outputId": "d0ddc2bc-ef0c-4acd-ac1a-870f263e5106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MuseTalk'...\n",
            "remote: Enumerating objects: 511, done.\u001b[K\n",
            "remote: Total 511 (delta 0), reused 0 (delta 0), pack-reused 511 (from 1)\u001b[K\n",
            "Receiving objects: 100% (511/511), 25.75 MiB | 40.75 MiB/s, done.\n",
            "Resolving deltas: 100% (192/192), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TMElyralab/MuseTalk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd MuseTalk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZTN5bWg5wZP",
        "outputId": "25675064-ddef-4f3f-cd02-d9bdbbbc0b4e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MuseTalk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "B65jbLQU54SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 accelerate==0.32.0 peft==0.10.0"
      ],
      "metadata": {
        "id": "zBi96Rq39ySM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content && git clone https://github.com/open-mmlab/mmcv.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6JwL3FbNG6J",
        "outputId": "26039db3-8400-4a4c-ad82-17ae845d5eeb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmcv'...\n",
            "remote: Enumerating objects: 17575, done.\u001b[K\n",
            "remote: Counting objects: 100% (464/464), done.\u001b[K\n",
            "remote: Compressing objects: 100% (310/310), done.\u001b[K\n",
            "remote: Total 17575 (delta 336), reused 154 (delta 154), pack-reused 17111 (from 4)\u001b[K\n",
            "Receiving objects: 100% (17575/17575), 14.52 MiB | 31.50 MiB/s, done.\n",
            "Resolving deltas: 100% (12782/12782), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/mmcv && git checkout v2.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh2JvJP6R-Sg",
        "outputId": "1067d405-7a27-4787-bc53-3b72b92d09b6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Note: switching to 'v2.1.0'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 57c4e25e Bump version to 2.1.0 (#2959)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/mmcv && pip install -r requirements/optional.txt\n"
      ],
      "metadata": {
        "id": "NoV7akjFNMpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/mmcv && pip install -e . -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAnl5u6oNb6z",
        "outputId": "126f7a6f-d65d-4cda-f9be-3d23d54d2fa5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [136/136] c++ -MMD -MF /content/mmcv/build/temp.linux-x86_64-cpython-311/mmcv/ops/csrc/pytorch/pybind.o.d -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -DMMCV_WITH_CUDA -I/content/mmcv/mmcv/ops/csrc/pytorch -I/content/mmcv/mmcv/ops/csrc/common -I/content/mmcv/mmcv/ops/csrc/common/cuda -I/usr/local/lib/python3.11/dist-packages/torch/include -I/usr/local/lib/python3.11/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.11/dist-packages/torch/include/TH -I/usr/local/lib/python3.11/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.11 -c -c /content/mmcv/mmcv/ops/csrc/pytorch/pybind.cpp -o /content/mmcv/build/temp.linux-x86_64-cpython-311/mmcv/ops/csrc/pytorch/pybind.o -std=c++17 -DTORCH_API_INCLUDE_EXTENSION_H '-DPYBIND11_COMPILER_TYPE=\"_gcc\"' '-DPYBIND11_STDLIB=\"_libstdcpp\"' '-DPYBIND11_BUILD_ABI=\"_cxxabi1011\"' -DTORCH_EXTENSION_NAME=_ext -D_GLIBCXX_USE_CXX11_ABI=0\n",
            "    creating build/lib.linux-x86_64-cpython-311/mmcv\n",
            "    x86_64-linux-gnu-g++ -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -shared -Wl,-O1 -Wl,-Bsymbolic-functions /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/active_rotated_filter.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/assign_score_withk.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/ball_query.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/bbox_overlaps.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/bezier_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/bias_act.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/border_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/box_iou_quadri.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/box_iou_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/carafe.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/carafe_naive.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/chamfer_distance.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/contour_expand.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/convex_iou.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/correlation.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/active_rotated_filter.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/bbox_overlaps_cpu.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/bezier_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/box_iou_quadri.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/box_iou_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/deform_conv.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/modulated_deform_conv.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/nms.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/nms_quadri.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/nms_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/pixel_group.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/points_in_boxes.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/psamask.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/roi_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/roi_align_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/rotated_feature_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/sparse_indice.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/sparse_maxpool.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/sparse_reordering.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cpu/voxelization.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/active_rotated_filter_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/assign_score_withk_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/ball_query_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/bbox_overlaps_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/bezier_align_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/bias_act_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/border_align_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/box_iou_quadri_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/box_iou_rotated_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/carafe_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/carafe_naive_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/chamfer_distance_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/convex_iou.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/correlation_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/cudabind.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/deform_conv_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/deform_roi_pool_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/diff_iou_rotated_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/filtered_lrelu.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/focal_loss_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/furthest_point_sample_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/fused_bias_leakyrelu_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/fused_spconv_ops_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/gather_points_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/group_points_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/iou3d_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/knn_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/masked_conv2d_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/min_area_polygons.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/modulated_deform_conv_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/ms_deform_attn_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/nms_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/nms_quadri_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/nms_rotated_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/points_in_boxes_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/points_in_polygons_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/prroi_pool_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/psamask_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/riroi_align_rotated_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/roi_align_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/roi_align_rotated_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/roi_pool_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/roiaware_pool3d_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/roipoint_pool3d_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/rotated_feature_align_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/scatter_points_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/sparse_indice.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/sparse_maxpool.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/sparse_pool_ops_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/sparse_reordering.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/spconv_ops_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/stack_ball_query_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/stack_group_points_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/sync_bn_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/three_interpolate_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/three_nn_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/tin_shift_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/upfirdn2d_kernel.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/cuda/voxelization_cuda.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/deform_conv.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/deform_roi_pool.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/diff_iou_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/filtered_lrelu.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/focal_loss.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/furthest_point_sample.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/fused_bias_leakyrelu.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/fused_spconv_ops.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/gather_points.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/group_points.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/info.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/iou3d.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/knn.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/masked_conv2d.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/min_area_polygons.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/modulated_deform_conv.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/ms_deform_attn.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/nms.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/nms_quadri.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/nms_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/pixel_group.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/points_in_boxes.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/points_in_polygons.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/prroi_pool.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/psamask.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/pybind.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/riroi_align_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/roi_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/roi_align_rotated.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/roi_pool.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/roiaware_pool3d.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/roipoint_pool3d.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/rotated_feature_align.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/scatter_points.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/sparse_pool_ops.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/spconv_ops.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/sync_bn.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/three_interpolate.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/three_nn.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/tin_shift.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/upfirdn2d.o /content/mmcv/build/temp.linux-x86_64-cpython-311/./mmcv/ops/csrc/pytorch/voxelization.o -L/usr/local/lib/python3.11/dist-packages/torch/lib -L/usr/local/cuda/lib64 -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-cpython-311/mmcv/_ext.cpython-311-x86_64-linux-gnu.so\n",
            "    copying build/lib.linux-x86_64-cpython-311/mmcv/_ext.cpython-311-x86_64-linux-gnu.so -> mmcv\n",
            "    Creating /usr/local/lib/python3.11/dist-packages/mmcv.egg-link (link to .)\n",
            "    Adding mmcv 2.1.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-2.1.0 mmengine-0.10.7 yapf-0.43.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show mmcv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTBI0dEYPYwC",
        "outputId": "68766a62-f379-4a21-f5f1-f00f0b9e8c79"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: mmcv\n",
            "Version: 2.1.0\n",
            "Summary: OpenMMLab Computer Vision Foundation\n",
            "Home-page: https://github.com/open-mmlab/mmcv\n",
            "Author: MMCV Contributors\n",
            "Author-email: openmmlab@gmail.com\n",
            "License: \n",
            "Location: /content/mmcv\n",
            "Editable project location: /content/mmcv\n",
            "Requires: addict, mmengine, numpy, packaging, Pillow, pyyaml, yapf\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --no-cache-dir -U openmim\n",
        "!mim install mmengine\n",
        "!mim install \"mmdet==3.3.0\"\n",
        "!mim install \"mmpose==1.3.2\"\n"
      ],
      "metadata": {
        "id": "Ou5Dam3L6pvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list | grep -E \"accelerate|peft|torch|mmcv|mmdet|mmpose|numpy\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1swUIJE79tmG",
        "outputId": "831b1b6f-def3-4be6-f39a-a87a0525f547"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate                            0.32.0\n",
            "mmcv                                  2.1.0               /content/mmcv\n",
            "mmdet                                 3.3.0\n",
            "mmpose                                1.3.2\n",
            "numpy                                 1.23.5\n",
            "peft                                  0.10.0\n",
            "torch                                 2.4.1\n",
            "torchao                               0.10.0\n",
            "torchaudio                            2.4.1\n",
            "torchdata                             0.11.0\n",
            "torchsummary                          1.5.1\n",
            "torchtune                             0.6.1\n",
            "torchvision                           0.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MuseTalk 1.0\n",
        "!sh ./download_weights.sh\n"
      ],
      "metadata": {
        "id": "C0mIxExb6t2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MuseTalk 1.0\n",
        "!sh inference.sh v1.0 normal\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2op2YQzc9DwJ",
        "outputId": "b26ce53b-2765-40cc-eb78-2ed1c9263e81"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-22 16:40:30.729597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import \\\n",
            "Loads checkpoint by local backend from path: ./models/dwpose/dw-ll_ucoco_384.pth\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, map_location=map_location)\n",
            "cuda start\n",
            "An error occurred while trying to fetch models/sd-vae: Error no file named diffusion_pytorch_model.safetensors found in directory models/sd-vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "load unet model from ./models/musetalk/pytorch_model.bin\n",
            "/content/MuseTalk/musetalk/models/unet.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(model_path) if torch.cuda.is_available() else torch.load(model_path, map_location=self.device)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/resnet.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path) #modelzoo.load_url(resnet18_url)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/__init__.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(model_pth))\n",
            "Loaded inference config: {'task_0': {'video_path': 'data/video/yongen.mp4', 'audio_path': 'data/audio/yongen.wav'}, 'task_1': {'video_path': 'data/video/yongen.mp4', 'audio_path': 'data/audio/eng.wav', 'bbox_shift': -7}}\n",
            "Extracting landmarks... time-consuming operation\n",
            "reading images...\n",
            "100% 268/268 [00:03<00:00, 74.44it/s]\n",
            "get key_landmark and face bounding boxes with the default value\n",
            "  0% 0/268 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.11/dist-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "100% 268/268 [00:23<00:00, 11.33it/s]\n",
            "********************************************bbox_shift parameter adjustment**********************************************************\n",
            "Total frame:「268」 Manually adjust range : [ -21~23 ] , the current value: 0\n",
            "*************************************************************************************************************************************\n",
            "Number of frames: 268\n",
            "Starting inference\n",
            "100% 25/25 [00:12<00:00,  1.94it/s]\n",
            "Padding generated images to original video size\n",
            "100% 200/200 [00:21<00:00,  9.51it/s]\n",
            "Video generation command: ffmpeg -y -v warning -r 25.0 -f image2 -i ./results/test/v1/yongen_yongen/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/test/v1/temp_yongen_yongen.mp4\n",
            "Audio combination command: ffmpeg -y -v warning -i data/audio/yongen.wav -i ./results/test/v1/temp_yongen_yongen.mp4 ./results/test/v1/yongen_yongen.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mResults saved to ./results/test/v1/yongen_yongen.mp4\n",
            "Extracting landmarks... time-consuming operation\n",
            "reading images...\n",
            "100% 268/268 [00:03<00:00, 69.95it/s]\n",
            "get key_landmark and face bounding boxes with the bbox_shift: -7\n",
            "100% 268/268 [00:20<00:00, 12.83it/s]\n",
            "********************************************bbox_shift parameter adjustment**********************************************************\n",
            "Total frame:「268」 Manually adjust range : [ -21~23 ] , the current value: -7\n",
            "*************************************************************************************************************************************\n",
            "Number of frames: 268\n",
            "Starting inference\n",
            "100% 188/188 [00:38<00:00,  4.94it/s]\n",
            "Padding generated images to original video size\n",
            "100% 1500/1500 [02:38<00:00,  9.48it/s]\n",
            "Video generation command: ffmpeg -y -v warning -r 25.0 -f image2 -i ./results/test/v1/yongen_eng/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/test/v1/temp_yongen_eng.mp4\n",
            "Audio combination command: ffmpeg -y -v warning -i data/audio/eng.wav -i ./results/test/v1/temp_yongen_eng.mp4 ./results/test/v1/yongen_eng.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mResults saved to ./results/test/v1/yongen_eng.mp4\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MuseTalk 1.0\n",
        "!sh inference.sh v1.0 realtime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ax1EZGCR9Vgj",
        "outputId": "495912b4-9bef-43f2-f875-b0e471a4f775"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-22 16:46:26.793917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import \\\n",
            "Loads checkpoint by local backend from path: ./models/dwpose/dw-ll_ucoco_384.pth\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, map_location=map_location)\n",
            "cuda start\n",
            "/content/MuseTalk/scripts/realtime_inference.py:56: FutureWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
            "  @torch.no_grad()\n",
            "An error occurred while trying to fetch models/sd-vae: Error no file named diffusion_pytorch_model.safetensors found in directory models/sd-vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "load unet model from ./models/musetalk/pytorch_model.bin\n",
            "/content/MuseTalk/musetalk/models/unet.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(model_path) if torch.cuda.is_available() else torch.load(model_path, map_location=self.device)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/resnet.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path) #modelzoo.load_url(resnet18_url)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/__init__.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(model_pth))\n",
            "{'avator_1': {'preparation': True, 'bbox_shift': 5, 'video_path': 'data/video/yongen.mp4', 'audio_clips': {'audio_0': 'data/audio/yongen.wav', 'audio_1': 'data/audio/eng.wav'}}}\n",
            "*********************************\n",
            "  creating avator: avator_1\n",
            "*********************************\n",
            "preparing data materials ... ...\n",
            "extracting landmarks...\n",
            "reading images...\n",
            "100% 268/268 [00:04<00:00, 54.48it/s]\n",
            "get key_landmark and face bounding boxes with the bbox_shift: 5\n",
            "  0% 0/268 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.11/dist-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "100% 268/268 [00:23<00:00, 11.30it/s]\n",
            "********************************************bbox_shift parameter adjustment**********************************************************\n",
            "Total frame:「268」 Manually adjust range : [ -21~23 ] , the current value: 5\n",
            "*************************************************************************************************************************************\n",
            "100% 536/536 [00:50<00:00, 10.55it/s]\n",
            "Inferring using: data/audio/yongen.wav\n",
            "start inference\n",
            "processing audio:data/audio/yongen.wav costs 1226.433515548706ms\n",
            "200\n",
            "100% 10/10 [00:07<00:00,  1.34it/s]\n",
            "Total process time of 200 frames including saving images = 18.168729543685913s\n",
            "ffmpeg -y -v warning -r 25 -f image2 -i ./results/avatars/avator_1/tmp/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/avatars/avator_1/temp.mp4\n",
            "ffmpeg -y -v warning -i data/audio/yongen.wav -i ./results/avatars/avator_1/temp.mp4 ./results/avatars/avator_1/vid_output/audio_0.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mresult is save to ./results/avatars/avator_1/vid_output/audio_0.mp4\n",
            "\n",
            "\n",
            "Inferring using: data/audio/eng.wav\n",
            "start inference\n",
            "processing audio:data/audio/eng.wav costs 37.97292709350586ms\n",
            "1500\n",
            "100% 75/75 [00:17<00:00,  4.38it/s]\n",
            "Total process time of 1500 frames including saving images = 96.451087474823s\n",
            "ffmpeg -y -v warning -r 25 -f image2 -i ./results/avatars/avator_1/tmp/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/avatars/avator_1/temp.mp4\n",
            "ffmpeg -y -v warning -i data/audio/eng.wav -i ./results/avatars/avator_1/temp.mp4 ./results/avatars/avator_1/vid_output/audio_1.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mresult is save to ./results/avatars/avator_1/vid_output/audio_1.mp4\n",
            "\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MuseTalk 1.5 (Recommended)\n",
        "!sh inference.sh v1.5 normal\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUnY4r3i85XY",
        "outputId": "c0004b18-be21-4dbd-cc1d-42dea53b2cf4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-22 16:32:53.619757: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import \\\n",
            "Loads checkpoint by local backend from path: ./models/dwpose/dw-ll_ucoco_384.pth\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, map_location=map_location)\n",
            "cuda start\n",
            "An error occurred while trying to fetch models/sd-vae: Error no file named diffusion_pytorch_model.safetensors found in directory models/sd-vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "load unet model from ./models/musetalkV15/unet.pth\n",
            "/content/MuseTalk/musetalk/models/unet.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(model_path) if torch.cuda.is_available() else torch.load(model_path, map_location=self.device)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/resnet.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path) #modelzoo.load_url(resnet18_url)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/__init__.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(model_pth))\n",
            "Loaded inference config: {'task_0': {'video_path': 'data/video/yongen.mp4', 'audio_path': 'data/audio/yongen.wav'}, 'task_1': {'video_path': 'data/video/yongen.mp4', 'audio_path': 'data/audio/eng.wav', 'bbox_shift': -7}}\n",
            "Extracting landmarks... time-consuming operation\n",
            "reading images...\n",
            "100% 268/268 [00:03<00:00, 76.33it/s]\n",
            "get key_landmark and face bounding boxes with the default value\n",
            "  0% 0/268 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.11/dist-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "100% 268/268 [00:23<00:00, 11.39it/s]\n",
            "********************************************bbox_shift parameter adjustment**********************************************************\n",
            "Total frame:「268」 Manually adjust range : [ -21~23 ] , the current value: 0\n",
            "*************************************************************************************************************************************\n",
            "Number of frames: 268\n",
            "Starting inference\n",
            "100% 25/25 [00:12<00:00,  1.94it/s]\n",
            "Padding generated images to original video size\n",
            "100% 200/200 [00:22<00:00,  9.07it/s]\n",
            "Video generation command: ffmpeg -y -v warning -r 25.0 -f image2 -i ./results/test/v15/yongen_yongen/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/test/v15/temp_yongen_yongen.mp4\n",
            "Audio combination command: ffmpeg -y -v warning -i data/audio/yongen.wav -i ./results/test/v15/temp_yongen_yongen.mp4 ./results/test/v15/yongen_yongen.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mResults saved to ./results/test/v15/yongen_yongen.mp4\n",
            "Extracting landmarks... time-consuming operation\n",
            "reading images...\n",
            "100% 268/268 [00:03<00:00, 71.05it/s]\n",
            "get key_landmark and face bounding boxes with the default value\n",
            "100% 268/268 [00:20<00:00, 12.85it/s]\n",
            "********************************************bbox_shift parameter adjustment**********************************************************\n",
            "Total frame:「268」 Manually adjust range : [ -21~23 ] , the current value: 0\n",
            "*************************************************************************************************************************************\n",
            "Number of frames: 268\n",
            "Starting inference\n",
            "100% 188/188 [00:38<00:00,  4.94it/s]\n",
            "Padding generated images to original video size\n",
            "100% 1500/1500 [02:46<00:00,  9.02it/s]\n",
            "Video generation command: ffmpeg -y -v warning -r 25.0 -f image2 -i ./results/test/v15/yongen_eng/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/test/v15/temp_yongen_eng.mp4\n",
            "Audio combination command: ffmpeg -y -v warning -i data/audio/eng.wav -i ./results/test/v15/temp_yongen_eng.mp4 ./results/test/v15/yongen_eng.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mResults saved to ./results/test/v15/yongen_eng.mp4\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MuseTalk 1.5 (Recommended)\n",
        "!sh inference.sh v1.5 realtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML2eJnM69CX8",
        "outputId": "e2f30705-a190-4d9e-e683-59b66cf4921d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "\r0it [00:00, ?it/s]\r0it [00:00, ?it/s]\n",
            "2025-06-22 16:23:09.841496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/optim/optimizer/zero_optimizer.py:11: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import \\\n",
            "Loads checkpoint by local backend from path: ./models/dwpose/dw-ll_ucoco_384.pth\n",
            "/usr/local/lib/python3.11/dist-packages/mmengine/runner/checkpoint.py:347: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(filename, map_location=map_location)\n",
            "cuda start\n",
            "Downloading: \"https://www.adrianbulat.com/downloads/python-fan/s3fd-619a316812.pth\" to /root/.cache/torch/hub/checkpoints/s3fd-619a316812.pth\n",
            "100% 85.7M/85.7M [00:05<00:00, 17.8MB/s]\n",
            "/content/MuseTalk/scripts/realtime_inference.py:56: FutureWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
            "  @torch.no_grad()\n",
            "An error occurred while trying to fetch models/sd-vae: Error no file named diffusion_pytorch_model.safetensors found in directory models/sd-vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "load unet model from ./models/musetalkV15/unet.pth\n",
            "/content/MuseTalk/musetalk/models/unet.py:44: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  weights = torch.load(model_path) if torch.cuda.is_available() else torch.load(model_path, map_location=self.device)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/resnet.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path) #modelzoo.load_url(resnet18_url)\n",
            "/content/MuseTalk/musetalk/utils/face_parsing/__init__.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(torch.load(model_pth))\n",
            "{'avator_1': {'preparation': True, 'bbox_shift': 5, 'video_path': 'data/video/yongen.mp4', 'audio_clips': {'audio_0': 'data/audio/yongen.wav', 'audio_1': 'data/audio/eng.wav'}}}\n",
            "*********************************\n",
            "  creating avator: avator_1\n",
            "*********************************\n",
            "preparing data materials ... ...\n",
            "extracting landmarks...\n",
            "reading images...\n",
            "100% 268/268 [00:04<00:00, 55.42it/s]\n",
            "get key_landmark and face bounding boxes with the default value\n",
            "  0% 0/268 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/mmdet/models/layers/se_layer.py:158: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "/usr/local/lib/python3.11/dist-packages/mmdet/models/backbones/csp_darknet.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=False):\n",
            "100% 268/268 [00:22<00:00, 11.92it/s]\n",
            "********************************************bbox_shift parameter adjustment**********************************************************\n",
            "Total frame:「268」 Manually adjust range : [ -21~23 ] , the current value: 0\n",
            "*************************************************************************************************************************************\n",
            "100% 536/536 [00:52<00:00, 10.19it/s]\n",
            "Inferring using: data/audio/yongen.wav\n",
            "start inference\n",
            "processing audio:data/audio/yongen.wav costs 11697.424173355103ms\n",
            "200\n",
            "100% 10/10 [00:07<00:00,  1.41it/s]\n",
            "Total process time of 200 frames including saving images = 17.62869906425476s\n",
            "ffmpeg -y -v warning -r 25 -f image2 -i ./results/v15/avatars/avator_1/tmp/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/v15/avatars/avator_1/temp.mp4\n",
            "ffmpeg -y -v warning -i data/audio/yongen.wav -i ./results/v15/avatars/avator_1/temp.mp4 ./results/v15/avatars/avator_1/vid_output/audio_0.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : stereo\n",
            "\u001b[0mresult is save to ./results/v15/avatars/avator_1/vid_output/audio_0.mp4\n",
            "\n",
            "\n",
            "Inferring using: data/audio/eng.wav\n",
            "start inference\n",
            "processing audio:data/audio/eng.wav costs 35.414695739746094ms\n",
            "1500\n",
            "100% 75/75 [00:16<00:00,  4.44it/s]\n",
            "Total process time of 1500 frames including saving images = 95.31977701187134s\n",
            "ffmpeg -y -v warning -r 25 -f image2 -i ./results/v15/avatars/avator_1/tmp/%08d.png -vcodec libx264 -vf format=yuv420p -crf 18 ./results/v15/avatars/avator_1/temp.mp4\n",
            "ffmpeg -y -v warning -i data/audio/eng.wav -i ./results/v15/avatars/avator_1/temp.mp4 ./results/v15/avatars/avator_1/vid_output/audio_1.mp4\n",
            "\u001b[0;33mGuessed Channel Layout for Input Stream #0.0 : mono\n",
            "\u001b[0mresult is save to ./results/v15/avatars/avator_1/vid_output/audio_1.mp4\n",
            "\n",
            "\n",
            "\u001b[0m"
          ]
        }
      ]
    }
  ]
}