{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMksadLxPgaOuQBqVvd1E9y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weedge/doraemon-nb/blob/main/faiss_composite_indexes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. https://www.pinecone.io/learn/series/faiss/composite-indexes/\n",
        "2. https://www.youtube.com/watch?v=GEhmmcx1lvM\n",
        "3. https://www.youtube.com/watch?v=3Wqh4iUupbM\n",
        "\n"
      ],
      "metadata": {
        "id": "5jQb9BbZxa-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libomp-dev\n",
        "!pip install --upgrade faiss-cpu faiss-gpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7hElrk5ybT_",
        "outputId": "192727d4-1233-4c47-bd36-205b38e581bc"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libomp-dev is already the newest version (1:14.0-55~exp2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "首先，我们需要数据。我们将使用[Sift1M 数据集](http://corpus-texmex.irisa.fr/)，我们可以使用以下命令将其下载并加载到笔记本中：\n"
      ],
      "metadata": {
        "id": "CKxsG_GPy8-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import urllib.request as request\n",
        "from contextlib import closing\n",
        "\n",
        "# first we download the Sift1M dataset\n",
        "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
        "    with open('sift.tar.gz', 'wb') as f:\n",
        "        shutil.copyfileobj(r, f)"
      ],
      "metadata": {
        "id": "x1Ebybw5y-rk"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "\n",
        "# the download leaves us with a tar.gz file, we unzip it\n",
        "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
        "tar.extractall()"
      ],
      "metadata": {
        "id": "AszWRJj20xHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# now define a function to read the fvecs file format of Sift1M dataset\n",
        "def read_fvecs(fp):\n",
        "    a = np.fromfile(fp, dtype='int32')\n",
        "    d = a[0]\n",
        "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')\n",
        "\n",
        "# data we will search through\n",
        "xb = read_fvecs('./sift/sift_base.fvecs')  # 1M samples\n",
        "# also get some query vectors to search with\n",
        "xq = read_fvecs('./sift/sift_query.fvecs')\n",
        "# take just one query (there are many in sift_learn.fvecs)\n",
        "xq = xq[0].reshape(1, xq.shape[1])"
      ],
      "metadata": {
        "id": "qC6YGV2m00-4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "657Su0xx1Ilx",
        "outputId": "fe576fe0-7f58-4ee9-bd73-da397b40d535"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1.,   3.,  11., 110.,  62.,  22.,   4.,   0.,  43.,  21.,  22.,\n",
              "         18.,   6.,  28.,  64.,   9.,  11.,   1.,   0.,   0.,   1.,  40.,\n",
              "        101.,  21.,  20.,   2.,   4.,   2.,   2.,   9.,  18.,  35.,   1.,\n",
              "          1.,   7.,  25., 108., 116.,  63.,   2.,   0.,   0.,  11.,  74.,\n",
              "         40., 101., 116.,   3.,  33.,   1.,   1.,  11.,  14.,  18., 116.,\n",
              "        116.,  68.,  12.,   5.,   4.,   2.,   2.,   9., 102.,  17.,   3.,\n",
              "         10.,  18.,   8.,  15.,  67.,  63.,  15.,   0.,  14., 116.,  80.,\n",
              "          0.,   2.,  22.,  96.,  37.,  28.,  88.,  43.,   1.,   4.,  18.,\n",
              "        116.,  51.,   5.,  11.,  32.,  14.,   8.,  23.,  44.,  17.,  12.,\n",
              "          9.,   0.,   0.,  19.,  37.,  85.,  18.,  16., 104.,  22.,   6.,\n",
              "          2.,  26.,  12.,  58.,  67.,  82.,  25.,  12.,   2.,   2.,  25.,\n",
              "         18.,   8.,   2.,  19.,  42.,  48.,  11.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67sBI0zu1Lc4",
        "outputId": "86c2fcab-7e8a-4d56-f22c-27da77e8626d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIH_miI1M1q",
        "outputId": "d15f937d-8888-46cb-db2b-b40f5a446d4e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[在向量搜索](https://www.pinecone.io/learn/what-is-similarity-search/)领域，有许多索引方法和向量处理技术，使我们能够在召回率、延迟和内存使用之间确定优先级。\n",
        "\n",
        "[使用 IVF、 PQ](https://www.pinecone.io/learn/series/faiss/product-quantization/)或[HNSW](https://www.pinecone.io/learn/series/faiss/hnsw/)等特定方法，我们通常可以获得良好的结果。但为了获得*最佳性能，*我们通常希望使用*复合索引*。\n",
        "\n",
        "我们可以将复合索引视为向量变换和一种或多种索引方法的逐步过程。允许我们将多个索引和/或处理步骤放在一起来创建我们的“理想”索引。\n",
        "\n",
        "例如，我们可以使用倒排文件（IVF）索引来缩小搜索范围（提高搜索速度），然后添加[乘积量化（PQ）](https://www.pinecone.io/learn/series/faiss/product-quantization/)等压缩技术，以将较大的索引保持在合理的大小限制内。\n",
        "\n",
        "如果能够自定义索引，则存在生成具有不必要的不良召回、延迟或内存使用率的索引的风险。\n",
        "\n",
        "如果我们想构建强大且高性能的向量相似性搜索应用程序，我们必须了解复合索引的工作原理。必须了解在哪里可以使用不同的索引或向量转换以及何时不需要它们。\n",
        "\n",
        "在本文中，我们将学习如何使用[Facebook AI 相似性搜索 (Faiss)](https://www.pinecone.io/learn/series/faiss/)构建高性能复合索引——这是一个强大的库，许多人使用它来构建快速、准确的向量相似性搜索索引。我们还将介绍 Faiss index_factory，它允许我们用更清晰、更优雅的代码构建复合索引。\n",
        "\n",
        "## 什么是复合索引(Composite Indexes)\n",
        "\n",
        "复合索引类似于*乐高积木*；我们把一个放在另一个上面。我们会发现大多数块都可以组合在一起，但不同的组合可以产生任何东西，从艺术杰作到无法辨认的混乱。\n",
        "\n",
        "这同样适用于faiss。大多数组件可以放置在一起 - 但这并不意味着它们应该放置在一起。\n",
        "\n",
        "综合索引由以下各项的任意组合构建：\n",
        "\n",
        "- **向量变换(Vector transform)**— 在索引之前应用于向量的预处理步骤（PCA、OPQ）。\n",
        "- **粗量化器(Coarse quantizer)**-将向量*粗略*组织到子域（用于限制搜索范围，包括 IVF、IMI 和 HNSW）。\n",
        "- **精细量化器(Fine quantizer)**—将向量*更精细地*压缩为更小的域（用于压缩索引大小，例如 PQ）。\n",
        "- **细化(Refinement)**——搜索时的最后一步，使用原始平面向量上的距离计算对结果进行重新排序。或者，可以使用另一个索引（非平坦）索引。\n",
        "\n",
        "请注意，粗量化是指向量的“聚类”（例如 IVF 的倒排索引）。通过使用粗量化，我们通过限制搜索范围来实现*非穷举搜索。*\n",
        "\n",
        "精细量化描述了将向量压缩为*代码*（与 PQ 一样）[1][2][3]。这样做的目的是为了减少索引的内存使用。\n",
        "\n",
        "### 指数成分\n",
        "\n",
        "我们可以使用以下组件构建复合索引：\n",
        "\n",
        "\n",
        "|        Vector transform        |                       Coarse quantizer                       |                  Fine quantizer                   |   Refinement   |\n",
        "| :----------------------------: | :----------------------------------------------------------: | :-----------------------------------------------: | :------------: |\n",
        "| PCA, OPQ, RR, L2norm, ITQ, Pad | IVF,Flat, IMI, IVF,HNSW, IVF,PQ, IVF,RCQ, HNSW,Flat, HNSW,SQ, HNSW,PQ | Flat*, PQ, SQ, Residual*, RQ, LSQ, ZnLattice, LSH | RFlat, Refine* |\n",
        "\n",
        "\n",
        "\n",
        "例如，我们可以构建一个索引，其中：\n",
        "\n",
        "- Vector transform  **使用OPQ**转换传入向量。\n",
        "- Coarse quantizer 通过将向量存储在倒排文件列表**IVF**中来执行向量的粗量化，从而实现非穷举搜索。\n",
        "- Fine quantizer 压缩向量，通过每个 IVF 单元内的**PQ**减少内存使用*（向量被量化，但它们的单元分配不会改变）*。\n",
        "- Refinement 搜索后，根据原始平面向量**RFlat**对结果重新排序。\n",
        "\n",
        "**构建这些索引时，使用不同 Faiss 类的列表可能会变得混乱 - 因此使用 Faiss index_factory构建索引通常会更清晰**。\n",
        "\n",
        "![我们可以合并 IVF 和 PQ 索引，将量化的 PQ 向量存储在 IVF 结构中。](https://cdn.sanity.io/images/vr8gru94/production/409e12bad9ca16b82d685bf6c203ea9c0d282b59-1920x1080.png)\n",
        "\n",
        "我们可以合并 IVF 和 PQ 索引，将量化的 PQ 向量存储在 IVF 结构中。\n",
        "\n",
        "## Faiss Index Factory\n",
        "\n",
        "Faiss **index_factory**函数允许我们使用字符串来构建复合索引。它允许我们切换："
      ],
      "metadata": {
        "id": "JzWSqrg7xQWv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "i6rJvFy9waNy"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "quantizer = faiss.IndexFlatL2(128)\n",
        "index = faiss.IndexIVFFlat(quantizer, 128, 256)\n",
        "#index.is_trained\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_f = faiss.index_factory(128, \"IVF256,Flat\")\n",
        "#index_f.is_trained\n",
        "index_f.train(xb)\n",
        "index_f.add(xb)\n"
      ],
      "metadata": {
        "id": "mRDEIIq1yn3w"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们没有在 index_factory 示例中指定L2距离，因为 index_factory 默认使用L2。如果我们想使用 IndexFlatIP， 我们将 faiss.METRIC_INNER_PRODUCT 添加到我们的 index_factory 参数中。\n",
        "\n",
        "通过比较它们的性能，我们可以确认这两种方法产生相同的综合指数。首先，它们是否返回相同的最近邻居\n",
        "\n"
      ],
      "metadata": {
        "id": "XEvJ4cbIyq-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 100\n",
        "D, I = index.search(xq, k)  # search class-based index\n",
        "print(I,D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNABiSnByrjL",
        "outputId": "3c9764e8-965c-41be-efdc-2c311962841d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[701258 455537 562594 600499 619660  36267   2176 454263 722642 779712\n",
            "  721706 480497 619829 701919 224263 871568 225116 904911 391655 957845\n",
            "  930567 882961 221339 486457 104122 710644 465294 919197  16429 398306\n",
            "  989762 670103 403035 656997  87759 293551 839679 679408 931855 169794\n",
            "  703365 722837 882943  14218 392032  95545 932068 828457 782458 436743\n",
            "  403442 565750 977462 480765 875747 703631 561735 564474 185891 491343\n",
            "  454389 831924 727687 253993 827372 377461 629490 245147 746238 574941\n",
            "  955881 222238 730997 722935 744176 170348 839745 394538 879897  88584\n",
            "  628092 174301 172378 753423 310902 931722 842594 873615 820116  20822\n",
            "  742261  15892 236119 710839 656501 312288 562343 561910 928461 710969]] [[69844. 71441. 73537. 73793. 74356. 76583. 76608. 76664. 77587. 78092.\n",
            "  78655. 79223. 79309. 79508. 80246. 80499. 80639. 80668. 80749. 81399.\n",
            "  81870. 81991. 82049. 82210. 82455. 82615. 82742. 83031. 83307. 83377.\n",
            "  83466. 83576. 83632. 83646. 83828. 83899. 83911. 84504. 84617. 84829.\n",
            "  85459. 85573. 85654. 85932. 86033. 86101. 86360. 86578. 86601. 86812.\n",
            "  86824. 86870. 86933. 87084. 87134. 87135. 87395. 87414. 87658. 87691.\n",
            "  88186. 88266. 88420. 88465. 88641. 88661. 88722. 88772. 88870. 89198.\n",
            "  89278. 89303. 89393. 89400. 89591. 89661. 89830. 89938. 89959. 89997.\n",
            "  90054. 90222. 90354. 90482. 90500. 90517. 90531. 90730. 90830. 90875.\n",
            "  90885. 90976. 91062. 91078. 91082. 91171. 91253. 91315. 91380. 91395.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D_f, I_f = index_f.search(xq, k)  # search index_factory index\n",
        "print(I_f,D_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8Pv9yG9ytM_",
        "outputId": "5ea8fd0a-205d-49fa-e961-f7df74140da9"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[701258 455537 562594 600499 619660  36267   2176 454263 722642 779712\n",
            "  721706 480497 619829 701919 224263 871568 225116 904911 391655 957845\n",
            "  930567 882961 221339 486457 104122 710644 465294 919197  16429 398306\n",
            "  989762 670103 403035 656997  87759 293551 839679 679408 931855 169794\n",
            "  703365 722837 882943  14218 392032  95545 932068 828457 782458 436743\n",
            "  403442 565750 977462 480765 875747 703631 561735 564474 185891 491343\n",
            "  454389 831924 727687 253993 827372 377461 629490 245147 746238 574941\n",
            "  955881 222238 730997 722935 744176 170348 839745 394538 879897  88584\n",
            "  628092 174301 172378 753423 310902 931722 842594 873615 820116  20822\n",
            "  742261  15892 236119 710839 656501 312288 562343 561910 928461 710969]] [[69844. 71441. 73537. 73793. 74356. 76583. 76608. 76664. 77587. 78092.\n",
            "  78655. 79223. 79309. 79508. 80246. 80499. 80639. 80668. 80749. 81399.\n",
            "  81870. 81991. 82049. 82210. 82455. 82615. 82742. 83031. 83307. 83377.\n",
            "  83466. 83576. 83632. 83646. 83828. 83899. 83911. 84504. 84617. 84829.\n",
            "  85459. 85573. 85654. 85932. 86033. 86101. 86360. 86578. 86601. 86812.\n",
            "  86824. 86870. 86933. 87084. 87134. 87135. 87395. 87414. 87658. 87691.\n",
            "  88186. 88266. 88420. 88465. 88641. 88661. 88722. 88772. 88870. 89198.\n",
            "  89278. 89303. 89393. 89400. 89591. 89661. 89830. 89938. 89959. 89997.\n",
            "  90054. 90222. 90354. 90482. 90500. 90517. 90531. 90730. 90830. 90875.\n",
            "  90885. 90976. 91062. 91078. 91082. 91171. 91253. 91315. 91380. 91395.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "I_f.tolist() == I.tolist()  # check that both output same results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ratVpCYpyvnT",
        "outputId": "7adbf7c5-763d-45d5-8f16-c8329b8bebb9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "相同的结果，它们的搜索速度和内存使用情况如何比较？\n",
        "\n"
      ],
      "metadata": {
        "id": "bIGd_BO631td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmgTrdOp32em",
        "outputId": "797676b8-f8bb-42f7-d5cc-b2ba3e30632b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 µs ± 2.31 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index_f.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH32AxrG384A",
        "outputId": "27650d36-35e9-4f97-8e76-d627ef1a359a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112 µs ± 5.71 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_memory(index):\n",
        "    # write index to file\n",
        "    faiss.write_index(index, './temp.index')\n",
        "    # get file size\n",
        "    file_size = os.path.getsize('./temp.index')\n",
        "    # delete saved index\n",
        "    os.remove('./temp.index')\n",
        "    return file_size"
      ],
      "metadata": {
        "id": "iOhHtcI16U0g"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_memory(index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBztwOAz4Her",
        "outputId": "6a83f236-5fd9-4282-9aa5-aa3ef72b51cc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520133259"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_memory(index_f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmrY9hzd4OIt",
        "outputId": "f32de34a-600b-4ded-abe2-bdca6d824869"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "520133259"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_memory函数返回内存使用情况的精确匹配。搜索速度非常接近，之间快了 几μs——差异可以忽略不计。\n",
        "\n",
        " 我们将召回率计算为平坦 L2 索引与测试索引之间top- k的匹配百分比。\n",
        "\n",
        "文献中更常用的指标是recall@k；这不是 这里 计算的召回率。 Recall@k 是返回前k 个 返回记录中最近邻居的查询的百分比。\n",
        "\n",
        " 如果我们在使用k 值为 100时有 50% 的时间返回真实的最近邻，则我们可以说recall@100 性能为 0.5。\n",
        "\n"
      ],
      "metadata": {
        "id": "NVu4mtBr8i3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 为什么使用索引工厂\n",
        "从我们的测试来看，我们可以确信这两种索引构建方法只不过是通往同一目的地的不同路径。\n",
        "\n",
        "考虑到这一点——我们为什么要关心学习如何使用index_factory？首先，这可以取决于个人喜好。如果您更喜欢基于类的索引构建方法，请坚持使用。\n",
        "\n",
        "然而，通过使用index_factory我们可以大大提高代码的优雅性和清晰度。当使用index_factory时，我们将看到五行复杂的代码可以用一行更易读的代码表示。\n",
        "\n",
        "让我们组合一个复合索引，其中使用 OPQ 预处理向量，使用 IVF 聚类，使用 PQ 量化，然后使用Flat索引重新排序。\n",
        "\n"
      ],
      "metadata": {
        "id": "ojgFDvHT8mhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = xb.shape[1]\n",
        "m = 32\n",
        "nbits = 8\n",
        "nlist = 256\n",
        "\n",
        "# we initialize our OPQ and coarse+fine quantizer steps separately\n",
        "opq = faiss.OPQMatrix(d, m)\n",
        "# d now refers to shape of rotated vectors from OPQ (which are equal)\n",
        "vecs = faiss.IndexFlatL2(d)\n",
        "sub_index = faiss.IndexIVFPQ(vecs, d, nlist, m, nbits)\n",
        "# now we merge the preprocessing, coarse, and fine quantization steps\n",
        "index = faiss.IndexPreTransform(opq, sub_index)\n",
        "# we will add all of the previous steps to our final refinement step\n",
        "index = faiss.IndexRefineFlat(index)\n",
        "# train the index, and index vectors\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "JxayrdVj8kOO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "此代码演示了向索引添加多个组件可能产生的复杂性。如果我们使用index_factory重写它，我们会得到更简单的代码：\n"
      ],
      "metadata": {
        "id": "zrqs3v_g8_IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = xb.shape[1]\n",
        "# in index string, m==32, nlist==256, nbits is 8 by default\n",
        "\n",
        "index = faiss.index_factory(d, \"OPQ32,IVF256,PQ32,RFlat\")\n",
        "# train and index vectors\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "5ZqpICBn9AF0"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "两种方法产生完全相同的索引。每个的性能：\n",
        "\n",
        "|        Recall         | Search Time | Memory Usage |       |\n",
        "| :-------------------: | :---------: | :----------: | ----- |\n",
        "| Without index_factory |     31%     |    181µs     | 552MB |\n",
        "|  With index_factory   |     31%     |    174µs     | 552MB |\n",
        "\n",
        "\n",
        "\n",
        "**使用index_factory**时，搜索时间确实会稍微快一些，但除此之外，使用或不使用**index_factory**构建的等效索引之间没有性能差异。\n",
        "\n",
        "## 热门复合索引\n",
        "\n",
        "现在我们知道如何使用**index_factory**快速构建复合索引，让我们探索一些流行的高性能组合。"
      ],
      "metadata": {
        "id": "UhmXiJiL9BeT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IVFADC\n",
        "\n",
        "我们在上面介绍了修改后的**IVFADC**索引 -我们之前示例中的**IVF256、PQ32**部分构成了 IVFADC 的核心。让我们更详细地探讨一下。\n",
        "\n",
        "该指数于 2010 年与产品量化一起引入[4]。从那时起，它仍然是最受欢迎的索引之一 - 由于它是一种易于使用的索引，可以产生合理的召回率、快速的速度和*令人难以置信的*内存使用率。\n",
        "\n",
        "当我们的首要任务是最大限度地减少内存使用同时保持快速搜索速度时，IVFADC 是理想的选择。是以好的查询性能，但不好的召回性能为代价的。\n",
        "\n",
        "使用 IVFADC 建立索引有两个步骤：\n",
        "\n",
        "1. 向量被分配到IVF 结构中的不同列表（*或Voronoi 单元）。*\n",
        "2. 使用 PQ 压缩向量。\n",
        "\n",
        "![IVFADC 的索引过程，改编自[4]。](https://cdn.sanity.io/images/vr8gru94/production/0b9d996a8476e1bbe0ceea54ea7703f304125ffd-1920x980.png)\n",
        "\n",
        "IVFADC 的索引过程，改编自[4]。\n",
        "\n",
        "对向量进行索引后，在查询向量**xq**和我们的索引量化向量**之间**执行对称距离计算 ( **ADC** ) **。**\n",
        "\n",
        "该搜索被称为*非对称搜索*，因为它将未压缩的**xq与压缩的 PQ 向量（我们之前索引的）进行比较。**\n",
        "\n",
        "![通过对称距离计算（SDC，左），我们在将 xq 与之前量化的 xb 向量进行比较之前对其进行量化。 ADC（右）跳过 xq 的量化，并将其直接与量化的 xb 向量进行比较。](https://cdn.sanity.io/images/vr8gru94/production/e6008652a7306c91155c9dd1b95a8e934a2ffefa-1920x1000.png)\n",
        "\n",
        "通过对称距离计算（SDC，左），我们在将 xq 与之前量化的 xb 向量进行比较之前对其进行量化。ADC（右）跳过 xq 的量化，并将其直接与量化的 xb 向量进行比较。\n",
        "\n",
        "要使用**index_factory**实现索引，我们可以编写："
      ],
      "metadata": {
        "id": "h7u5NDPK9mg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"IVF256,PQ32x8\")\n",
        "index.train(xb)\n",
        "index.add(xb)\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo7iU2559Min",
        "outputId": "e250abc2-5e5e-4c07-a527-7055f14c2cb0"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[562594 455537 701258 185891 619829 722642 600499 779712 904911  36267\n",
            "  619660  15295 670103 398306 710644   2176 480497 225116 989762 701919\n",
            "  930567 565750 224263 919197 865591 873615 454263 703365  20822 977462\n",
            "  465294 882961 104122 875747 721706 403035 827372 169794  87759 656997\n",
            "  293551 828457 593937 871568 377461 308335 253993 137556 839679 486457\n",
            "  436743 842594 222238 221339  14218 628092 753248 392032 561910 730997\n",
            "  936186 932068 931722 722837 746238 722935 932767 315099 727687 679408\n",
            "  703631 710969 562343 245147 394538 454389  12458 236119 487871 880300\n",
            "   88584 165696 876536 310902 391655 436861 744176 932570 178778 178211\n",
            "  480765  72687 491343 371759 742261  16429 831924 931855 564474 844167]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "由此，我们创建了包含256 个IVF 单元的 IVFADC 索引；每个向量分别使用m和nbits值32和8通过 PQ 进行压缩。PQ默认使用nbits == 8所以我们也可以写\"IVF256,PQ32\"。\n",
        "\n",
        "m : 原始向量被分割成的子向量的数量\n",
        "\n",
        "nbits：每个子量化器使用的位数，我们可以计算每个子量化器使用的质心数量为 2**nbits\n",
        "\n",
        "我们可以减少nbits以减少索引内存使用量，或增加 nbits 以提高召回率和搜索速度。然而，当前版本的 Faiss 确实将IVF ,PQ的nbits限制为>= 8。\n",
        "\n",
        "还可以增加index.nprobe值来搜索更多 IVF 单元 - 默认情况下，该值为1。\n",
        "\n"
      ],
      "metadata": {
        "id": "MhYB227s95oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index.nprobe = 8\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC6116wN93Gi",
        "outputId": "84ef04b3-9600-4c4e-941e-1279bd929d3a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1] [[561813 934876 932085 706771 708177 908244 562594 455537 435345  68299\n",
            "   36538 701258 185891 619829 722642 181477 453447 562167 569837 872728\n",
            "  600499 565419 779712 893601 904911  36267 871066  59844 931632 530400\n",
            "  568573 619660 746931  15295 670103 102903 886630 236647 398306 710644\n",
            "    2176 480497 843384 860056   3752  49874 225116 732473 989762 701919\n",
            "  879793 923811 930567 564914 565750  36139 678385 556209 224263   4009\n",
            "  919197 865591 915482 873615 454263 703365  11342 374617 956733  20822\n",
            "  541845 544275 374319 977462 565484 465294 882961 104122 745811 875747\n",
            "  721706 403035 827372 169794 368186 194603 273419  87759 656997 293551\n",
            "    2837 910119 811700 369820 828457 237161 240996 869059    882 791852]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里我们有不同**nbits**和**nprobe**值的索引性能：\n",
        "\n",
        "|     Index     | nprobe | Recall | Search Time | Memory |\n",
        "| :-----------: | :----: | :----: | :---------: | :----: |\n",
        "| IVF256,PQ32x4 |   1    |  27%   |    329µs    |  25MB  |\n",
        "| IVF256,PQ32x4 |   6    |  45%   |    975µs    |  25MB  |\n",
        "| IVF256,PQ32x8 |   1    |  30%   |    136µs    |  40MB  |\n",
        "| IVF256,PQ32x8 |   8    |  74%   |    729µs    |  40MB  |\n",
        "\n",
        "\n",
        "### 优化乘积量化(Optimized Product Quantization)\n",
        "\n",
        "IVFADC和其他使用 PQ 的索引可以从优化乘积量化(OPQ)中受益。\n",
        "\n",
        "OPQ 的工作原理是旋转向量以使 PQ 中使用的子向量上的值分布变平。这对于数据分布不均匀的不平衡向量特别有利。\n",
        "\n",
        "在 Faiss 中，我们添加 OPQ 作为预处理步骤。对于IVFADC，OPQ索引字符串看起来像“OPQ32，IVF256，PQ32”，其中OPQ32和PQ32中的32指的是PQ生成的代码中的字节数m 。  \n",
        "\n",
        "Faiss中的OPQ矩阵并不是 整个 旋转和PQ过程。这只是旋转。下游必须包含 PQ 步骤才能实施 OPQ。\n",
        "\n",
        "和以前一样，我们需要在初始化时训练索引。\n",
        "\n"
      ],
      "metadata": {
        "id": "k-sle7kE-KQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can add pre-processing vector rotation to\n",
        "# improve distribution for the PQ step using OPQ\n",
        "index = faiss.index_factory(d, \"OPQ32,IVF256,PQ32x8\")\n",
        "index.train(xb)\n",
        "index.add(xb)\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GU5QBGj97zV",
        "outputId": "e7d1ffbf-3744-4680-d5a2-ddc9cedb58e5"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[562594 455537 701258 565419 619660 619829 882961 722642 454263 882946\n",
            "  727687   2176 465294 779712 721706 957845 104122 398306 491343 839679\n",
            "  480497 225116 904911 710644 486457 391655  36267 224263 656997 670103\n",
            "  703631 703365  16429 293551 392032 753248 436743 879897 989762 701919\n",
            "  722837 930567  87759 574941 871568 831924 221339 722935 170348 436861\n",
            "  919197 753203 730997 253993 480765 403442 827372  20822  95545 172378\n",
            "  169794 174301 487046 865591 873615 828457 977462 931855 628092 211660\n",
            "  403035 561735 165696 478742  62735 656501  88584 565750 875747 310902\n",
            "   15892 580841  61099 746238 245147 839745 742261 935185 564474 137556\n",
            "  710839 377461 782458 931722 844167 222238 162232 112803 710969 185891]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4K71VYj-Qbm",
        "outputId": "82d415e4-b553-4b36-a054-dcc91c80127e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "140 µs ± 17.9 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sift1M 数据集的数据分布已经很平衡，因此 OPQ 只给我们带来了召回性能的微小提升。当nprobe == 1时，我们的召回率从 30% 增加到 31%。\n",
        "\n",
        "我们可以增加nprobe值来提高召回率（以速度为代价）。但是，由于我们向索引添加了预处理步骤，因此我们无法直接使用index.nprobe访问nprobe，因为该索引不再引用索引的 IVF 部分。\n",
        "\n",
        "相反，我们必须在修改nprobe值之前提取IVF 索引- 我们可以使用extract_index_ivf函数来完成此操作。\n",
        "\n"
      ],
      "metadata": {
        "id": "eCwVZ7zd-S1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ivf = faiss.extract_index_ivf(index)\n",
        "ivf.nprobe = 13\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB19cjAB-Vxl",
        "outputId": "a09f058f-2a3d-4af9-9e38-be6c2f1c36df"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[932085 934876 561813 435345 562594 455537 701258 708177 872728 706771\n",
            "  695756 565419 908244  68299 619660 619829 893601 882961 562167 722642\n",
            "  454263 565814 600499 910119  87578 882946 727687 159953 915482   2176\n",
            "   36538 236647 171663 465294 779712 746931  59844 568573 988166 721706\n",
            "  102903 843560 158759   4009 871066 376161 957845 104122 564914 394507\n",
            "  398306 478814 886222 843384 806773 491343 923811 931632 374319 791852\n",
            "  839679 463781 180955 721370 194603 273419 480497 374617   2837 931948\n",
            "  225116 904911 710644 486457    882 391655 708525 876972  68581  36267\n",
            "  294458 556209 224263 368702 886630 656997 489261 883849 733897 544202\n",
            "  670103 570366 240996 703631 938544   3752 703365  16429 385660 529986]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ssP5MST-XHb",
        "outputId": "9e66a108-94d4-4fe8-ea52-85199fb119d9"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.38 ms ± 255 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "当**nprobe**值为**14 时**，我们返回 74% 的召回率。与单独 PQ 类似的召回结果，同时搜索时间从 729μs -> 1060μs 增加。\n",
        "\n",
        "|     Index     | nprobe | Recall | Search Time | Memory |\n",
        "| :------------: | :--: | :--: | :------: | :----: |\n",
        "| IVF256，PQ32x4 |  1   | 30%  | 136微秒  | 40.2MB |\n",
        "| IVF256，PQ32x4 |  1   | 31%  | 143微秒  | 40.3MB |\n",
        "| IVF256，PQ32x8 |  8   | 74%  | 729微秒  | 40.2MB |\n",
        "| IVF256，PQ32x8 |  13  | 74%  | 1060微秒 | 40.3MB |\n",
        "\n",
        "我们将在本文后面看到 OPQ 可用于提高性能，但正如我们在这里看到的，情况并非*总是*如此。\n",
        "\n",
        "![各种 nprobe 值的搜索时间（上）和召回率（下）。 我们纳入了“IVF256，Flat”进行比较。 扁平索引的内存使用量要高得多，为 520MB。](https://cdn.sanity.io/images/vr8gru94/production/2f8651fdfc87169f2b088c95d37a8a033701ad7a-1920x1080.png)\n",
        "\n",
        "各种 nprobe 值的搜索时间（上）和召回率（下）。我们纳入了“IVF256，Flat”进行比较。扁平索引的内存使用量要高得多，为 520MB。\n",
        "\n",
        "OPQ 还可用于降低预处理步骤中向量的维数。这个维度D必须是M的倍数，最好是D == 4M。为了将维度减少到64，我们可以使用\"OPQ16_64,IVF256,PQ16\"。\n",
        "\n"
      ],
      "metadata": {
        "id": "8aHQ5FKM-jym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-D-ADC 是指**多维索引（multi-dimensional indexing）**，以及在搜索时产生非对称距离计算的 PQ 步骤（如我们之前讨论的） [5] 。\n",
        "\n",
        "Multi-D-ADC index 基于 inverted multi-index(IMI)，是 IVF 的延伸。\n",
        "\n",
        "IMI 在召回和搜索速度方面都优于 IVF，但确实增加了内存使用量 [7]。这使得 IMI 索引（例如multi-D-ADC）在 IVFADC 无法完全达到所需的召回率和速度的情况下成为理想选择，并且可以节省更多内存使用量。IMI 索引的工作方式与 IVF 非常相似，但 Voronoi 单元在向量维度上进行分割。它产生的结果类似于多级 Voronoi 单元结构。\n",
        "\n",
        "![Voronoi单元分裂到多个向量子空间。 给定一个查询向量 xq，我们将每个 xq 子向量与其各自的子空间单元进行比较。](https://cdn.sanity.io/images/vr8gru94/production/ce81a066f489fe38b681d4fd7111f9cb5e4c804e-1920x1020.png)\n",
        "\n",
        "Voronoi单元分裂到多个向量子空间。 给定一个查询向量 xq，我们将每个 xq 子向量与其各自的子空间单元进行比较。\n",
        "\n",
        "当我们使用 PQ 将矢量压缩添加到 IMI 时，我们会生成Multi-D-ADC index。其中 ADC 是指将查询向量与 PQ 向量进行比较时进行的不对称距离计算。\n",
        "\n",
        "将所有这些放在一起，我们可以使用索引工厂字符串“IMI2x8,PQ32”创建 Multi-D-ADC index。\n",
        "\n"
      ],
      "metadata": {
        "id": "Sao8OuWm-rg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"IMI2x8,PQ32\")\n",
        "index.train(xb)  # index construction time is large for IMI\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "4xkjMGLI-wHn"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imi = faiss.extract_index_ivf(index)  # access nprobe\n",
        "imi.nprobe = 620\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1e_C9G7-wnF",
        "outputId": "48131b65-ea28-47db-b9dc-56b02906e2b3"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[934876 932085 561813 706771 708177 908244 435345 893601 701258 455537\n",
            "   36538 872728 619660 454263 910119  36267 562167 562594 236647 565814\n",
            "  746931 568573 843384 565419 600499 871066 480497 886222   3752  87759\n",
            "  915482  68299 931632 530400 224263 172378 863299 198964 277780  13612\n",
            "  806773 368702 530127 882946 914188 947001 496221   2837  87578 240996\n",
            "  463781 721706 225116 904911 689718 391655 931721  15847 957845 886630\n",
            "  746111 486457 732473 710644 570366 931948 871568 224849 701919 565484\n",
            "  930567 745811 465294 221339 919197 159953 478814 383299 813701 294458\n",
            "  293551 988166 238549 871048 368186 158640 102903 670103 619829 220944\n",
            "   63349 376161 933949 923811 544202  16429 561694 390777 569837  59844]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlMBVy_x-yBo",
        "outputId": "61f06677-3dfc-4451-c6a0-5b28375e16a2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14 ms ± 120 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "为了返回与 IVFADC 等效的类似召回，我们将搜索时间增加到 1.3 毫秒，这非常慢。但是，如果我们将 OPQ 添加到索引中，我们将返回更好的结果。\n",
        "\n"
      ],
      "metadata": {
        "id": "xn8b5a61-0Zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"OPQ32,IMI2x8,PQ32\")  # lets try with OPQ\n",
        "index.train(xb)  # index construction time is even larger for OPQ,IMI\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "xS7BSVnN-0w7"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imi = faiss.extract_index_ivf(index)  # we increase nprobe\n",
        "imi.nprobe = 100\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1YfQ4H--2GI",
        "outputId": "f9f6d9c4-9f4d-45c4-efbe-88869c91254f"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[932085 934876 561813 708177 706771 872728 562594 701258 236647  36538\n",
            "  565419 908244 455537 600499 104122 619660  87578 568573   2176 886630\n",
            "  871066 931632 843384 480497 564914 453447 240996  68299  49874   4009\n",
            "  565814 957845 562167 754070 454263 904911 893601 988166 670103 806773\n",
            "  722642 159953 465294 541845   2837 886222    882 746931 915482  91348\n",
            "   36267 237161 224263 721370 882961 253993 947001 374617 102903 779712\n",
            "  931855  36139  12840 294458 385660 899809 882946 221339 871568 486457\n",
            "  932570 544275 869059 813701 879793 910119 933949 701919 403035 845643\n",
            "  158759 678385 225116  16429 710644 930567 374319    190 886135 753423\n",
            "  923811 544202 871048 322550 564474 478814 753248 592899 883696 293551]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHdLSY7Y-4gl",
        "outputId": "9346a17b-e299-45e7-b3bd-c7efd9467737"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "665 µs ± 18.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "对于 74% 的召回率，我们的 OPQ multi-D-ADC 索引速度最快，平均搜索时间仅为 461μs。(注： 这个是作者的跑的结果，实际以当前环境跑的结果为准，但是结论是一致的)\n",
        "\n",
        "|       Index       | Recall | Search Time | Memory |\n",
        "| :---------------: | :----: | :---------: | :----: |\n",
        "|    IVF256,PQ32    |  74%   |    729µs    | 40.2MB |\n",
        "|    IMI2x8,PQ32    |  72%   |   1350µs    | 40.8MB |\n",
        "| OPQ32,IMI2x8,PQ32 |  74%   |    461µs    | 40.7MB |\n",
        "\n",
        "和以前一样，我们可以使用nprobe微调索引以优先考虑召回或速度。\n",
        "\n",
        "![各种 nprobe 值的搜索时间（上）和召回率（下）。 我们包含“IMI2x8，Flat”进行比较。 扁平索引的内存使用量要高得多，为 520MB。](https://cdn.sanity.io/images/vr8gru94/production/3500949c3274050f2c7bcc970dd74e24c46a7e95-1920x1080.png)\n",
        "\n",
        "各种 nprobe 值的搜索时间（上）和召回率（下）。我们包含“IMI2x8，Flat”进行比较。扁平索引的内存使用量要高得多，为 520MB。\n",
        "\n",
        "“**OPQ32，IMI2x8，PQ32**”是我们在低内存的召回率和速度方面最好的指标之一。然而，我们将看到我们可以通过以下索引进一步改进这些指标。\n",
        "\n",
        "\n",
        "\n",
        "### HNSW Indexes\n",
        "\n",
        "IVF 与 分层导航小型世界(HNSW) 图是我们最终的复合索引。该索引将我们的索引向量按照通常的 IVF 方式分割成单元格，但这次我们将使用 HNSW 优化该过程。\n",
        "\n",
        "与我们之前的两个指数相比，采用 HNSW 的 IVF 可以产生相当或更好的速度以及显着更高的召回率，但代价是内存使用量更高*。*\n",
        "\n",
        "在较高层面上，HNSW 基于*小世界图理论*，即网络中的所有顶点（*节点*）（无论有多大）都可以通过少量步骤遍历。\n",
        "\n",
        "![](https://d33wubrfki0l68.cloudfront.net/2c46ea2a595c6ecb10a7c1d729bb85620bcc3b3e/b9423/images/composite-indexes-11.mp4)\n",
        "\n",
        "可导航的小世界图的示例，图中的所有节点都通过少量的边遍历连接。小世界图论假设即使对于具有数十亿个顶点的巨大网络也是如此。\n",
        "\n",
        "在这个小世界图中，我们看到了短程和长程链接。当遍历远程链接时，我们在图表中移动得更快。\n",
        "\n",
        "HNSW 通过将图链接拆分为多个层来利用这一点。在较高的入口层，我们只找到远程链接。当我们向下移动层时，会添加较短距离的链接。\n",
        "\n",
        "搜索时，我们从这些具有远程链接的较高层开始。这意味着我们的第一次遍历是跨越远程链接的。当我们向下移动层时，当我们遍历更多的短程链接时，我们的搜索变得更加精细。\n",
        "\n",
        "![HNSW 图将包含远程和短程链接的典型图分解为多个层（层次结构）。 在搜索过程中，我们从最高层开始，它由远程链接组成。 当我们向下移动每一层时，链接变得更加细化。](https://cdn.sanity.io/images/vr8gru94/production/0b4b19e673df19f684dbfe5ed91f80f283cda10c-1920x1080.png)\n",
        "\n",
        "HNSW 图将包含远程和短程链接的典型图分解为多个层（层次结构）。在搜索过程中，我们从最高层开始，它由远程链接组成。当我们向下移动每一层时，链接变得更加细化。\n",
        "\n",
        "这种方法应该最大限度地减少遍历次数（加快搜索速度），同时仍然在较低层中执行非常精细的搜索（保持高召回率）。\n",
        "\n",
        "那就是HNSW，但是我们如何才能将HNSW与IVF结合起来呢？\n",
        "\n",
        "使用普通 IVF，我们引入查询向量并将其与每个单元质心进行比较，识别最近的质心以限制我们的搜索范围。\n",
        "\n",
        "为了将此过程与 HNSW 配对，我们生成所有这些单元质心的 HNSW 图，使穷举质心搜索*近似*。\n",
        "\n",
        "![HNSW 可用于使用 IVF 单元质心快速找到近似最近邻。](https://cdn.sanity.io/images/vr8gru94/production/0c94d256ebe92cf3ffea7429f54ede89477a6513-1920x1080.png)\n",
        "\n",
        "HNSW 可用于使用 IVF 单元质心快速找到近似最近邻。\n",
        "\n",
        "之前，我们一直使用具有 256 个单元质心的 IVF 索引。256 的穷举搜索很快，并且没有理由使用具有如此少质心的近似搜索。\n",
        "\n",
        "由于我们的单元格很少，因此每个单元格必须包含许多向量 - 仍将使用穷举搜索来搜索这些向量。在这种情况下，单元质心上的 IVF+HNSW 没有帮助。\n",
        "\n",
        "对于 IVF+HNSW 索引，我们需要将“少数质心和大单元”替换为“许多质心和小单元”。\n",
        "\n",
        "对于我们的 1M 索引，建议nlist值为65536 [8]。但是，我们应该向index.train提供至少 30\\*nlist == 1.97M个向量，但我们没有。所以16384或更小的nlist更合适。对于此数据集，nlist == 4096返回最高的召回率（速度较慢）。\n",
        "\n",
        "使用 IVF+HNSW，我们使用 HNSW 快速识别近似最近的单元质心，然后将我们的穷举搜索限制到那些最近的单元。\n",
        "\n",
        "可以使用\"IVF4096_HNSW32,Flat\"构建标准 IVF+HNSW 索引。利用这个，我们有：\n",
        "\n",
        "- 4096 个IVF 单元。\n",
        "- 单元质心存储在 HNSW 图中。每个质心都与其他32 个质心相连。\n",
        "- 向量本身没有改变。它们是平面向量。"
      ],
      "metadata": {
        "id": "IjTsq8_xfXrI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = faiss.index_factory(d, \"IVF4096_HNSW32,Flat\")\n",
        "index.train(xb)\n",
        "index.add(xb)"
      ],
      "metadata": {
        "id": "1X5ueHFnf5V3"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_m8-X4Zf6T6",
        "outputId": "45edb333-1e00-4b1a-e97b-6742a3814f8f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[934876 701258 619660 746931 886630 779712 721706  49874 619829 701919\n",
            "   87578 225116 904911 957845 882946 882961 394507 732473 104122 465294\n",
            "  956733 919197 678385  16429 989762 293551 879793 561694 876511 722837\n",
            "   95545 514091 436743 403442 703631 564474 628450 956632  72761 554637\n",
            "  629490 225065 746238  68862 731216 744176 839745  88584 628092 701108\n",
            "  753423 842594 807000 203984 268262  12458 181176 844361 502709  88961\n",
            "   91712 487046 455038 133003 932194 753248  95139 753203 625014 223897\n",
            "  844167 394954 121987 586237 977398  87321 982563 561446 528935 554609\n",
            "  627989 251583  60470 255493 237257  61099 287103 294078 887051 514115\n",
            "  881811 451258 900144 231787 933420 682025 564065 745965 140644 923860]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNMWHAh0f7km",
        "outputId": "f82e4aed-ff4f-4a82-dd27-10ea973c4189"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "148 µs ± 41 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.nprobe = 146\n",
        "D, I = index.search(xq, k)\n",
        "print(I)\n",
        "#recall(I)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnK1sgL4f-6y",
        "outputId": "91fab8e0-8864-4f2d-ae1a-d5cc4fe8f7cb"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[932085 934876 561813 708177 706771 695756 435345 701258 455537 872728\n",
            "   36538 562594 908244 600499 893601 619660 562167 746931 565419 236647\n",
            "  568573  36267   2176 931632 454263   3752 910119 722642 843384 886630\n",
            "   68299 779712 871066 721706  49874 886222 480497 619829 701919    882\n",
            "   87578 224263   4009 871568 478814 225116 904911 391655 565484   2837\n",
            "  102903 159953 171663 957845 791852 368702 453447 915482 930567 544275\n",
            "  180955  59844 882946 899809 882961 988166 860056 221339 556209 544202\n",
            "  394507 486457 529986 732473 104122 923811 564914  36139 710644 806773\n",
            "  465294 237161 871048 569837 374617 463781 956733 919197 678385 158759\n",
            "  240996 931948  16429  91348  63349 398306 931721 989762 929750 670103]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "index.search(xq, k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OFTHjzmgAo7",
        "outputId": "b6c1cb1b-0abd-45ee-deda-cdf04e4d9bfd"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.71 ms ± 374 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "有了这个索引，我们可以在 58.9μs -> 916μs 的搜索时间内实现从 25% -> 100% 召回率的令人难以置信的性能。\n",
        "\n",
        "![各种 nprobe 值的搜索时间（上）和召回率（下）。 以更长的搜索时间为代价，我们可以通过减少 nlist 来提高召回率。](https://cdn.sanity.io/images/vr8gru94/production/ae39ade8751b67c4acdc7f960c9a0ee9e565ff95-1920x1080.png)\n",
        "\n",
        "各种 nprobe 值的搜索时间（上）和召回率（下）。以更长的搜索时间为代价，我们可以通过减少 nlist 来提高召回率。\n",
        "\n",
        "然而，IVF+HNSW 指数也并非没有缺陷。尽管我们拥有令人难以置信的召回率和快速的搜索速度，但这个索引的内存使用量是*巨大的*。我们的 1M 128 维向量产生的索引大小为 523MB+。\n",
        "\n",
        "正如我们之前所做的那样，我们可以使用 PQ 和 OPQ 来减少这种情况，但这会减少召回率并增加搜索时间。\n",
        "\n",
        "\n",
        "\n",
        "|             Index             | Recall | Search Time | Memory |\n",
        "| :---------------------------: | :----: | :---------: | :----: |\n",
        "|       IVF4096_HNSW,Flat       |  90%   |    550µs    | 523MB  |\n",
        "|    IVF4096_HNSW,PQ32 (PQ)     |  69%   |    550µs    |  43MB  |\n",
        "| OPQ32,IVF4096_HNSW,PQ32 (OPQ) |  74%   |    364µs    |  43MB  |\n",
        "\n",
        "如果可以接受较低的召回率以最大限度地减少搜索时间和内存使用量，则带有 OPQ 的 IVF+HNSW 索引是理想的选择。另一方面，带有 PQ 的 IVF+HNSW 并没有比我们之前的*IVFADC*和*Multi-D-ADC*指数有任何优势。\n",
        "\n",
        "|    Name     |   Index String    | Recall | Search Time | Memory |\n",
        "| :---------: | :---------------: | :----: | :---------: | :----: |\n",
        "|   IVFADC    |    IVF256,PQ32    |  74%   |    729µs    |  40MB  |\n",
        "| Multi-D-ADC | OPQ32,IMI2x8,PQ32 |  74%   |    461µs    |  41MB  |\n",
        "\n",
        "\n",
        "\n",
        "这就是本文的内容！我们介绍了复合索引以及如何使用 Faiss **index_factory**构建它们。我们研究了几个最流行的综合指数，包括：\n",
        "\n",
        "- IVFADC\n",
        "- Multi-D-ADC\n",
        "- IVF-HNSW\n",
        "\n",
        "通过索引和搜索 Sift1M 数据集，我们学习了如何修改每个索引的参数以优先考虑召回率、速度和内存使用情况。\n",
        "\n",
        "根据我们在此介绍的内容，您将能够设计和测试各种复合索引，并更好地决定最适合您需求的索引结构。"
      ],
      "metadata": {
        "id": "5i5sv1gOgK7z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "[1] Y.Chen, et al., Approximate Nearest Neighbor Search by Residual Vector Quantization (2010), Sensors\n",
        "\n",
        "[2] Y. Matsui, et al., A Survey of Product Quantization (2018), ITE Trans. on MTA\n",
        "\n",
        "[3] T. Ge, et. al., Optimized Product Quantization (2014), TPAMI\n",
        "\n",
        "[4] H. Jégou, et al., Product quantization for nearest neighbor search (2010), TPAMI\n",
        "\n",
        "[5] A. Babenko, V. Lempitsky, The Inverted Multi-Index (2012), CVPR\n",
        "\n",
        "[6] H. Jégou, et al., Searching in One Billion Vectors: Re-rank with Source Coding (2011), ICASSP\n",
        "\n",
        "[7] D. Baranchuk, et al., Revisiting the Inverted Indices for Billion-Scale Approximate Nearest Neighbors (2018), ECCV\n",
        "\n",
        "[8] Guidelines to choose an index, Faiss wiki\n",
        "\n",
        "[9] The Index Factory, Faiss wiki\n",
        "\n"
      ],
      "metadata": {
        "id": "wOBhtOk2gnz1"
      }
    }
  ]
}